{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os \n",
    "import fastai\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "PATH=\"/home/kirana/Documents/phd/final\"\n",
    "DATAPATH=\"/home/kirana/Documents/phd/data/aclImdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_train,df_valid,df_test,itos, train_tokens, valid_tokens, test_tokens, trn_lm, val_lm, test_lm]=pickle.load(open(f'{PATH}/inter/dfs_tokens_fastai.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=52 # 52 - Jeremey, 20 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt= 70 #70 - Jeremey, 35 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_lm(tokens,bs):\n",
    "    import itertools\n",
    "    # Collapse into a single large array\n",
    "    tokens=np.asarray(list (itertools.chain(*tokens)))\n",
    "    # How many batches\n",
    "    n_batch=len(tokens)//bs\n",
    "    # Truncate to exclude the ones at the end\n",
    "    tokens=tokens[:bs*n_batch]\n",
    "    # Reshape\n",
    "    tokens=tokens.reshape(bs,-1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52, 396650), (52, 43895), (52, 143259))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens=create_data_lm(df_train['tokens'],bs)\n",
    "valid_tokens=create_data_lm(df_valid['tokens'],bs)\n",
    "test_tokens=create_data_lm(df_test['tokens'],bs)\n",
    "train_tokens.shape, valid_tokens.shape, test_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i):\n",
    "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 70) (52, 70)\n"
     ]
    }
   ],
   "source": [
    "n_batch=train_tokens.shape[1]\n",
    "for i in range(0,n_batch,bptt):\n",
    "    seq_len=min(bptt,n_batch-1-i)\n",
    "    x=train_tokens[:,i:i+seq_len]\n",
    "    y=train_tokens[:,i+1:i+1+seq_len]\n",
    "    print (x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52, 70), (52, 70))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   41,    42,    43,    40, ...,     2,  1896,   463,     4],\n",
       "        [ 1071,    23,    67,    39, ...,     2,    98,    11,    63],\n",
       "        [   54,    34,     7,   190, ...,     2,    87,    34,  5998],\n",
       "        [    7,  1213,     8,   453, ...,   406,     4,     2,    46],\n",
       "        ...,\n",
       "        [   60,   126,   931,     6, ...,   114,    39,   599,    63],\n",
       "        [    2, 15094,   132,    65, ...,    56,  1350,   209,   281],\n",
       "        [11783,   658,   318,     3, ...,     6,    64,    79,  1268],\n",
       "        [   42,    43,    40,     2, ...,   708,   111,     4,     2]]),\n",
       " array([[   42,    43,    40,    13, ...,  1896,   463,     4,     2],\n",
       "        [   23,    67,    39,    18, ...,    98,    11,    63,    28],\n",
       "        [   34,     7,   190,  1732, ...,    87,    34,  5998,    47],\n",
       "        [ 1213,     8,   453,    21, ...,     4,     2,    46,     7],\n",
       "        ...,\n",
       "        [  126,   931,     6,   126, ...,    39,   599,    63,   314],\n",
       "        [15094,   132,    65,   411, ...,  1350,   209,   281,     9],\n",
       "        [  658,   318,     3,    25, ...,    64,    79,  1268,    85],\n",
       "        [   43,    40,     2,    14, ...,   111,     4,     2, 13447]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52, 70), (52, 70))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 396650)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-trained AWD-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_AWD_LSTM='/home/kirana/Documents/phd/data/pre-trained/awd_lstm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bwd_wt103_enc.h5  fwd_wt103_enc.h5  itos_wt103.pkl  \u001b[0m\u001b[01;34mwt103_60002\u001b[0m/\r\n",
      "bwd_wt103.h5      fwd_wt103.h5      \u001b[01;34mwt103_238642\u001b[0m/   \u001b[01;31mwt103_tiny.tgz\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls {PATH_AWD_LSTM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(f'{PATH_AWD_LSTM}/fwd_wt103.h5', map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.encoder.weight',\n",
       "              tensor([[-1.2274e-01,  2.7886e-01, -3.8850e-01,  ..., -1.0404e-01,\n",
       "                        1.9580e-02,  1.8548e-01],\n",
       "                      [ 1.4854e-05, -2.3424e-05,  1.9693e-05,  ...,  2.1349e-05,\n",
       "                        2.1776e-05, -1.2394e-05],\n",
       "                      [ 1.8070e-01,  1.5874e+00, -1.1738e-01,  ..., -4.5935e-02,\n",
       "                       -8.1352e-02,  1.8054e-01],\n",
       "                      ...,\n",
       "                      [-1.8595e-03, -6.8529e-03,  1.6999e-03,  ...,  1.7039e-03,\n",
       "                        4.1632e-03, -1.3171e-03],\n",
       "                      [-2.3120e-03, -6.9001e-03,  1.8772e-03,  ...,  5.0309e-04,\n",
       "                        4.6596e-03, -2.5850e-03],\n",
       "                      [-2.2463e-03, -9.1512e-03,  1.3927e-03,  ...,  1.2296e-03,\n",
       "                        5.8085e-03, -1.8940e-03]])),\n",
       "             ('0.encoder_with_dropout.embed.weight',\n",
       "              tensor([[-1.2274e-01,  2.7886e-01, -3.8850e-01,  ..., -1.0404e-01,\n",
       "                        1.9580e-02,  1.8548e-01],\n",
       "                      [ 1.4854e-05, -2.3424e-05,  1.9693e-05,  ...,  2.1349e-05,\n",
       "                        2.1776e-05, -1.2394e-05],\n",
       "                      [ 1.8070e-01,  1.5874e+00, -1.1738e-01,  ..., -4.5935e-02,\n",
       "                       -8.1352e-02,  1.8054e-01],\n",
       "                      ...,\n",
       "                      [-1.8595e-03, -6.8529e-03,  1.6999e-03,  ...,  1.7039e-03,\n",
       "                        4.1632e-03, -1.3171e-03],\n",
       "                      [-2.3120e-03, -6.9001e-03,  1.8772e-03,  ...,  5.0309e-04,\n",
       "                        4.6596e-03, -2.5850e-03],\n",
       "                      [-2.2463e-03, -9.1512e-03,  1.3927e-03,  ...,  1.2296e-03,\n",
       "                        5.8085e-03, -1.8940e-03]])),\n",
       "             ('0.rnns.0.module.weight_ih_l0',\n",
       "              tensor([[-0.0812, -0.0811, -0.0937,  ..., -0.0259, -0.1403, -0.3247],\n",
       "                      [ 0.1154,  0.1142,  0.0938,  ..., -0.0711,  0.1669, -0.0387],\n",
       "                      [-0.0051,  0.1007,  0.2071,  ..., -0.0860, -0.0288, -0.0894],\n",
       "                      ...,\n",
       "                      [ 0.0055,  0.0157,  0.2990,  ...,  0.0616,  0.1159, -0.4737],\n",
       "                      [ 0.0181,  0.0426,  0.1130,  ...,  0.3529, -0.0114, -0.0125],\n",
       "                      [-0.0167, -0.1328,  0.1741,  ...,  0.0548, -0.0045,  0.1688]])),\n",
       "             ('0.rnns.0.module.bias_ih_l0',\n",
       "              tensor([ 0.1503, -0.4701, -0.1885,  ..., -0.5919, -0.2172, -0.1207])),\n",
       "             ('0.rnns.0.module.bias_hh_l0',\n",
       "              tensor([ 0.1503, -0.4701, -0.1885,  ..., -0.5919, -0.2172, -0.1207])),\n",
       "             ('0.rnns.0.module.weight_hh_l0_raw',\n",
       "              tensor([[-0.1013,  0.1786, -0.0528,  ...,  0.0741,  0.0306,  0.2467],\n",
       "                      [ 0.1780, -0.0853, -0.0243,  ..., -0.1129, -0.1310, -0.1498],\n",
       "                      [ 0.0661, -0.0496,  0.0921,  ...,  0.1829,  0.0533, -0.1525],\n",
       "                      ...,\n",
       "                      [-0.0322, -0.0704,  0.1653,  ...,  0.2142, -0.0558,  0.0315],\n",
       "                      [-0.1651, -0.0290,  0.1748,  ..., -0.0446,  0.5444,  0.0616],\n",
       "                      [ 0.0905, -0.1704, -0.0053,  ..., -0.0057,  0.2269,  0.0328]])),\n",
       "             ('0.rnns.1.module.weight_ih_l0',\n",
       "              tensor([[ 0.3307,  0.0385,  0.0860,  ...,  0.0685, -0.0444,  0.0539],\n",
       "                      [ 0.0720,  0.1607,  0.0562,  ...,  0.0276,  0.0613,  0.1632],\n",
       "                      [-0.1565, -0.1168,  0.1897,  ..., -0.0357,  0.0296,  0.0961],\n",
       "                      ...,\n",
       "                      [-0.0897, -0.1464, -0.0760,  ...,  0.0536,  0.0422, -0.0580],\n",
       "                      [ 0.1166, -0.1534, -0.1784,  ..., -0.0689,  0.2170,  0.1461],\n",
       "                      [-0.0413,  0.0689,  0.0581,  ..., -0.0640, -0.1703, -0.0945]])),\n",
       "             ('0.rnns.1.module.bias_ih_l0',\n",
       "              tensor([-0.8577, -0.6784, -0.7249,  ..., -0.6782,  0.0567, -0.5026])),\n",
       "             ('0.rnns.1.module.bias_hh_l0',\n",
       "              tensor([-0.8577, -0.6784, -0.7249,  ..., -0.6782,  0.0567, -0.5026])),\n",
       "             ('0.rnns.1.module.weight_hh_l0_raw',\n",
       "              tensor([[-0.0273, -0.2277,  0.0782,  ...,  0.1355, -0.1282,  0.1669],\n",
       "                      [ 0.1218,  0.0017, -0.0998,  ..., -0.2085, -0.0686, -0.1389],\n",
       "                      [-0.3878, -0.0498, -0.1748,  ..., -0.4014,  0.1986, -0.4400],\n",
       "                      ...,\n",
       "                      [-0.2097, -0.4298,  0.3551,  ...,  0.0316, -0.1198,  0.1266],\n",
       "                      [ 0.0037, -0.0223,  0.0032,  ..., -0.2672, -0.3093, -0.0361],\n",
       "                      [-0.0464,  0.1664, -0.1348,  ...,  0.1600, -0.1138,  0.0845]])),\n",
       "             ('0.rnns.2.module.weight_ih_l0',\n",
       "              tensor([[-0.0741,  0.0447, -0.0744,  ..., -0.0419,  0.1600, -0.0553],\n",
       "                      [ 0.0270,  0.0118,  0.0449,  ...,  0.1165, -0.1080, -0.0681],\n",
       "                      [-0.1023, -0.1662, -0.0229,  ...,  0.1652, -0.1070,  0.0970],\n",
       "                      ...,\n",
       "                      [-0.0989, -0.4425, -0.0343,  ..., -0.1434,  0.5851, -0.0291],\n",
       "                      [ 0.0802, -0.1067,  0.2789,  ..., -0.0916, -0.2240,  0.1020],\n",
       "                      [-0.4078,  0.7220,  0.1142,  ...,  0.5287,  0.2035, -0.1811]])),\n",
       "             ('0.rnns.2.module.bias_ih_l0',\n",
       "              tensor([-0.3681, -0.9079, -0.1998,  ...,  0.8533,  0.3202,  1.2172])),\n",
       "             ('0.rnns.2.module.bias_hh_l0',\n",
       "              tensor([-0.3681, -0.9079, -0.1998,  ...,  0.8533,  0.3202,  1.2172])),\n",
       "             ('0.rnns.2.module.weight_hh_l0_raw',\n",
       "              tensor([[-0.0966,  0.0236, -0.0152,  ...,  0.0388, -0.0531, -0.0395],\n",
       "                      [-0.0328, -0.2217,  0.0028,  ...,  0.0143, -0.0368, -0.0085],\n",
       "                      [ 0.0167, -0.0081, -0.0561,  ...,  0.0125,  0.0442, -0.0139],\n",
       "                      ...,\n",
       "                      [-0.0212, -0.1034, -0.0106,  ..., -0.0561,  0.0200, -0.0157],\n",
       "                      [ 0.0183,  0.0364, -0.0251,  ..., -0.0240, -0.1150,  0.0046],\n",
       "                      [ 0.0100, -0.1824,  0.1076,  ..., -0.0269,  0.2733,  0.1846]])),\n",
       "             ('1.decoder.weight',\n",
       "              tensor([[-1.2274e-01,  2.7886e-01, -3.8850e-01,  ..., -1.0404e-01,\n",
       "                        1.9580e-02,  1.8548e-01],\n",
       "                      [ 1.4854e-05, -2.3424e-05,  1.9693e-05,  ...,  2.1349e-05,\n",
       "                        2.1776e-05, -1.2394e-05],\n",
       "                      [ 1.8070e-01,  1.5874e+00, -1.1738e-01,  ..., -4.5935e-02,\n",
       "                       -8.1352e-02,  1.8054e-01],\n",
       "                      ...,\n",
       "                      [-1.8595e-03, -6.8529e-03,  1.6999e-03,  ...,  1.7039e-03,\n",
       "                        4.1632e-03, -1.3171e-03],\n",
       "                      [-2.3120e-03, -6.9001e-03,  1.8772e-03,  ...,  5.0309e-04,\n",
       "                        4.6596e-03, -2.5850e-03],\n",
       "                      [-2.2463e-03, -9.1512e-03,  1.3927e-03,  ...,  1.2296e-03,\n",
       "                        5.8085e-03, -1.8940e-03]]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(f'{PATH_AWD_LSTM}/fwd_wt103_enc.h5', map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.weight',\n",
       "              tensor([[-1.2274e-01,  2.7886e-01, -3.8850e-01,  ..., -1.0404e-01,\n",
       "                        1.9580e-02,  1.8548e-01],\n",
       "                      [ 1.4854e-05, -2.3424e-05,  1.9693e-05,  ...,  2.1349e-05,\n",
       "                        2.1776e-05, -1.2394e-05],\n",
       "                      [ 1.8070e-01,  1.5874e+00, -1.1738e-01,  ..., -4.5935e-02,\n",
       "                       -8.1352e-02,  1.8054e-01],\n",
       "                      ...,\n",
       "                      [-1.8595e-03, -6.8529e-03,  1.6999e-03,  ...,  1.7039e-03,\n",
       "                        4.1632e-03, -1.3171e-03],\n",
       "                      [-2.3120e-03, -6.9001e-03,  1.8772e-03,  ...,  5.0309e-04,\n",
       "                        4.6596e-03, -2.5850e-03],\n",
       "                      [-2.2463e-03, -9.1512e-03,  1.3927e-03,  ...,  1.2296e-03,\n",
       "                        5.8085e-03, -1.8940e-03]])),\n",
       "             ('encoder_with_dropout.embed.weight',\n",
       "              tensor([[-1.2274e-01,  2.7886e-01, -3.8850e-01,  ..., -1.0404e-01,\n",
       "                        1.9580e-02,  1.8548e-01],\n",
       "                      [ 1.4854e-05, -2.3424e-05,  1.9693e-05,  ...,  2.1349e-05,\n",
       "                        2.1776e-05, -1.2394e-05],\n",
       "                      [ 1.8070e-01,  1.5874e+00, -1.1738e-01,  ..., -4.5935e-02,\n",
       "                       -8.1352e-02,  1.8054e-01],\n",
       "                      ...,\n",
       "                      [-1.8595e-03, -6.8529e-03,  1.6999e-03,  ...,  1.7039e-03,\n",
       "                        4.1632e-03, -1.3171e-03],\n",
       "                      [-2.3120e-03, -6.9001e-03,  1.8772e-03,  ...,  5.0309e-04,\n",
       "                        4.6596e-03, -2.5850e-03],\n",
       "                      [-2.2463e-03, -9.1512e-03,  1.3927e-03,  ...,  1.2296e-03,\n",
       "                        5.8085e-03, -1.8940e-03]])),\n",
       "             ('rnns.0.module.weight_ih_l0',\n",
       "              tensor([[-0.0812, -0.0811, -0.0937,  ..., -0.0259, -0.1403, -0.3247],\n",
       "                      [ 0.1154,  0.1142,  0.0938,  ..., -0.0711,  0.1669, -0.0387],\n",
       "                      [-0.0051,  0.1007,  0.2071,  ..., -0.0860, -0.0288, -0.0894],\n",
       "                      ...,\n",
       "                      [ 0.0055,  0.0157,  0.2990,  ...,  0.0616,  0.1159, -0.4737],\n",
       "                      [ 0.0181,  0.0426,  0.1130,  ...,  0.3529, -0.0114, -0.0125],\n",
       "                      [-0.0167, -0.1328,  0.1741,  ...,  0.0548, -0.0045,  0.1688]])),\n",
       "             ('rnns.0.module.bias_ih_l0',\n",
       "              tensor([ 0.1503, -0.4701, -0.1885,  ..., -0.5919, -0.2172, -0.1207])),\n",
       "             ('rnns.0.module.bias_hh_l0',\n",
       "              tensor([ 0.1503, -0.4701, -0.1885,  ..., -0.5919, -0.2172, -0.1207])),\n",
       "             ('rnns.0.module.weight_hh_l0_raw',\n",
       "              tensor([[-0.1013,  0.1786, -0.0528,  ...,  0.0741,  0.0306,  0.2467],\n",
       "                      [ 0.1780, -0.0853, -0.0243,  ..., -0.1129, -0.1310, -0.1498],\n",
       "                      [ 0.0661, -0.0496,  0.0921,  ...,  0.1829,  0.0533, -0.1525],\n",
       "                      ...,\n",
       "                      [-0.0322, -0.0704,  0.1653,  ...,  0.2142, -0.0558,  0.0315],\n",
       "                      [-0.1651, -0.0290,  0.1748,  ..., -0.0446,  0.5444,  0.0616],\n",
       "                      [ 0.0905, -0.1704, -0.0053,  ..., -0.0057,  0.2269,  0.0328]])),\n",
       "             ('rnns.1.module.weight_ih_l0',\n",
       "              tensor([[ 0.3307,  0.0385,  0.0860,  ...,  0.0685, -0.0444,  0.0539],\n",
       "                      [ 0.0720,  0.1607,  0.0562,  ...,  0.0276,  0.0613,  0.1632],\n",
       "                      [-0.1565, -0.1168,  0.1897,  ..., -0.0357,  0.0296,  0.0961],\n",
       "                      ...,\n",
       "                      [-0.0897, -0.1464, -0.0760,  ...,  0.0536,  0.0422, -0.0580],\n",
       "                      [ 0.1166, -0.1534, -0.1784,  ..., -0.0689,  0.2170,  0.1461],\n",
       "                      [-0.0413,  0.0689,  0.0581,  ..., -0.0640, -0.1703, -0.0945]])),\n",
       "             ('rnns.1.module.bias_ih_l0',\n",
       "              tensor([-0.8577, -0.6784, -0.7249,  ..., -0.6782,  0.0567, -0.5026])),\n",
       "             ('rnns.1.module.bias_hh_l0',\n",
       "              tensor([-0.8577, -0.6784, -0.7249,  ..., -0.6782,  0.0567, -0.5026])),\n",
       "             ('rnns.1.module.weight_hh_l0_raw',\n",
       "              tensor([[-0.0273, -0.2277,  0.0782,  ...,  0.1355, -0.1282,  0.1669],\n",
       "                      [ 0.1218,  0.0017, -0.0998,  ..., -0.2085, -0.0686, -0.1389],\n",
       "                      [-0.3878, -0.0498, -0.1748,  ..., -0.4014,  0.1986, -0.4400],\n",
       "                      ...,\n",
       "                      [-0.2097, -0.4298,  0.3551,  ...,  0.0316, -0.1198,  0.1266],\n",
       "                      [ 0.0037, -0.0223,  0.0032,  ..., -0.2672, -0.3093, -0.0361],\n",
       "                      [-0.0464,  0.1664, -0.1348,  ...,  0.1600, -0.1138,  0.0845]])),\n",
       "             ('rnns.2.module.weight_ih_l0',\n",
       "              tensor([[-0.0741,  0.0447, -0.0744,  ..., -0.0419,  0.1600, -0.0553],\n",
       "                      [ 0.0270,  0.0118,  0.0449,  ...,  0.1165, -0.1080, -0.0681],\n",
       "                      [-0.1023, -0.1662, -0.0229,  ...,  0.1652, -0.1070,  0.0970],\n",
       "                      ...,\n",
       "                      [-0.0989, -0.4425, -0.0343,  ..., -0.1434,  0.5851, -0.0291],\n",
       "                      [ 0.0802, -0.1067,  0.2789,  ..., -0.0916, -0.2240,  0.1020],\n",
       "                      [-0.4078,  0.7220,  0.1142,  ...,  0.5287,  0.2035, -0.1811]])),\n",
       "             ('rnns.2.module.bias_ih_l0',\n",
       "              tensor([-0.3681, -0.9079, -0.1998,  ...,  0.8533,  0.3202,  1.2172])),\n",
       "             ('rnns.2.module.bias_hh_l0',\n",
       "              tensor([-0.3681, -0.9079, -0.1998,  ...,  0.8533,  0.3202,  1.2172])),\n",
       "             ('rnns.2.module.weight_hh_l0_raw',\n",
       "              tensor([[-0.0966,  0.0236, -0.0152,  ...,  0.0388, -0.0531, -0.0395],\n",
       "                      [-0.0328, -0.2217,  0.0028,  ...,  0.0143, -0.0368, -0.0085],\n",
       "                      [ 0.0167, -0.0081, -0.0561,  ...,  0.0125,  0.0442, -0.0139],\n",
       "                      ...,\n",
       "                      [-0.0212, -0.1034, -0.0106,  ..., -0.0561,  0.0200, -0.0157],\n",
       "                      [ 0.0183,  0.0364, -0.0251,  ..., -0.0240, -0.1150,  0.0046],\n",
       "                      [ 0.0100, -0.1824,  0.1076,  ..., -0.0269,  0.2733,  0.1846]]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos2=pickle.load(open(f'{PATH_AWD_LSTM}/itos_wt103.pkl','rb'))\n",
    "stoi2 = collections.defaultdict(lambda: -1, { v: k for k, v in enumerate(itos2) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([238462, 400])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wgts = wgts['encoder.weight'].numpy() # converts np.ndarray from torch.FloatTensor.output shape: (238462, 400)\n",
    "row_m = enc_wgts.mean(0) # returns the average of the array elements along axis 0. output shape: (400,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((238462, 400), 59972)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_wgts.shape, len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_emb=enc_wgts.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_w = np.zeros((len(itos),n_emb), dtype=np.float32) # shape: (60002, 400)\n",
    "\n",
    "for i, w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r >= 0 else row_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8910"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(itos).difference(set(itos2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp=len(itos)\n",
    "n_emb=400 #650\n",
    "n_hidden=400 #650\n",
    "n_layers=2\n",
    "dropout=0.2\n",
    "wd=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class language_model (nn.Module):\n",
    "    def __init__(self,n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,pretrain_mtx=None,adaptive_log_softmax=True,tie_weights=True):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device,self.pretrain_mtx=\\\n",
    "                            n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,pretrain_mtx\n",
    "        self.adaptive_log_softmax,self.tie_weights=adaptive_log_softmax,tie_weights\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        self.gen_hidden()\n",
    "        self.create_architecture()\n",
    "        if pretrain_mtx is not None:\n",
    "            print (\"initializing\")\n",
    "            self.initialize_glove()\n",
    "            \n",
    "        if self.adaptive_log_softmax is False:\n",
    "            self.criterion=nn.CrossEntropyLoss()\n",
    "        \n",
    "    def create_architecture(self):\n",
    "        # Dropout layer\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        # Embedding Layer\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb)\n",
    "        # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=False)\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        if self.adaptive_log_softmax:\n",
    "            # Adaptive Log Softmax Loss\n",
    "            self.adaptive_softmax=AdaptiveLogSoftmaxWithLoss(self.n_hidden,\n",
    "                                    self.n_inp,\n",
    "                                    cutoffs=[round(self.n_inp/15),3*round(self.n_inp/15)],\n",
    "                                    div_value=4,\n",
    "                                    get_full_prob=True)\n",
    "        else:\n",
    "            self.decoder=nn.Linear(self.n_hidden,self.n_inp)\n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=False\n",
    "        if self.tie_weights:\n",
    "            self.decoder.weight.requires_grad=False\n",
    "        \n",
    "    \n",
    "    def unfreeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=True\n",
    "        if self.tie_weights:\n",
    "            self.decoder.weight.requires_grad=True\n",
    "        \n",
    "    def initialize_glove(self):\n",
    "        self.encoder.weight.data=torch.Tensor(self.pretrain_mtx)\n",
    "        if self.tie_weights:\n",
    "            self.decoder.weight=self.encoder.weight\n",
    "    \n",
    "    def gen_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "        \n",
    "    def forward(self,Xb,Yb):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "        out,new_hidden=self.lstm(embs,self.hidden)\n",
    "        out=self.dropout_op(out)\n",
    "         # Wrap the hidden state in a new tensor without the gradients\n",
    "        self.hidden=(Variable(new_hidden[0].data,requires_grad=False).to(self.device),\\\n",
    "                     Variable(new_hidden[1].data,requires_grad=False).to(self.device))\n",
    "        if self.adaptive_log_softmax:\n",
    "            out=out.reshape(out.size(0)*out.size(1),out.size(2))        # output is of shape n_batch * n_seq * n_hidden\n",
    "      \n",
    "            out=self.adaptive_softmax(out,Yb.view(-1))\n",
    "            loss=out.loss\n",
    "            preds=out.output_full\n",
    "        else:\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "            preds=self.decoder(out.contiguous().view(out.size(0)*out.size(1), out.size(2)))\n",
    "            loss=self.criterion(preds,Yb.contiguous().view(-1))\n",
    "\n",
    "        return preds, loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multinomial(preds,actual):\n",
    "    preds=preds.max(1)[1]\n",
    "    correct=preds==actual\n",
    "    return correct.float().sum()/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing\n"
     ]
    }
   ],
   "source": [
    "device=\"cuda:0\"\n",
    "model=language_model(n_inp,n_emb,n_hidden,n_layers,False,bs,device,0.05,0.25,0.25,new_w,False,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59972, 400)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59972, 400]), torch.Size([59972, 400]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.weight.data.shape,model.decoder.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59972, 400]), 400, 59972)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(n_hidden,n_inp).weight.data.shape, n_hidden, n_inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if model forward works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59972, 400]), torch.Size([59972, 400]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.weight.shape,model.encoder.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 70)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==0:\n",
    "    model.forward(torch.LongTensor(x),torch.LongTensor(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "\n",
    "    \n",
    "    def fit (self,Xb,Yb,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds,loss=self.model(Xb,Yb)\n",
    "        \n",
    "       \n",
    "            \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc=self.metric_fn(preds,Yb.view(-1))\n",
    "            acc=acc.item()\n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.25)\n",
    "            if 1==0:\n",
    "                for p in self.model.parameters():\n",
    "                    p.data.add_(self.lr, p.grad.data)\n",
    "        \n",
    "        return myloss, acc\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        n_batch=iterator.shape[1]\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        self.model.gen_hidden()\n",
    "        #for k,i in enumerate(range(0,n_batch,self.bptt)):\n",
    "        n_batch=iterator.shape[1]\n",
    "        while i<n_batch-bptt:\n",
    "            if mode_train:\n",
    "                cust_bptt=self.bptt if np.random.random() < 0.95 else self.bptt//np.random.randint (2,4)\n",
    "            else:\n",
    "                cust_bptt=bptt\n",
    "            seq_len=min(cust_bptt,n_batch-1-i)\n",
    "            Xb=train_tokens[:,i:i+seq_len]\n",
    "            Yb=train_tokens[:,i+1:i+1+seq_len]\n",
    "            Xb=torch.LongTensor(Xb)\n",
    "            Yb=torch.LongTensor(Yb)\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc=self.fit(Xb,Yb,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  {epoch_acc/(k)}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "            k=k+1\n",
    "            i=i+seq_len\n",
    "        epoch_loss=epoch_loss/k\n",
    "        epoch_acc=epoch_acc/k\n",
    "        \n",
    "        if 1==0:\n",
    "            lr /= 4.0\n",
    "            # Freeze all the layers initially\n",
    "            for param in resnet.parameters():\n",
    "                param.requires_grad=False\n",
    "            torch.save(resnet,'resnet')\n",
    "            torch.save(resnet.state_dict(),'resnet_state_dict')\n",
    "            resnet.load_state_dict(torch.load('resnet_state_dict'))\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr  \n",
    "            \n",
    "        return epoch_loss,epoch_acc\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "    \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            loss,acc=self.run_epoch(dltrain,True)\n",
    "            print (f'Epoch:{epoch} Loss:{loss}')\n",
    "            lossv,accv=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Loss:{loss} Accuracy:{acc} Loss:{lossv} Accuracy:{accv}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "metric_fn=accuracy_multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5667"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batch=np.int(np.ceil(train_tokens.shape[1]/bptt))\n",
    "n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.weight.requires_grad, model.decoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model,optimizer,accuracy_multinomial,device,bptt,500,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59972"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 6.4186923856735225  0.1256440096916631\n",
      "Batch:1000 5.975013018608093  0.1428456595451571\n",
      "Batch:1500 5.703111585299174  0.15750889422899733\n",
      "Batch:2000 5.522894755125046  0.17147609517280943\n",
      "Batch:2500 5.402414136695862  0.18100878104809673\n",
      "Batch:3000 5.318031203905742  0.1877163416664116\n",
      "Batch:3500 5.254208151136126  0.19282243491669318\n",
      "Batch:4000 5.203129969477653  0.19697120873781387\n",
      "Batch:4500 5.163327643182543  0.20024992004502565\n",
      "Batch:5000 5.131113591957092  0.20301871568681673\n",
      "Batch:5500 5.103157820268111  0.20546087148895656\n",
      "Epoch:0 Loss:5.086213410995549\n",
      "Batch:500 4.631790215492249  0.24965495628118514\n",
      "Epoch:0 Loss:5.086213410995549 Accuracy:0.20681632462081542 Loss:4.622790627122115 Accuracy:0.24897340615020033\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 4.822180908203125  0.23166522961854935\n",
      "Batch:1000 4.816756655216217  0.23130953197181225\n",
      "Batch:1500 4.8144236154556275  0.2312667663494746\n",
      "Batch:2000 4.811392104864121  0.231457393810153\n",
      "Batch:2500 4.808410526275635  0.23159412576556207\n",
      "Batch:3000 4.807046829064687  0.23170385818680128\n",
      "Batch:3500 4.8042004195622035  0.231917307811124\n",
      "Batch:4000 4.8003717069625855  0.23227731432765722\n",
      "Batch:4500 4.798418300098843  0.23243337718645732\n",
      "Batch:5000 4.797634657287598  0.23259801009893416\n",
      "Batch:5500 4.795557430527427  0.23288895350423727\n",
      "Epoch:0 Loss:4.793212692277114\n",
      "Batch:500 4.593199374198914  0.2548681422173977\n",
      "Epoch:0 Loss:4.793212692277114 Accuracy:0.23301714043248878 Loss:4.584325109752552 Accuracy:0.2541598856591722\n",
      "Batch:500 4.781205368041992  0.23690770462155342\n",
      "Batch:1000 4.77642805814743  0.23609374105930328\n",
      "Batch:1500 4.776681967099508  0.23588988294204077\n",
      "Batch:2000 4.775143810987473  0.23597905515134335\n",
      "Batch:2500 4.773270655632019  0.23597246767878532\n",
      "Batch:3000 4.772814255714416  0.2359534638275703\n",
      "Batch:3500 4.771457904270717  0.23604299180848257\n",
      "Batch:4000 4.7687360228300095  0.2362470614798367\n",
      "Batch:4500 4.767899984147814  0.236258067763514\n",
      "Batch:5000 4.767861588573456  0.2363126993328333\n",
      "Batch:5500 4.766690572131764  0.2365026439157399\n",
      "Epoch:1 Loss:4.76489449422519\n",
      "Batch:500 4.576147096633911  0.25647968155145645\n",
      "Epoch:1 Loss:4.76489449422519 Accuracy:0.2365577341838521 Loss:4.567306888921029 Accuracy:0.25577844356140644\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr']=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 4.733539869308472  0.24251291117072105\n",
      "Batch:1000 4.719546927928924  0.24291519297659397\n",
      "Batch:1500 4.7128190304438276  0.2432057686348756\n",
      "Batch:2000 4.707510038852692  0.24350628813356162\n",
      "Batch:2500 4.70116847076416  0.24382904130220412\n",
      "Batch:3000 4.697382926940918  0.24412565616269907\n",
      "Batch:3500 4.693041769163949  0.2444696547644479\n",
      "Batch:4000 4.687445062637329  0.24490681042149662\n",
      "Batch:4500 4.683736782709757  0.24518179152078098\n",
      "Batch:5000 4.681049967861176  0.24541851072609425\n",
      "Batch:5500 4.6771268238587815  0.24581626212867824\n",
      "Epoch:0 Loss:4.67342630883851\n",
      "Batch:500 4.467592614173889  0.2683994608819485\n",
      "Epoch:0 Loss:4.67342630883851 Accuracy:0.2460255659976863 Loss:4.458752728725354 Accuracy:0.26772132413714317\n",
      "Batch:500 4.661553425788879  0.24950868251919747\n",
      "Batch:1000 4.657487545967102  0.24878116242587567\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-eb63cbf2de36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-0f9fa68fffdc>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(self, dltrain, dlvalid, n_epochs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch:{epoch} Loss:{loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mlossv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-0f9fa68fffdc>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, iterator, mode_train, lrs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-0f9fa68fffdc>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Xb, Yb, mode_train)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mmyloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr']=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f'{PATH}/inter/varybptt_model_state_dict_freeze')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/varybptt_learner_state_dict_freeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(f'{PATH}/inter/varybptt_model_state_dict'))\n",
    "#optimizer.load_state_dict(torch.load(f'{PATH}/inter/varybptt_learner_state_dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.weight.requires_grad, model.decoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 4.806624510765076  0.24196685341000557\n",
      "Batch:1000 4.757751633644104  0.24493252439796925\n",
      "Batch:1500 4.726561160087585  0.24686977541446686\n",
      "Batch:2000 4.701271289825439  0.24833283469825984\n",
      "Batch:2500 4.67970911693573  0.24951352741122246\n",
      "Batch:3000 4.6627134453455605  0.2503829180995623\n",
      "Batch:3500 4.646721647671291  0.2512773364995207\n",
      "Batch:4000 4.63151394546032  0.2521417151428759\n",
      "Batch:4500 4.61914976978302  0.2528052290976048\n",
      "Batch:5000 4.608692124557495  0.25340674981176853\n",
      "Batch:5500 4.597938516790217  0.25405117465149274\n",
      "Epoch:0 Loss:4.590262610365019\n",
      "Batch:500 4.204100080490113  0.2859588055610657\n",
      "Epoch:0 Loss:4.590262610365019 Accuracy:0.25438765124873686 Loss:4.196222264230537 Accuracy:0.2853120703256111\n",
      "Batch:500 4.470796348571778  0.26236842864751814\n",
      "Batch:1000 4.461713090896606  0.2621190260797739\n",
      "Batch:1500 4.457737143834432  0.26209192782640456\n",
      "Batch:2000 4.4526124441623685  0.26223397482186556\n",
      "Batch:2500 4.447095703887939  0.26240997207760813\n",
      "Batch:3000 4.443782367706299  0.26251464229325455\n",
      "Batch:3500 4.438993614060538  0.2627221998700074\n",
      "Batch:4000 4.433551677703857  0.2630441156364977\n",
      "Batch:4500 4.429845869912041  0.26321742279993166\n",
      "Batch:5000 4.426886752510071  0.2634201177716255\n",
      "Batch:5500 4.423111534812234  0.2636699751182036\n",
      "Epoch:1 Loss:4.419759635735605\n",
      "Batch:500 4.108376214504242  0.29170001500844955\n",
      "Epoch:1 Loss:4.419759635735605 Accuracy:0.26378592228407066 Loss:4.100756528845244 Accuracy:0.291002872077662\n",
      "Batch:500 4.3788408889770505  0.26766869229078294\n",
      "Batch:1000 4.3727482695579525  0.26731443947553635\n",
      "Batch:1500 4.371161871592204  0.2671469842195511\n",
      "Batch:2000 4.368796796321869  0.26703101832419635\n",
      "Batch:2500 4.3655730228424074  0.2670563504874706\n",
      "Batch:3000 4.364254941304525  0.26706026269992195\n",
      "Batch:3500 4.3613425989151  0.2671969012405191\n",
      "Batch:4000 4.3579596754312515  0.2673635494597256\n",
      "Batch:4500 4.355692935307821  0.2674740215374364\n",
      "Batch:5000 4.3545710787773135  0.2675703781336546\n",
      "Batch:5500 4.35225024617802  0.26777414481206374\n",
      "Epoch:2 Loss:4.349648758052413\n",
      "Batch:500 4.056341802120209  0.29500935584306714\n",
      "Epoch:2 Loss:4.349648758052413 Accuracy:0.2678544117217804 Loss:4.049037373997568 Accuracy:0.2942513776928234\n",
      "Batch:500 4.328897950172425  0.27084898319840434\n",
      "Batch:1000 4.324340566635132  0.27054403798282145\n",
      "Batch:1500 4.322892963091532  0.2701875640153885\n",
      "Batch:2000 4.321435386180878  0.27014778862148525\n",
      "Batch:2500 4.318935326385498  0.2701011473834515\n",
      "Batch:3000 4.317546785354614  0.2700865527242422\n",
      "Batch:3500 4.315811557497297  0.27015376769219124\n",
      "Batch:4000 4.313083138346672  0.2703137823604047\n",
      "Batch:4500 4.311254047817654  0.27041650174061455\n",
      "Batch:5000 4.310779796123505  0.2704955501794815\n",
      "Batch:5500 4.30879505668987  0.27067000989751383\n",
      "Epoch:3 Loss:4.306850930102792\n",
      "Batch:500 4.017507787227631  0.29787199318408963\n",
      "Epoch:3 Loss:4.306850930102792 Accuracy:0.2706844251834678 Loss:4.010078301650295 Accuracy:0.29710466491928894\n",
      "Batch:500 4.297663486480713  0.2725612385869026\n",
      "Batch:1000 4.292426213741303  0.2721673184037209\n",
      "Batch:1500 4.291604610761007  0.2719864338934422\n",
      "Batch:2000 4.290885041952134  0.27188512782752516\n",
      "Batch:2500 4.288046681594849  0.2719975693643093\n",
      "Batch:3000 4.287751198768616  0.27198991351326307\n",
      "Batch:3500 4.286345299312047  0.2720456355554717\n",
      "Batch:4000 4.283743646264076  0.2721816608160734\n",
      "Batch:4500 4.2823403520584105  0.2722617296046681\n",
      "Batch:5000 4.282127714443207  0.2723150154083967\n",
      "Batch:5500 4.28062946024808  0.27248400925235317\n",
      "Epoch:4 Loss:4.27853357333325\n",
      "Batch:500 3.990110990524292  0.29978023570775986\n",
      "Epoch:4 Loss:4.27853357333325 Accuracy:0.27253108141584914 Loss:3.9828650875334914 Accuracy:0.29901109248447266\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f'{PATH}/inter/varybptt_model_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/varybptt_learner_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 4.272457369804382  0.27471615970134733\n",
      "Batch:1000 4.267559949874878  0.2740515992343426\n",
      "Batch:1500 4.267114808082581  0.273838185886542\n",
      "Batch:2000 4.266339130401612  0.27369468961656096\n",
      "Batch:2500 4.264564046478272  0.2736269864797592\n",
      "Batch:3000 4.264817505757014  0.27352512232462567\n",
      "Batch:3500 4.263663566112518  0.27356928267223496\n",
      "Batch:4000 4.2613649269938465  0.27369629619270563\n",
      "Batch:4500 4.2601746790674  0.2737410924302207\n",
      "Batch:5000 4.259788099336624  0.273805964243412\n",
      "Batch:5500 4.258415932611985  0.27396675740317866\n",
      "Epoch:0 Loss:4.256667076612103\n",
      "Batch:500 3.9689039225578306  0.3013489162325859\n",
      "Epoch:0 Loss:4.256667076612103 Accuracy:0.273989359056968 Loss:3.961688128004424 Accuracy:0.30059371971817866\n",
      "Batch:500 4.253802610397339  0.27625672483444214\n",
      "Batch:1000 4.250454862594604  0.27541374777257444\n",
      "Batch:1500 4.250013441085815  0.27510657292604446\n",
      "Batch:2000 4.249407567024231  0.2749712665230036\n",
      "Batch:2500 4.247304359817505  0.27495967178344727\n",
      "Batch:3000 4.247195794423421  0.274863102282087\n",
      "Batch:3500 4.24618313053676  0.2748695626727172\n",
      "Batch:4000 4.243960322082042  0.2749848773442209\n",
      "Batch:4500 4.243036764939626  0.2750378621485498\n",
      "Batch:5000 4.243082191705704  0.27506922042965887\n",
      "Batch:5500 4.2419904574914415  0.2752121121666648\n",
      "Epoch:1 Loss:4.240278755393175\n",
      "Batch:500 3.9520465602874757  0.30264232331514357\n",
      "Epoch:1 Loss:4.240278755393175 Accuracy:0.2752433113100102 Loss:3.944761323396479 Accuracy:0.301952887379952\n",
      "Batch:500 4.239076951503754  0.2771598777770996\n",
      "Batch:1000 4.23432679438591  0.2766323816180229\n",
      "Batch:1500 4.233935835997263  0.27618479416767755\n",
      "Batch:2000 4.233508265137672  0.2759946126192808\n",
      "Batch:2500 4.232122252845764  0.2759773790240288\n",
      "Batch:3000 4.232022822856903  0.27589611760775246\n",
      "Batch:3500 4.231081019605909  0.2759532228410244\n",
      "Batch:4000 4.22871005320549  0.276118856895715\n",
      "Batch:4500 4.228083292961121  0.27614211462603677\n",
      "Batch:5000 4.228097224617004  0.27617864250540736\n",
      "Batch:5500 4.227032048008659  0.2763124988837676\n",
      "Epoch:2 Loss:4.225445387842401\n",
      "Batch:500 3.9349311981201174  0.3038978179693222\n",
      "Epoch:2 Loss:4.225445387842401 Accuracy:0.27632103363331456 Loss:3.9279118858075788 Accuracy:0.30318455058231686\n",
      "Batch:500 4.226143006324768  0.2779093765616417\n",
      "Batch:1000 4.221716035366058  0.2774207476079464\n",
      "Batch:1500 4.221846985975901  0.2770303668777148\n",
      "Batch:2000 4.221687261462211  0.2769131388068199\n",
      "Batch:2500 4.220388352394104  0.2768854345321655\n",
      "Batch:3000 4.221015781084697  0.27673689257601897\n",
      "Batch:3500 4.220111707006182  0.2767437970340252\n",
      "Batch:4000 4.218281571447849  0.27682766934111713\n",
      "Batch:4500 4.217256110032399  0.27693317254053224\n",
      "Batch:5000 4.217394009256363  0.2769365908533335\n",
      "Batch:5500 4.216481361215765  0.27708352609656073\n",
      "Epoch:3 Loss:4.2147807567460776\n",
      "Batch:500 3.9233791794776915  0.30484726798534395\n",
      "Epoch:3 Loss:4.2147807567460776 Accuracy:0.27709500366020334 Loss:3.916422138563944 Accuracy:0.30416514842133774\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f'{PATH}/inter/varybptt_model_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/varybptt_learner_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 4.215587013244629  0.2790443264245987\n",
      "Batch:1000 4.212339537620545  0.2783490325063467\n",
      "Batch:1500 4.21223117129008  0.2779750633140405\n",
      "Batch:2000 4.212278420805931  0.2777671938613057\n",
      "Batch:2500 4.2109540965080265  0.27770000673532486\n",
      "Batch:3000 4.211227813800176  0.2775996452718973\n",
      "Batch:3500 4.210249499525343  0.27761185379964964\n",
      "Batch:4000 4.20857752674818  0.2777071903422475\n",
      "Batch:4500 4.207921216752794  0.27771874876817065\n",
      "Batch:5000 4.208143178653717  0.2777416648209095\n",
      "Batch:5500 4.207130738258362  0.27786863873221657\n",
      "Epoch:0 Loss:4.205581469679631\n",
      "Batch:500 3.912629920005798  0.305733531832695\n",
      "Epoch:0 Loss:4.205581469679631 Accuracy:0.2779049221745413 Loss:3.905625071822171 Accuracy:0.3050169282172475\n",
      "Batch:500 4.207696530342102  0.27951427340507506\n",
      "Batch:1000 4.2041611847877505  0.27889167445898055\n",
      "Batch:1500 4.203369742393494  0.2785125058889389\n",
      "Batch:2000 4.202742716908455  0.27842603901028634\n",
      "Batch:2500 4.201797800922394  0.2782968729197979\n",
      "Batch:3000 4.201788281202316  0.27823682116468745\n",
      "Batch:3500 4.201248368127006  0.27826603478193285\n",
      "Batch:4000 4.1993636204600335  0.2783723334223032\n",
      "Batch:4500 4.198441207196978  0.2783921842707528\n",
      "Batch:5000 4.198783425045013  0.278440078830719\n",
      "Batch:5500 4.197885664853183  0.27853972228548746\n",
      "Epoch:1 Loss:4.19641857244614\n",
      "Batch:500 3.9039217467308043  0.30628902626037596\n",
      "Epoch:1 Loss:4.19641857244614 Accuracy:0.27856392449441336 Loss:3.8968654408979644 Accuracy:0.30559617385529636\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.40244910553017, 48.91088652373189)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.9), np.exp(3.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.02279096040995"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(4.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f'{PATH}/inter/varybptt_model_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/varybptt_learner_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type language_model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save (model,f'{PATH}/inter/varybptt_model_awd_lstm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save (optimizer,f'{PATH}/inter/varybptt_optimizer_awd_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save (learner,f'{PATH}/inter/varybptt_learner_awd_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(f'{PATH}/inter/varybptt_model_awd_lstm')\n",
    "optimizer=torch.load(f'{PATH}/inter/varybptt_optimizer_awd_lstm')\n",
    "learner=torch.load(f'{PATH}/inter/varybptt_learner_awd_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.print_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.print_every=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr']=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:5000 4.191555965566635  0.27895016501545905\n",
      "Epoch:0 Loss:4.189279972732312\n",
      "Epoch:0 Loss:4.189279972732312 Accuracy:0.279056860735352 Loss:3.888390183258665 Accuracy:0.30639143109891975\n",
      "Batch:5000 4.184880942630768  0.2795264025002718\n",
      "Epoch:1 Loss:4.182591495435438\n",
      "Epoch:1 Loss:4.182591495435438 Accuracy:0.27964237154797217 Loss:3.8800614541797547 Accuracy:0.30709379854384794\n",
      "Batch:5000 4.178718735313415  0.28009060700237753\n",
      "Epoch:2 Loss:4.1765148642944965\n",
      "Epoch:2 Loss:4.1765148642944965 Accuracy:0.2802164892245033 Loss:3.875843460670118 Accuracy:0.3074640429666358\n",
      "Batch:5000 4.174020307207107  0.28042426459491254\n",
      "Epoch:3 Loss:4.171807640145708\n",
      "Epoch:3 Loss:4.171807640145708 Accuracy:0.28055680217117523 Loss:3.867707792841837 Accuracy:0.3082054058710734\n",
      "Batch:5000 4.168868962335586  0.28084619493186475\n",
      "Epoch:4 Loss:4.166873217077107\n",
      "Epoch:4 Loss:4.166873217077107 Accuracy:0.2809790029380946 Loss:3.862522657217972 Accuracy:0.3087119171113679\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr']=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:5000 4.163958197116852  0.2813019690066576\n",
      "Epoch:0 Loss:4.161988633866987\n",
      "Epoch:0 Loss:4.161988633866987 Accuracy:0.28140069496502756 Loss:3.8563619542159913 Accuracy:0.3091684789463664\n",
      "Batch:5000 4.1607256004333495  0.28148320442438124\n",
      "Epoch:1 Loss:4.1586531713490595\n",
      "Epoch:1 Loss:4.1586531713490595 Accuracy:0.2816352815020318 Loss:3.851972371957709 Accuracy:0.3095562481804137\n",
      "Batch:5000 4.157159119272232  0.2818359586745501\n",
      "Epoch:2 Loss:4.15509404706474\n",
      "Epoch:2 Loss:4.15509404706474 Accuracy:0.28194083723833996 Loss:3.8482098567999152 Accuracy:0.3098524429581382\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr']=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:5000 4.1534087936401365  0.2821624159812927\n",
      "Epoch:0 Loss:4.151401502357985\n",
      "Epoch:0 Loss:4.151401502357985 Accuracy:0.28225070216188686 Loss:3.8438201752956216 Accuracy:0.3104299358678967\n",
      "Batch:5000 4.150405143165588  0.2824517137289047\n",
      "Epoch:1 Loss:4.148308266302205\n",
      "Epoch:1 Loss:4.148308266302205 Accuracy:0.2825875951728968 Loss:3.840221481460133 Accuracy:0.31043212698026895\n",
      "Batch:5000 4.147210362434387  0.28258621204793455\n",
      "Epoch:2 Loss:4.145364629223815\n",
      "Epoch:2 Loss:4.145364629223815 Accuracy:0.28270174358899774 Loss:3.8401112681940983 Accuracy:0.3103839294476943\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.5254744397892"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr']=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:5000 4.143955935955048  0.2828591864913702\n",
      "Epoch:0 Loss:4.141991081134684\n",
      "Epoch:0 Loss:4.141991081134684 Accuracy:0.2830100399804029 Loss:3.8335480682397383 Accuracy:0.31103152706862636\n",
      "Batch:5000 4.141544650888443  0.28316244994103906\n",
      "Epoch:1 Loss:4.139325787286801\n",
      "Epoch:1 Loss:4.139325787286801 Accuracy:0.28328755290418833 Loss:3.829367069536419 Accuracy:0.31145347419537994\n",
      "Batch:5000 4.1389409245967865  0.2834029611200094\n",
      "Epoch:2 Loss:4.136891617148599\n",
      "Epoch:2 Loss:4.136891617148599 Accuracy:0.28350075740207037 Loss:3.8271600257076526 Accuracy:0.31175098312718635\n",
      "Batch:5000 4.136695261716842  0.2836590170711279\n",
      "Epoch:3 Loss:4.134605913790469\n",
      "Epoch:3 Loss:4.134605913790469 Accuracy:0.2837789879018062 Loss:3.823387879123718 Accuracy:0.31225924695317636\n",
      "Batch:5000 4.134734677839279  0.2838487447053194\n",
      "Epoch:4 Loss:4.13263868183117\n",
      "Epoch:4 Loss:4.13263868183117 Accuracy:0.2839147918542621 Loss:3.8216802617579555 Accuracy:0.31237711128815887\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lm_weights=model.encoder.weight.data.cpu().numpy()\n",
    "pickle.dump(pretrained_lm_weights,open(f'{PATH}/inter/pretrained_lm_weights_varybptt','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:5000 4.132158522224426  0.28400751931071283\n",
      "Epoch:0 Loss:4.130148391361934\n",
      "Epoch:0 Loss:4.130148391361934 Accuracy:0.2841352554543546 Loss:3.8187610376774788 Accuracy:0.31244896963072355\n",
      "Batch:5000 4.130559538078308  0.28417330280840397\n",
      "Epoch:1 Loss:4.128598285223609\n",
      "Epoch:1 Loss:4.128598285223609 Accuracy:0.2842837788839621 Loss:3.816732867102494 Accuracy:0.31269477657153844\n",
      "Batch:5000 4.128701234436035  0.28426859176754954\n",
      "Epoch:2 Loss:4.1267418176231425\n",
      "Epoch:2 Loss:4.1267418176231425 Accuracy:0.28439697716034645 Loss:3.813723863406995 Accuracy:0.3128998342788581\n",
      "Batch:5000 4.127094842720032  0.28455928462445734\n",
      "Epoch:3 Loss:4.125193606277157\n",
      "Epoch:3 Loss:4.125193606277157 Accuracy:0.28466668297768705 Loss:3.8120866023372426 Accuracy:0.31293663943403266\n",
      "Batch:5000 4.126036881113053  0.28458673093020914\n",
      "Epoch:4 Loss:4.123962987545563\n",
      "Epoch:4 Loss:4.123962987545563 Accuracy:0.28469906520134824 Loss:3.811087922806565 Accuracy:0.3132183758550854\n",
      "Batch:5000 4.124003568029404  0.28468038603067397\n",
      "Epoch:5 Loss:4.122069010051502\n",
      "Epoch:5 Loss:4.122069010051502 Accuracy:0.2848030137226039 Loss:3.8088569675336044 Accuracy:0.31316930122162545\n",
      "Batch:5000 4.12226355843544  0.2848144257634878\n",
      "Epoch:6 Loss:4.1201961135178635\n",
      "Epoch:6 Loss:4.1201961135178635 Accuracy:0.28492604693712253 Loss:3.806611385071677 Accuracy:0.31349792054585485\n",
      "Batch:5000 4.120889620447159  0.2849748725265264\n",
      "Epoch:7 Loss:4.118937989184697\n",
      "Epoch:7 Loss:4.118937989184697 Accuracy:0.2850895783088072 Loss:3.8049978514037064 Accuracy:0.3136372549587079\n",
      "Batch:5000 4.119767966365814  0.28508358995914457\n",
      "Epoch:8 Loss:4.117808776172502\n",
      "Epoch:8 Loss:4.117808776172502 Accuracy:0.2852275068788864 Loss:3.8034492691167805 Accuracy:0.3140377315798064\n",
      "Batch:5000 4.1186867268562315  0.28531639195382597\n",
      "Epoch:9 Loss:4.116754889365913\n",
      "Epoch:9 Loss:4.116754889365913 Accuracy:0.2854219247114357 Loss:3.80100355612224 Accuracy:0.31404956181844074\n",
      "Batch:5000 4.116892675304413  0.2853671972304583\n",
      "Epoch:10 Loss:4.1150185067092195\n",
      "Epoch:10 Loss:4.1150185067092195 Accuracy:0.2854694397528831 Loss:3.802301349442161 Accuracy:0.3139387084916828\n",
      "Batch:5000 4.115845063924789  0.28553773456811904\n",
      "Epoch:11 Loss:4.113883330441666\n",
      "Epoch:11 Loss:4.113883330441666 Accuracy:0.2856368891166373 Loss:3.798265044198652 Accuracy:0.3141661118092149\n",
      "Batch:5000 4.1142268591403965  0.28565478194355964\n",
      "Epoch:12 Loss:4.112160600858696\n",
      "Epoch:12 Loss:4.112160600858696 Accuracy:0.2857758883242955 Loss:3.796659355148364 Accuracy:0.31455344313449646\n",
      "Batch:5000 4.113231094932556  0.2857891274511814\n",
      "Epoch:13 Loss:4.111482501804584\n",
      "Epoch:13 Loss:4.111482501804584 Accuracy:0.285875688101867 Loss:3.7962948507859564 Accuracy:0.3146752519280526\n",
      "Batch:5000 4.112294072961808  0.28593157382309436\n",
      "Epoch:14 Loss:4.110318387134279\n",
      "Epoch:14 Loss:4.110318387134279 Accuracy:0.2860327402308642 Loss:3.795229650570445 Accuracy:0.3146231115529792\n",
      "Batch:5000 4.111072478342057  0.2859205156236887\n",
      "Epoch:15 Loss:4.109203749137531\n",
      "Epoch:15 Loss:4.109203749137531 Accuracy:0.2860608601603822 Loss:3.7954063099917423 Accuracy:0.3143663502385932\n",
      "Batch:5000 4.110539411735535  0.2860456876665354\n",
      "Epoch:16 Loss:4.108539176449438\n",
      "Epoch:16 Loss:4.108539176449438 Accuracy:0.28615906874226305 Loss:3.7924105710390084 Accuracy:0.3147703318409562\n",
      "Batch:5000 4.109485911989212  0.28607895802855493\n",
      "Epoch:17 Loss:4.107602957134906\n",
      "Epoch:17 Loss:4.107602957134906 Accuracy:0.286201471571888 Loss:3.7926494900309486 Accuracy:0.31482159696887746\n",
      "Batch:5000 4.108063845062256  0.286207242667675\n",
      "Epoch:18 Loss:4.106112171085804\n",
      "Epoch:18 Loss:4.106112171085804 Accuracy:0.28631428013854865 Loss:3.790254113016326 Accuracy:0.315095445328352\n",
      "Batch:5000 4.107683492422104  0.2862692828387022\n",
      "Epoch:19 Loss:4.105641352251095\n",
      "Epoch:19 Loss:4.105641352251095 Accuracy:0.28640857663765984 Loss:3.788327004920923 Accuracy:0.31520761404501385\n",
      "Batch:5000 4.106135518503189  0.2864964970767498\n",
      "Epoch:20 Loss:4.104171581251952\n",
      "Epoch:20 Loss:4.104171581251952 Accuracy:0.28658079744714404 Loss:3.787097081803439 Accuracy:0.3154323889117872\n",
      "Batch:5000 4.105278205537796  0.28653811230659487\n",
      "Epoch:21 Loss:4.103326514980135\n",
      "Epoch:21 Loss:4.103326514980135 Accuracy:0.2866499302803634 Loss:3.7868344209601053 Accuracy:0.31528604406108884\n",
      "Batch:5000 4.104375666999817  0.2866173478782177\n",
      "Epoch:22 Loss:4.102521067723834\n",
      "Epoch:22 Loss:4.102521067723834 Accuracy:0.28672490185763944 Loss:3.784596004364403 Accuracy:0.31554850161170656\n",
      "Batch:5000 4.103387032794952  0.2867359121322632\n",
      "Epoch:23 Loss:4.101400494800539\n",
      "Epoch:23 Loss:4.101400494800539 Accuracy:0.2868354007875365 Loss:3.78438535223357 Accuracy:0.3157592553175998\n",
      "Batch:5000 4.103178753709793  0.2865749256521463\n",
      "Epoch:24 Loss:4.101230822175858\n",
      "Epoch:24 Loss:4.101230822175858 Accuracy:0.2867233804541052 Loss:3.7842180097692513 Accuracy:0.3158070143710293\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lm_weights=model.encoder.weight.data.cpu().numpy()\n",
    "pickle.dump(pretrained_lm_weights,open(f'{PATH}/inter/pretrained_lm_weights_varybptt_final','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type language_model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(),f'{PATH}/inter/varybptt_model_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/varybptt_learner_state_dict')\n",
    "torch.save (model,f'{PATH}/inter/varybptt_model_awd_lstm')\n",
    "torch.save (optimizer,f'{PATH}/inter/varybptt_optimizer_awd_lstm')\n",
    "torch.save (learner,f'{PATH}/inter/varybptt_learner_awd_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.81604173557396"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
