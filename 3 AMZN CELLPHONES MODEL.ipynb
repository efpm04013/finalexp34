{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os \n",
    "import fastai\n",
    "import fastai\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/home/kirana/Documents/phd\"\n",
    "DATAPATH=\"/home/kirana/Documents/phd/data/experiment/cellphoneaccessory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_train,df_valid,itos, train_tokens, valid_tokens, trn_lm, val_lm]=pickle.load(open(f'{DATAPATH}/inter/dfs_tokens_fastai.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dstype</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110215</th>\n",
       "      <td>Good quality, after 3 charges doubles duration...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, good, quality, ...</td>\n",
       "      <td>[18, 19, 20, 17, 2, 58, 106, 6, 125, 140, 283,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16078</th>\n",
       "      <td>THIS THING IS NOT WORTH THE WAIT AS WELL AS AN...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxup, this, xxup, thin...</td>\n",
       "      <td>[18, 19, 20, 17, 13, 12, 13, 162, 13, 11, 13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45386</th>\n",
       "      <td>This case looks great but i dont like the fact...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, this, case, loo...</td>\n",
       "      <td>[18, 19, 20, 17, 2, 12, 27, 148, 42, 29, 5, 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63069</th>\n",
       "      <td>I've seen some reviews that complain about the...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, seen, some, re...</td>\n",
       "      <td>[18, 19, 20, 17, 5, 115, 659, 107, 365, 21, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96949</th>\n",
       "      <td>These are incredible and install without fuss ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, these, are, inc...</td>\n",
       "      <td>[18, 19, 20, 17, 2, 88, 40, 1299, 8, 445, 147,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label dstype  \\\n",
       "110215  Good quality, after 3 charges doubles duration...      0   test   \n",
       "16078   THIS THING IS NOT WORTH THE WAIT AS WELL AS AN...      1   test   \n",
       "45386   This case looks great but i dont like the fact...      1  train   \n",
       "63069   I've seen some reviews that complain about the...      0  train   \n",
       "96949   These are incredible and install without fuss ...      0   test   \n",
       "\n",
       "                                                    words  \\\n",
       "110215  [ \\n , xxbos, xxfld, 1, xxmaj, good, quality, ...   \n",
       "16078   [ \\n , xxbos, xxfld, 1, xxup, this, xxup, thin...   \n",
       "45386   [ \\n , xxbos, xxfld, 1, xxmaj, this, case, loo...   \n",
       "63069   [ \\n , xxbos, xxfld, 1, i, 've, seen, some, re...   \n",
       "96949   [ \\n , xxbos, xxfld, 1, xxmaj, these, are, inc...   \n",
       "\n",
       "                                                   tokens  \n",
       "110215  [18, 19, 20, 17, 2, 58, 106, 6, 125, 140, 283,...  \n",
       "16078   [18, 19, 20, 17, 13, 12, 13, 162, 13, 11, 13, ...  \n",
       "45386   [18, 19, 20, 17, 2, 12, 27, 148, 42, 29, 5, 49...  \n",
       "63069   [18, 19, 20, 17, 5, 115, 659, 107, 365, 21, 11...  \n",
       "96949   [18, 19, 20, 17, 2, 88, 40, 1299, 8, 445, 147,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df_train,df_valid],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    86500\n",
       "test     86500\n",
       "Name: dstype, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dstype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df.loc[df['dstype']!='test']\n",
    "df_test=df.loc[df['dstype']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86500, 5), (86500, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dstype</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45386</th>\n",
       "      <td>This case looks great but i dont like the fact...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, this, case, loo...</td>\n",
       "      <td>[18, 19, 20, 17, 2, 12, 27, 148, 42, 29, 5, 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63069</th>\n",
       "      <td>I've seen some reviews that complain about the...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, seen, some, re...</td>\n",
       "      <td>[18, 19, 20, 17, 5, 115, 659, 107, 365, 21, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>The charger came with all of the correct Motor...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, the, charger, c...</td>\n",
       "      <td>[18, 19, 20, 17, 2, 4, 78, 200, 25, 55, 14, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122285</th>\n",
       "      <td>MediaDevil is my *go-to* screen protector. You...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, mediadevil, is, my, *,...</td>\n",
       "      <td>[18, 19, 20, 17, 5672, 11, 16, 280, 160, 36, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22017</th>\n",
       "      <td>i purchased this and loved it.. its so pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, purchased, this, an...</td>\n",
       "      <td>[18, 19, 20, 17, 5, 248, 12, 8, 569, 7, 322, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label dstype  \\\n",
       "45386   This case looks great but i dont like the fact...      1  train   \n",
       "63069   I've seen some reviews that complain about the...      0  train   \n",
       "3441    The charger came with all of the correct Motor...      0  train   \n",
       "122285  MediaDevil is my *go-to* screen protector. You...      0  train   \n",
       "22017   i purchased this and loved it.. its so pretty ...      0  train   \n",
       "\n",
       "                                                    words  \\\n",
       "45386   [ \\n , xxbos, xxfld, 1, xxmaj, this, case, loo...   \n",
       "63069   [ \\n , xxbos, xxfld, 1, i, 've, seen, some, re...   \n",
       "3441    [ \\n , xxbos, xxfld, 1, xxmaj, the, charger, c...   \n",
       "122285  [ \\n , xxbos, xxfld, 1, mediadevil, is, my, *,...   \n",
       "22017   [ \\n , xxbos, xxfld, 1, i, purchased, this, an...   \n",
       "\n",
       "                                                   tokens  \n",
       "45386   [18, 19, 20, 17, 2, 12, 27, 148, 42, 29, 5, 49...  \n",
       "63069   [18, 19, 20, 17, 5, 115, 659, 107, 365, 21, 11...  \n",
       "3441    [18, 19, 20, 17, 2, 4, 78, 200, 25, 55, 14, 4,...  \n",
       "122285  [18, 19, 20, 17, 5672, 11, 16, 280, 160, 36, 1...  \n",
       "22017   [18, 19, 20, 17, 5, 248, 12, 8, 569, 7, 322, 1...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=52 # 52 - Jeremey, 20 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt= 70 #70 - Jeremey, 35 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dstype</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45386</th>\n",
       "      <td>This case looks great but i dont like the fact...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, this, case, loo...</td>\n",
       "      <td>[18, 19, 20, 17, 2, 12, 27, 148, 42, 29, 5, 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63069</th>\n",
       "      <td>I've seen some reviews that complain about the...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, seen, some, re...</td>\n",
       "      <td>[18, 19, 20, 17, 5, 115, 659, 107, 365, 21, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>The charger came with all of the correct Motor...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, the, charger, c...</td>\n",
       "      <td>[18, 19, 20, 17, 2, 4, 78, 200, 25, 55, 14, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122285</th>\n",
       "      <td>MediaDevil is my *go-to* screen protector. You...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, mediadevil, is, my, *,...</td>\n",
       "      <td>[18, 19, 20, 17, 5672, 11, 16, 280, 160, 36, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22017</th>\n",
       "      <td>i purchased this and loved it.. its so pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, purchased, this, an...</td>\n",
       "      <td>[18, 19, 20, 17, 5, 248, 12, 8, 569, 7, 322, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label dstype  \\\n",
       "45386   This case looks great but i dont like the fact...      1  train   \n",
       "63069   I've seen some reviews that complain about the...      0  train   \n",
       "3441    The charger came with all of the correct Motor...      0  train   \n",
       "122285  MediaDevil is my *go-to* screen protector. You...      0  train   \n",
       "22017   i purchased this and loved it.. its so pretty ...      0  train   \n",
       "\n",
       "                                                    words  \\\n",
       "45386   [ \\n , xxbos, xxfld, 1, xxmaj, this, case, loo...   \n",
       "63069   [ \\n , xxbos, xxfld, 1, i, 've, seen, some, re...   \n",
       "3441    [ \\n , xxbos, xxfld, 1, xxmaj, the, charger, c...   \n",
       "122285  [ \\n , xxbos, xxfld, 1, mediadevil, is, my, *,...   \n",
       "22017   [ \\n , xxbos, xxfld, 1, i, purchased, this, an...   \n",
       "\n",
       "                                                   tokens  \n",
       "45386   [18, 19, 20, 17, 2, 12, 27, 148, 42, 29, 5, 49...  \n",
       "63069   [18, 19, 20, 17, 5, 115, 659, 107, 365, 21, 11...  \n",
       "3441    [18, 19, 20, 17, 2, 4, 78, 200, 25, 55, 14, 4,...  \n",
       "122285  [18, 19, 20, 17, 5672, 11, 16, 280, 160, 36, 1...  \n",
       "22017   [18, 19, 20, 17, 5, 248, 12, 8, 569, 7, 322, 1...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    74329\n",
       "1    12171\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14873\n",
       "1     2427\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', '.', 'the']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "padlen=1400\n",
    "padding_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['n_tok']=df_train['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    86500.000000\n",
       "mean       116.635734\n",
       "std        171.919658\n",
       "min          5.000000\n",
       "25%         38.000000\n",
       "50%         62.000000\n",
       "75%        125.000000\n",
       "max       5867.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['n_tok']=df_valid['tokens'].apply(len)\n",
    "df_valid.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/kirana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_test['n_tok']=df_test['tokens'].apply(len)\n",
    "df_test.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[18. 19. 20. 17. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    x=df_train['tokens'].values[i]\n",
    "    y=df_train['label'].values[i]    \n",
    "    out=np.ones(padlen)\n",
    "    if len(x) < padlen:\n",
    "        out[:len(x)]=x\n",
    "    else:\n",
    "        out=x[:padlen]\n",
    "    print (out)\n",
    "    print (y)\n",
    "    print (len(out))\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86500, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    74329\n",
       " 1    12171\n",
       " Name: label, dtype: int64, 0    14873\n",
       " 1     2427\n",
       " Name: label, dtype: int64, 0    74328\n",
       " 1    12172\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts(), df_valid['label'].value_counts(),df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86500, 6), (17300, 6))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_sentiment (Dataset):\n",
    "    def __init__ (self,df,bs,padlen=64,xvar='tokens',yvar='label',len_var='n_tok',padding_idx=1):\n",
    "        self.x,self.y,self.padlen,self.padding_idx,self.len_var,self.bs=\\\n",
    "            df[xvar],df[yvar],padlen,padding_idx,df[len_var],bs\n",
    "        self.len_var=self.len_var.clip(0,padlen)\n",
    "    \n",
    "    def pad (self,x):\n",
    "        out=np.ones(self.padlen)*self.padding_idx\n",
    "        out=out.astype(int)\n",
    "        if len(x)>=self.padlen:\n",
    "            out[:]=x[:self.padlen]\n",
    "        else:\n",
    "            out[:len(x)]=x\n",
    "        return out\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        return self.pad(self.x.iloc[idx]),self.y.iloc[idx],self.len_var.iloc[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padlen=max(df_train['n_tok'])\n",
    "padlen=1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=ds_sentiment(df_train,bs,padlen)\n",
    "dsvalid=ds_sentiment(df_valid,bs,padlen)\n",
    "dstest=ds_sentiment(df_test,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain=DataLoader(dstrain,bs,True)\n",
    "dlvalid=DataLoader(dsvalid,bs,False)\n",
    "dltest=DataLoader(dstest,bs,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb,yb,xlen in dltrain:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[18, 19, 20,  ...,  1,  1,  1],\n",
       "         [18, 19, 20,  ...,  1,  1,  1],\n",
       "         [18, 19, 20,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [18, 19, 20,  ...,  1,  1,  1],\n",
       "         [18, 19, 20,  ...,  1,  1,  1],\n",
       "         [18, 19, 20,  ...,  1,  1,  1]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " tensor([ 77,  98, 353,  61,  92,  32,  34, 206, 183,  64, 183, 174,  33,  38,\n",
       "         158, 351,  74,  70, 452,  27,  48,  69, 142,  66,  73,  68, 396,  45,\n",
       "          31, 100, 143,  28,  52, 214,  67, 221,  32,  24,  83,  44, 255,  37,\n",
       "          51,  83,  65,  85,  36,  58,  83,  58,  54, 176]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb, xlen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cyclical learning rates\n",
    "\tvary learning rate by epoch between two values\n",
    "\t\n",
    "\n",
    "bptt=70\n",
    "n_emb=400\n",
    "n_hid=1150\n",
    "n_layers=3\n",
    "bs=48 # whatever is the max that can fit in memory\n",
    "\n",
    "# shuffle dataset\n",
    "# sort the data by length\n",
    "\n",
    "\n",
    "class ds_sentiment(Dataset):\n",
    "\tdef __init__(self,x,y):\n",
    "\t\tself.x,self.y=x,y\n",
    "\t\n",
    "\tdef __getitem__(self,idx):\n",
    "\t\treturn self.x[idx],self.y[idx]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 70)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp=len(itos)\n",
    "n_emb=400 #650\n",
    "n_hidden=400#400\n",
    "n_layers= 2 # 2\n",
    "dropout=0.5 # 0.5\n",
    "wd=1e-7\n",
    "bidirectional=True\n",
    "dropout_e=0.2 # 0.5 - changing to 0.4, 0.3 or any dropout value did not make much difference\n",
    "dropout_o=0.5 #0.5\n",
    "n_out=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 1400]), torch.Size([52]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape,xlen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    74329\n",
       "1    12171\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', '.', 'the']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 8])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool1d(5)\n",
    "input = torch.randn(1, 64, 8)\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_classifier (nn.Module):\n",
    "    def __init__(self,n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,pretrain_mtx=None,n_out=1,padding_idx=1,n_filters=100,filter_sizes=[3,4,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device,self.pretrain_mtx,self.padding_idx=\\\n",
    "                            n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,pretrain_mtx,padding_idx\n",
    "        self.n_out,self.n_filters,self.filter_sizes=n_out,n_filters,filter_sizes\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        \n",
    "        self.create_architecture()\n",
    "        if pretrain_mtx is not None:\n",
    "            print (f'initializing glove with {pretrain_mtx.shape}')\n",
    "            self.initialize_glove()\n",
    "        self.init_hidden()\n",
    "        self.criterion=nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def set_dropouts(self, dropout, dropout_o, dropout_e):\n",
    "        self.dropout, self.dropout_o, self.dropout_e = dropout, dropout_o, dropout_e\n",
    "    \n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=False\n",
    "         \n",
    "    def unfreeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=True\n",
    "\n",
    "    def initialize_glove(self):\n",
    "        self.encoder.weight.data.copy_(torch.Tensor(self.pretrain_mtx))\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "\n",
    "    def create_architecture(self):\n",
    "        ###################################\n",
    "        # Embedding layer - common to both\n",
    "        ###################################\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb,padding_idx=self.padding_idx)\n",
    "        \n",
    "        #######################################\n",
    "        # For RNN #############################\n",
    "        #######################################\n",
    "        # Embedding Layer: Embedding layer just maps each word to an index. n_inp to n_emb mapping is all it does\n",
    "            # input to this is of shape n_batch * n_seq\n",
    "         # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "          # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        self.avg_pool1d=torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool1d=torch.nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "    \n",
    "        #######################################\n",
    "        # For CNN #############################\n",
    "        #######################################    \n",
    "        #embedding dimension is the \"depth\" of the filter and the number of tokens in the sentence is the width.\n",
    "        self.conv_0=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[0])\n",
    "        self.conv_1=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[1])\n",
    "        self.conv_2=torch.nn.Conv1d(self.n_emb,self.n_filters,kernel_size=self.filter_sizes[2])\n",
    "        \n",
    "        self.fc=nn.Linear(len(self.filter_sizes)*self.n_filters+self.n_hidden*4,self.n_out)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward (self,Xb,Yb,Xb_lengths):\n",
    "        \n",
    "        ####RNN PORTION\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "        packed_embs = pack_padded_sequence(embs,Xb_lengths,batch_first=True, enforce_sorted=False)\n",
    "        lstm_out,(hidden,cell)=self.lstm(packed_embs)\n",
    "        lstm_out,lengths=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "        hidden = self.dropout_op(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        avg_pool=self.avg_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        max_pool=self.max_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        \n",
    "        #CNN Portion\n",
    "        new_embs=embs.permute(0,2,1)        \n",
    "        conved_0=torch.relu(self.conv_0(new_embs))\n",
    "        conved_1=torch.relu(self.conv_1(new_embs))\n",
    "        conved_2=torch.relu(self.conv_2(new_embs)) \n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_0.shape[2])\n",
    "        pooled_0=max_pool1d(conved_0).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_1.shape[2])\n",
    "        pooled_1=max_pool1d(conved_1).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_2.shape[2])\n",
    "        pooled_2=max_pool1d(conved_2).squeeze(2)\n",
    "        cat_cnn = self.dropout_op(torch.cat([pooled_0,pooled_1,pooled_2],dim=1))\n",
    "        \n",
    "        ## Concatenate\n",
    "        big_out=torch.cat([cat_cnn,hidden,max_pool],dim=1)\n",
    "        preds=self.fc(big_out)\n",
    "\n",
    "        loss=self.criterion(preds,Yb.contiguous().float().view(-1,1))\n",
    "\n",
    "        \n",
    "        return preds.view(-1),loss\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds,actual, device=\"cpu\", cutoff=0.5):\n",
    "    preds=torch.sigmoid(preds)\n",
    "    zeros=torch.zeros(len(preds)).to(device)\n",
    "    ones = torch.ones(len(preds)).to(device)\n",
    "\n",
    "    preds=torch.where(preds>cutoff,ones,zeros)\n",
    "    correct=torch.round(preds).long()==actual\n",
    "    return correct.float().sum()/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds, y, device=\"cpu\", cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    y=y.float()\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lm_weights=pickle.load(open(f'{DATAPATH}/inter/varybpttpretrained_lm_weights_unfreeze','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if model forward works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30238, 400, 400, 2, True, 52, 'cpu', 0.2, 0.5, 0.5, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout_o,dropout,n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (30238, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=dropout_e,dropout=dropout,\\\n",
    "                 dropout_o=dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 18,990,201 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model_sentiment):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_classifier(\n",
       "  (dropout_enc): Dropout(p=0.2)\n",
       "  (encoder): Embedding(30238, 400, padding_idx=1)\n",
       "  (lstm): LSTM(400, 400, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout_op): Dropout(p=0.5)\n",
       "  (avg_pool1d): AdaptiveAvgPool1d(output_size=1)\n",
       "  (max_pool1d): AdaptiveMaxPool1d(output_size=1)\n",
       "  (conv_0): Conv1d(400, 100, kernel_size=(3,), stride=(1,))\n",
       "  (conv_1): Conv1d(400, 100, kernel_size=(4,), stride=(1,))\n",
       "  (conv_2): Conv1d(400, 100, kernel_size=(5,), stride=(1,))\n",
       "  (fc): Linear(in_features=1900, out_features=1, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1038, -0.1617,  0.4763,  0.1031,  0.5394, -0.0359, -0.0891, -0.0819,\n",
       "          0.0914,  0.2321, -0.1753,  0.1504,  0.1881,  0.0576,  0.1359,  0.3349,\n",
       "         -0.0198,  0.0853,  0.0948,  0.0360,  0.2663, -0.1731,  0.0191,  0.0171,\n",
       "         -0.1178,  0.2249,  0.2731,  0.0598,  0.1792,  0.1288, -0.0159, -0.0210,\n",
       "          0.1913, -0.2608, -0.0144, -0.3651,  0.0881, -0.0331,  0.0551, -0.0612,\n",
       "         -0.0864,  0.2334,  0.1120, -0.0632,  0.0744, -0.1690,  0.1217,  0.3580,\n",
       "          0.1299,  0.0166,  0.0316,  0.0595], grad_fn=<ViewBackward>),\n",
       " tensor(0.7294, grad_fn=<BinaryCrossEntropyWithLogitsBackward>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,loss=model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0186, -0.0136, -0.0394,  0.3853,  0.3903,  0.0111,  0.1027, -0.4606,\n",
       "         0.3577,  0.1939,  0.4739,  0.0445,  0.0780, -0.0223, -0.0019,  0.0445,\n",
       "         0.1595,  0.2407,  0.2614,  0.2101,  0.0490, -0.1715, -0.1226,  0.1104,\n",
       "         0.1200, -0.2724, -0.3210,  0.1809,  0.1269,  0.1004,  0.1300,  0.0332,\n",
       "         0.1341,  0.1872, -0.0517, -0.3960, -0.0151,  0.0647, -0.0291, -0.0498,\n",
       "         0.0244,  0.1217,  0.0850,  0.1081, -0.1186,  0.4414, -0.0540, -0.2426,\n",
       "        -0.0486, -0.1957,  0.0390,  0.2643], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3846)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_binomial(preds.to(device),yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5782312925170068"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yb,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.096664,  0.068908, -0.026539,  0.145172, ...,  0.017248,  0.058272, -0.04472 , -0.068174],\n",
       "       [-0.073669, -0.021713,  0.121824, -0.061521, ..., -0.144361,  0.072465, -0.00783 , -0.0527  ],\n",
       "       [ 0.016913, -0.092459, -0.205166,  0.193297, ...,  0.012541,  0.087248,  0.136005,  0.118961],\n",
       "       [ 0.151758,  0.590315,  0.002815,  0.07636 , ...,  0.053235,  0.03477 , -0.463683,  0.170703],\n",
       "       ...,\n",
       "       [-0.076562, -0.043897,  0.025359, -0.080075, ..., -0.00668 ,  0.143226,  0.024018, -0.079905],\n",
       "       [-0.057223,  0.01818 ,  0.105571, -0.002987, ..., -0.118653,  0.09541 ,  0.104183,  0.028903],\n",
       "       [-0.083589, -0.046181,  0.077349, -0.037635, ..., -0.14745 ,  0.130461,  0.051213, -0.123047],\n",
       "       [-0.072408,  0.012531,  0.070828, -0.003311, ..., -0.061846,  0.097159, -0.050633, -0.060115]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_lm_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1e-07\n",
      "1 6e-07\n",
      "2 3.6e-06\n",
      "3 2.16e-05\n",
      "4 0.0001296\n",
      "5 0.0007776\n"
     ]
    }
   ],
   "source": [
    "# Weight Decay Schedule\n",
    "tempstart=1e-7\n",
    "for i in range (6):\n",
    "    print (i, tempstart)\n",
    "    tempstart=tempstart*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.005\n",
      "1 0.005\n",
      "2 0.0034999999999999996\n",
      "3 0.0017149999999999995\n",
      "4 0.0005882449999999997\n",
      "5 0.0001412376244999999\n"
     ]
    }
   ],
   "source": [
    "tempstart=5e-3\n",
    "for i in range (6):\n",
    "    print (i, tempstart)\n",
    "    tempstart=tempstart*(0.7**i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1,5,(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=[1e-2,5e-3,1e-4,5e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,4,(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs[torch.randint(0,4,(1,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=0.7,wd_mult=6):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        self.preds,self.preds_valid,self.trainY,self.actual=[],[],[],[]\n",
    "        \n",
    "    def fit (self,Xb,Yb,Xlen,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds,loss=self.model(Xb,Yb,Xlen)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "            acc=acc.item()\n",
    "            \n",
    "            if mode_train:\n",
    "                self.trainY.append(Yb.view(-1))\n",
    "                self.preds.append(preds.data)\n",
    "            else:\n",
    "                self.actual.append(Yb.view(-1))\n",
    "                self.preds_valid.append(preds.data)\n",
    "            \n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        self.model.init_hidden()\n",
    "        for Xb,Yb,Xlen in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            Xlen=Xlen.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc=self.fit(Xb,Yb,Xlen,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  {epoch_acc/(k)}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        \n",
    "        if self.cycle_mult > 0:\n",
    "            reset_cycle=self.cycle_mult\n",
    "        \n",
    "        for epoch in range(n_epochs):                \n",
    "\n",
    "            \n",
    "            loss,acc=self.run_epoch(dltrain,True)\n",
    "            lossv,accv=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss} Train Accuracy:{acc} Valid Loss:{lossv} Valid Accuracy:{accv}')\n",
    "        \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    #self.wd=self.start_wd\n",
    "                    reset_cycle=self.n_epoch+reset_cycle\n",
    "                else:\n",
    "                    self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    if self.n_epoch>1:\n",
    "                        self.wd*=self.wd_mult\n",
    "            self.n_epoch+=1\n",
    "                \n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                #param_group['weight_decay']=self.wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (30238, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout,\\\n",
    "                 dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n",
    "model_sentiment=model_sentiment.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model_sentiment.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "#optimizer=torch.optim.SGD(model_sentiment.parameters(),lr=1e-2,momentum=0.9, weight_decay=wd)\n",
    "metric_fn=accuracy_binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 333)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain),len(dlvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14873\n",
       "1     2427\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model_sentiment,optimizer,accuracy_binomial,device,bptt,100,0.25,cycle_mult=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5, 0.5, 0.2, 0.5, 0.5)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.dropout_e,model_sentiment.dropout,model_sentiment.dropout_o, learner.model.dropout_e,learner.model.dropout,learner.model.dropout_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.41720510229468344  0.8544231115281582\n",
      "Batch:200 0.36757185608148574  0.8652884986251592\n",
      "Batch:300 0.3414945187419653  0.873076960593462\n",
      "Batch:400 0.32591443171724677  0.8773077299818397\n",
      "Batch:500 0.31097005707025527  0.8823846524655818\n",
      "Batch:600 0.3038843103622397  0.8850000370293856\n",
      "Batch:700 0.2969167406431266  0.8867308059547628\n",
      "Batch:800 0.2894515492860228  0.8891827291809022\n",
      "Batch:900 0.2839808928055896  0.8915171311133437\n",
      "Batch:1000 0.27920361544191835  0.8932692681998015\n",
      "Batch:1100 0.274783763885498  0.8949650723690337\n",
      "Batch:1200 0.27080037764584025  0.8965224734321237\n",
      "Batch:1300 0.2685747260714953  0.8972041794772332\n",
      "Batch:1400 0.266121272378202  0.8982417956739664\n",
      "Batch:1500 0.26354200233519076  0.8991923451324304\n",
      "Batch:1600 0.26170703914016485  0.899867826057598\n",
      "Batch:100 0.15108717687427997  0.9359615755081176\n",
      "Batch:200 0.16316380670294164  0.9322115749120712\n",
      "Batch:300 0.17952120245744785  0.9271154214938482\n",
      "Epoch:0 Learning rate 0.005 Weight Decay 1e-07 Train Loss:0.26062318532226175 Train Accuracy:0.9003983673263485 Valid Loss:0.18737881964592784 Valid Accuracy:0.9260542961928222\n",
      "Batch:100 0.22566701084375382  0.914807733297348\n",
      "Batch:200 0.22475122172385453  0.9167308083176613\n",
      "Batch:300 0.22494495230416456  0.9161538857221604\n",
      "Batch:400 0.2264189451187849  0.9158173468708992\n",
      "Batch:500 0.22535987504571675  0.9162692695856094\n",
      "Batch:600 0.2255261054262519  0.9156410644451777\n",
      "Batch:700 0.22700332029057402  0.9148352038860321\n",
      "Batch:800 0.22513214143924415  0.9152885004878044\n",
      "Batch:900 0.22859867173764442  0.9142735430267122\n",
      "Batch:1000 0.22860270708054303  0.9144423468112945\n",
      "Batch:1100 0.22889419650828297  0.9142657736756585\n",
      "Batch:1200 0.22968990790036817  0.914102603594462\n",
      "Batch:1300 0.22955556717343056  0.9137870215911131\n",
      "Batch:1400 0.2302125676561679  0.9134890503117017\n",
      "Batch:1500 0.23022134528557459  0.9134231161276499\n",
      "Batch:1600 0.23018683975096793  0.9136418659612536\n",
      "Batch:100 0.17737561803311108  0.9253846555948257\n",
      "Batch:200 0.18448354713618756  0.9234615781903267\n",
      "Batch:300 0.19419341454903286  0.9215385017792384\n",
      "Epoch:1 Learning rate 0.005 Weight Decay 1e-07 Train Loss:0.2293673206004314 Train Accuracy:0.9140355728495007 Valid Loss:0.1957103442065082 Valid Accuracy:0.9218385450474851\n",
      "Batch:100 0.214919452406466  0.918076965212822\n",
      "Batch:200 0.20841517760418354  0.9215385028719902\n",
      "Batch:300 0.20516821587458253  0.9228205529848734\n",
      "Batch:400 0.20125367565546184  0.9236058087646961\n",
      "Batch:500 0.20305009404197336  0.9237692703008652\n",
      "Batch:600 0.20373980642917255  0.9231410650412242\n",
      "Batch:700 0.20327485776639412  0.9235714679956436\n",
      "Batch:800 0.20383193620713427  0.9229808083921671\n",
      "Batch:900 0.20364734632894396  0.9227778169843885\n",
      "Batch:1000 0.20284463728405536  0.9229231162071228\n",
      "Batch:1100 0.2024751955727962  0.9231993397257545\n",
      "Batch:1200 0.20121673190190145  0.9237820899983247\n",
      "Batch:1300 0.20217894725071697  0.9233432336953971\n",
      "Batch:1400 0.20262060804425605  0.9232417968767029\n",
      "Batch:1500 0.20369236856574813  0.9230769617557526\n",
      "Batch:1600 0.20383783245808446  0.9230168657377362\n",
      "Batch:100 0.1245143473148346  0.9534615707397461\n",
      "Batch:200 0.13384212028235198  0.949903880059719\n",
      "Batch:300 0.14222761154174804  0.9453205464283625\n",
      "Epoch:2 Learning rate 0.0034999999999999996 Weight Decay 1e-07 Train Loss:0.2038653294361071 Train Accuracy:0.9229093860978117 Valid Loss:0.1472595333941169 Valid Accuracy:0.9431547271954762\n",
      "Batch:100 0.19379511948674918  0.923846190571785\n",
      "Batch:200 0.19461071899160742  0.9243269604444504\n",
      "Batch:300 0.19143569132934013  0.9258974734942118\n",
      "Batch:400 0.18898839155212044  0.9273558069765567\n",
      "Batch:500 0.1837074967250228  0.9295000381469727\n",
      "Batch:600 0.18310587918385862  0.930032089650631\n",
      "Batch:700 0.18367635701383864  0.9296703678369522\n",
      "Batch:800 0.18344925923738628  0.9292308074980974\n",
      "Batch:900 0.18284338085187807  0.9294872178634008\n",
      "Batch:1000 0.18148311337828635  0.9301923462748527\n",
      "Batch:1100 0.1801918279955333  0.930821716947989\n",
      "Batch:1200 0.18020390866324307  0.9309135003884633\n",
      "Batch:1300 0.1792617470283921  0.9311242992602862\n",
      "Batch:1400 0.1799043245986104  0.9310302585789135\n",
      "Batch:1500 0.17992355338980753  0.9310256798664729\n",
      "Batch:1600 0.18029011958278715  0.9308053272217512\n",
      "Batch:100 0.12025304581969977  0.9588461875915527\n",
      "Batch:200 0.13013060795143247  0.9542308044433594\n",
      "Batch:300 0.13698428003738325  0.9501282395919164\n",
      "Epoch:3 Learning rate 0.0017149999999999995 Weight Decay 6e-07 Train Loss:0.1800631029428377 Train Accuracy:0.9308740523858712 Valid Loss:0.1400561021590555 Valid Accuracy:0.9483201500173803\n",
      "Batch:100 0.16088782712817193  0.9386538863182068\n",
      "Batch:200 0.16223303537815809  0.9375000390410423\n",
      "Batch:300 0.16446763629714647  0.9369231160481771\n",
      "Batch:400 0.16533727964386344  0.9369231152534485\n",
      "Batch:500 0.16331527056917547  0.9385769612789154\n",
      "Batch:600 0.16340525620616972  0.9380449093381564\n",
      "Batch:700 0.1643492242933384  0.9374450924566814\n",
      "Batch:800 0.16431959099369123  0.937403883561492\n",
      "Batch:900 0.1639329037256539  0.9373290973239475\n",
      "Batch:1000 0.16362222309969365  0.9371538836956024\n",
      "Batch:1100 0.16348236539993774  0.9375000374425542\n",
      "Batch:1200 0.16228283545157562  0.9377564476430416\n",
      "Batch:1300 0.16284744379468835  0.93729293685693\n",
      "Batch:1400 0.16285791146568954  0.9370604772227151\n",
      "Batch:1500 0.16177049017076692  0.9373590120871862\n",
      "Batch:1600 0.16174161582137458  0.9373437875881792\n",
      "Batch:100 0.11347871206700802  0.9584615713357926\n",
      "Batch:200 0.12274073630571365  0.9540384951233863\n",
      "Batch:300 0.12974407008538644  0.9502564444144567\n",
      "Epoch:4 Learning rate 0.0005882449999999997 Weight Decay 3.6e-06 Train Loss:0.1619223403988424 Train Accuracy:0.9371841474651144 Valid Loss:0.13317654096149467 Valid Accuracy:0.9488976502919698\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type sentiment_classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{DATAPATH}/inter/combo_model_dict_freeze')\n",
    "torch.save(optimizer.state_dict(),f'{DATAPATH}/inter/combo_optimizer_dict_freeze')\n",
    "torch.save (model_sentiment,f'{DATAPATH}/inter/combo_model_freeze')\n",
    "torch.save (optimizer,f'{DATAPATH}/inter/combo_optimizer_freeze')\n",
    "torch.save (learner,f'{DATAPATH}/inter/combo_learner_freeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=list(chain.from_iterable(learner.preds))[-df_train.shape[0]:]\n",
    "preds_valid=list(chain.from_iterable(learner.preds_valid))[-df_valid.shape[0]:]\n",
    "trainY=list(chain.from_iterable(learner.trainY))[-df_train.shape[0]:]\n",
    "actual=list(chain.from_iterable(learner.actual))[-df_valid.shape[0]:]\n",
    "preds=[x.item() for x in preds]\n",
    "preds_valid=[x.item() for x in preds_valid]\n",
    "trainY=[x.item() for x in trainY]\n",
    "actual=[x.item() for x in actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.993239042545457, 0.9871992982419396)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(trainY,preds),roc_auc_score(actual,preds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9074205537228046, 0.8904652618401836)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(trainY,np.round(expit(preds))), f1_score(actual,np.round(expit(preds_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9226392663043478, 0.9019442096365173)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(trainY,np.round(expit(preds))), precision_score(actual,np.round(expit(preds_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8926957521978474, 0.8792748248866914)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(trainY,np.round(expit(preds))), recall_score(actual,np.round(expit(preds_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001412376244999999"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model_sentiment,optimizer,accuracy_binomial,device,bptt,100,0.25,cycle_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.14735399410128594  0.9463461875915528\n",
      "Batch:200 0.15444163320586085  0.9433654198050498\n",
      "Batch:300 0.1546646469210585  0.9433333683013916\n",
      "Batch:400 0.15534858888015152  0.9430288815498352\n",
      "Batch:500 0.15498888851329684  0.942653881907463\n",
      "Batch:600 0.15552975428911547  0.9419231126705806\n",
      "Batch:700 0.15585355712633048  0.9417582782677242\n",
      "Batch:800 0.15671150278998539  0.9409375364333391\n",
      "Batch:900 0.15715933291241527  0.94074790014161\n",
      "Batch:1000 0.15680831052549182  0.9405961909890175\n",
      "Batch:1100 0.15661401318047535  0.9406468900225379\n",
      "Batch:1200 0.15589223742485048  0.9407211905221144\n",
      "Batch:1300 0.1559347337885545  0.9410059537795874\n",
      "Batch:1400 0.15584843903779982  0.9411264101096563\n",
      "Batch:1500 0.1548526171023647  0.9413333697319031\n",
      "Batch:1600 0.15571187870111317  0.9410817673057318\n",
      "Batch:100 0.11168353583663702  0.95923080265522\n",
      "Batch:200 0.12000477449968457  0.9554808023571968\n",
      "Batch:300 0.12496210868780812  0.9524359305699667\n",
      "Epoch:0 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.15584358168640533 Train Accuracy:0.941048021070086 Valid Loss:0.12751437323699305 Valid Accuracy:0.9514065681993067\n",
      "Batch:100 0.1489295007660985  0.9423077315092087\n",
      "Batch:200 0.14987134534865618  0.9413461926579475\n",
      "Batch:300 0.15164549745619296  0.9410897819201152\n",
      "Batch:400 0.15130543189123272  0.9406731151044369\n",
      "Batch:500 0.1544228046387434  0.9397308073043823\n",
      "Batch:600 0.15406834218340615  0.9403846536080043\n",
      "Batch:700 0.15109598870788302  0.9418406966754368\n",
      "Batch:800 0.14926702088676394  0.9424279221147299\n",
      "Batch:900 0.14831104718148708  0.9427137127849791\n",
      "Batch:1000 0.14811375335976482  0.9429038838148117\n",
      "Batch:1100 0.1478399568965489  0.9431643733111295\n",
      "Batch:1200 0.14812858118365207  0.9428686273097991\n",
      "Batch:1300 0.14851017826165144  0.9427811024739192\n",
      "Batch:1400 0.14864682390487619  0.9429258615630014\n",
      "Batch:1500 0.14875304600348074  0.942769268155098\n",
      "Batch:1600 0.14764621637295933  0.9431731139868498\n",
      "Batch:100 0.10816771823912859  0.9603846484422683\n",
      "Batch:200 0.11559680802747607  0.9567308017611503\n",
      "Batch:300 0.12106793434669574  0.953461571931839\n",
      "Epoch:1 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.1474929773965134 Train Accuracy:0.9431590915012819 Valid Loss:0.12374577569487216 Valid Accuracy:0.9519840688318819\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{DATAPATH}/inter/combo_model_dict_nofreeze')\n",
    "torch.save(optimizer.state_dict(),f'{DATAPATH}/inter/combo_optimizer_dict_nofreeze')\n",
    "torch.save (model_sentiment,f'{DATAPATH}/inter/combo_model_nofreeze')\n",
    "torch.save (optimizer,f'{DATAPATH}/inter/combo_optimizer_nofreeze')\n",
    "torch.save (learner,f'{DATAPATH}/inter/combo_learner_nofreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.1481987733580172  0.9457692664861679\n",
      "Batch:200 0.1433498420752585  0.9475961899757386\n",
      "Batch:300 0.14029900843277573  0.9484615739186605\n",
      "Batch:400 0.1420077897561714  0.9473077285289765\n",
      "Batch:500 0.14212058156356216  0.9470769592523575\n",
      "Batch:600 0.14230550966225564  0.9469231126705805\n",
      "Batch:700 0.1427850437563445  0.9467308045285089\n",
      "Batch:800 0.14206708617042751  0.9467308043688536\n",
      "Batch:900 0.1420172874712282  0.9468590092658996\n",
      "Batch:1000 0.14130316203460097  0.9471346504092216\n",
      "Batch:1100 0.1422005083665929  0.9469405943697149\n",
      "Batch:1200 0.14250342370942234  0.9468429838120938\n",
      "Batch:1300 0.14240365266799926  0.9468491475857221\n",
      "Batch:1400 0.14232219084032943  0.9467857496227536\n",
      "Batch:1500 0.14237443130960067  0.9464359328349431\n",
      "Batch:1600 0.14247469146503136  0.9463341701403261\n",
      "Batch:100 0.10694715581834316  0.9626923412084579\n",
      "Batch:200 0.11476943859830499  0.9578846490383148\n",
      "Batch:300 0.11936589508627851  0.955384649236997\n",
      "Epoch:0 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.14268420566468892 Train Accuracy:0.9461157437270651 Valid Loss:0.12144886276631563 Valid Accuracy:0.954236321621113\n",
      "Batch:100 0.14642037170007824  0.9461538791656494\n",
      "Batch:200 0.15017450814135372  0.9437500336766242\n",
      "Batch:300 0.14536257329707344  0.9446795217196147\n",
      "Batch:400 0.14386341439094394  0.9450481122732163\n",
      "Batch:500 0.14454851562902332  0.9452308050394058\n",
      "Batch:600 0.14253587761272987  0.9462820866703987\n",
      "Batch:700 0.1417009665923459  0.9465934417077473\n",
      "Batch:800 0.14199329417664558  0.9468029198050499\n",
      "Batch:900 0.14106468748301268  0.9470726848310894\n",
      "Batch:1000 0.14051744464412333  0.947076958656311\n",
      "Batch:1100 0.13971092848784544  0.947342692992904\n",
      "Batch:1200 0.13917596944297353  0.947532086968422\n",
      "Batch:1300 0.13882905335953602  0.9477811007316296\n",
      "Batch:1400 0.1392679596000484  0.947472563300814\n",
      "Batch:1500 0.1396103659371535  0.9473846507867177\n",
      "Batch:1600 0.13995429498143494  0.9474880161508917\n",
      "Batch:100 0.10445479556918144  0.9626923418045044\n",
      "Batch:200 0.11095829894766211  0.9594231095910072\n",
      "Batch:300 0.11586131104578574  0.9562179817756017\n",
      "Epoch:1 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.1394757356879731 Train Accuracy:0.9475545841985598 Valid Loss:0.11789835006692209 Valid Accuracy:0.9550448219339411\n",
      "Batch:100 0.12865492027252912  0.9538461875915527\n",
      "Batch:200 0.12809391090646385  0.9544231116771698\n",
      "Batch:300 0.133485060694317  0.9510256775220235\n",
      "Batch:400 0.13319118423387408  0.9506731133162976\n",
      "Batch:500 0.13369901859015226  0.950230804681778\n",
      "Batch:600 0.13425442262552678  0.9499679849545161\n",
      "Batch:700 0.13495547733136587  0.9494231131247112\n",
      "Batch:800 0.13534748571924865  0.9490384973585606\n",
      "Batch:900 0.1347090322814054  0.9493162752522363\n",
      "Batch:1000 0.13400119699165225  0.9495192666649819\n",
      "Batch:1100 0.13372481034560638  0.9494930428808386\n",
      "Batch:1200 0.1329324939272677  0.9498558049897353\n",
      "Batch:1300 0.13295827232301236  0.9497781422963509\n",
      "Batch:1400 0.13368441486531601  0.9495742115804128\n",
      "Batch:1500 0.13366646404129764  0.9493077280521393\n",
      "Batch:1600 0.13345977588847746  0.9494110932946205\n",
      "Batch:100 0.10311188194900751  0.9671154183149338\n",
      "Batch:200 0.10956494781188666  0.9626923391222953\n",
      "Batch:300 0.11363417128100992  0.9591666992505391\n",
      "Epoch:2 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.13315779240992226 Train Accuracy:0.9495847557957929 Valid Loss:0.11553201850156884 Valid Accuracy:0.9576692405763689\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.save(model_sentiment.state_dict(),f'{DATAPATH}/inter/combo_model_dict_nofreeze')\n",
    "torch.save(optimizer.state_dict(),f'{DATAPATH}/inter/combo_optimizer_dict_nofreeze')\n",
    "torch.save (model_sentiment,f'{DATAPATH}/inter/combo_model_nofreeze')\n",
    "torch.save (optimizer,f'{DATAPATH}/inter/combo_optimizer_nofreeze')\n",
    "torch.save (learner,f'{DATAPATH}/inter/combo_learner_nofreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.11893330838531256  0.950961577296257\n",
      "Batch:200 0.12474063745699823  0.9487500375509262\n",
      "Batch:300 0.1246312196056048  0.9505769594510396\n",
      "Batch:400 0.12652639192994683  0.9499519599974156\n",
      "Batch:500 0.1260271285660565  0.9505384975671768\n",
      "Batch:600 0.12753591419197619  0.9501923436919848\n",
      "Batch:700 0.12659697566447514  0.9507692666564669\n",
      "Batch:800 0.12775272281607614  0.9509375358372927\n",
      "Batch:900 0.12872788649673264  0.9505342239141464\n",
      "Batch:1000 0.1279005470518023  0.9507884972095489\n",
      "Batch:1100 0.12823334855620155  0.950681853890419\n",
      "Batch:1200 0.1281672568929692  0.9507692664861679\n",
      "Batch:1300 0.12848263101938825  0.9508580239002521\n",
      "Batch:1400 0.128067599464474  0.951126409471035\n",
      "Batch:1500 0.12750687605142594  0.9512436254819234\n",
      "Batch:1600 0.12742124902899377  0.9514183047786355\n",
      "Batch:100 0.10042033202946186  0.9669231098890304\n",
      "Batch:200 0.10634249138645828  0.9630769544839859\n",
      "Batch:300 0.1108099785571297  0.9601923390229543\n",
      "Epoch:0 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.12707993854620817 Train Accuracy:0.9515359543908674 Valid Loss:0.1129343207903184 Valid Accuracy:0.9587087405694498\n",
      "Batch:100 0.11098987583070993  0.9598077267408371\n",
      "Batch:200 0.11696871290914715  0.9562500342726707\n",
      "Batch:300 0.11570287787665924  0.9564743934075037\n",
      "Batch:400 0.11717524070758373  0.9566827267408371\n",
      "Batch:500 0.11959731259569525  0.9554615726470947\n",
      "Batch:600 0.12187717371465018  0.9545833679040273\n",
      "Batch:700 0.12235291976614722  0.9542857487712587\n",
      "Batch:800 0.12397446011309513  0.953581765294075\n",
      "Batch:900 0.12375678365532723  0.95401712861326\n",
      "Batch:1000 0.12386620574723929  0.9540192649364472\n",
      "Batch:1100 0.12405220824463124  0.953968565626578\n",
      "Batch:1200 0.1235439234545144  0.9539743931591511\n",
      "Batch:1300 0.12276027964929549  0.954142045883032\n",
      "Batch:1400 0.1221096644836611  0.9543544294578689\n",
      "Batch:1500 0.12237717737319569  0.9543590080738068\n",
      "Batch:1600 0.12192124023393262  0.9543269568309188\n",
      "Batch:100 0.10062239926308393  0.9676923406124115\n",
      "Batch:200 0.1058224606886506  0.9643269547820091\n",
      "Batch:300 0.1092878794359664  0.9612820839881897\n",
      "Epoch:1 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.12223327134751553 Train Accuracy:0.9543481445871294 Valid Loss:0.11111560806229308 Valid Accuracy:0.9601524932248456\n",
      "Batch:100 0.11850976870395243  0.9507692641019821\n",
      "Batch:200 0.12094418349210173  0.9536538794636726\n",
      "Batch:300 0.12060411787591875  0.9540384944279988\n",
      "Batch:400 0.11999302506214007  0.9541346482932568\n",
      "Batch:500 0.11972531968541443  0.9544615714550019\n",
      "Batch:600 0.11959379481927802  0.9541667000452677\n",
      "Batch:700 0.11813403843369867  0.9546978352751051\n",
      "Batch:800 0.11812506769201718  0.954903879314661\n",
      "Batch:900 0.11886476207421058  0.9548077257474263\n",
      "Batch:1000 0.11938432603795081  0.9544808028340339\n",
      "Batch:1100 0.11909358303909275  0.9546154180440036\n",
      "Batch:1200 0.11908139962470159  0.9542628541092077\n",
      "Batch:1300 0.11865235060381775  0.9545562466291281\n",
      "Batch:1400 0.11816075944275196  0.9549176159926823\n",
      "Batch:1500 0.11774828311863045  0.9551538794438045\n",
      "Batch:1600 0.11766402721230407  0.9553606101870536\n",
      "Batch:100 0.09810116693377495  0.9678846484422684\n",
      "Batch:200 0.10393720617517829  0.9643269550800323\n",
      "Batch:300 0.10740123402327299  0.9619231094916662\n",
      "Epoch:2 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.11766413347448598 Train Accuracy:0.9554537593100506 Valid Loss:0.10906990873137931 Valid Accuracy:0.9610508268659895\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{DATAPATH}/inter/combo_model_dict_nofreeze')\n",
    "torch.save(optimizer.state_dict(),f'{DATAPATH}/inter/combo_optimizer_dict_nofreeze')\n",
    "torch.save (model_sentiment,f'{DATAPATH}/inter/combo_model_nofreeze')\n",
    "torch.save (optimizer,f'{DATAPATH}/inter/combo_optimizer_nofreeze')\n",
    "torch.save (learner,f'{DATAPATH}/inter/combo_learner_nofreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.10535536853596568  0.9559615725278854\n",
      "Batch:200 0.10294018262065947  0.9585577276349068\n",
      "Batch:300 0.10768594457457463  0.958012856443723\n",
      "Batch:400 0.1106389448652044  0.95677888199687\n",
      "Batch:500 0.1098244603537023  0.9571923427581787\n",
      "Batch:600 0.11049984733108431  0.957596187988917\n",
      "Batch:700 0.11104100002907216  0.9574450893912997\n",
      "Batch:800 0.10949484838638454  0.9581490724533797\n",
      "Batch:900 0.11059404889018172  0.9577778116861979\n",
      "Batch:1000 0.11026997454557567  0.9581538800001145\n",
      "Batch:1100 0.10925600338303908  0.9584790546243841\n",
      "Batch:1200 0.1093431691483905  0.9585737514992555\n",
      "Batch:1300 0.11000675562625895  0.9581805068254471\n",
      "Batch:1400 0.11010531447960863  0.9582280555793218\n",
      "Batch:1500 0.10955910892039537  0.9583590079545975\n",
      "Batch:1600 0.10944370634679217  0.9583533990010619\n",
      "Batch:100 0.09314460944384337  0.9698077249526977\n",
      "Batch:200 0.0992743373569101  0.9657692623138427\n",
      "Batch:300 0.10297813124954701  0.9641025952498118\n",
      "Epoch:0 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.10997581450646976 Train Accuracy:0.9582197235252422 Valid Loss:0.10486973112857377 Valid Accuracy:0.9633608277853545\n",
      "Batch:100 0.10648858770728112  0.962115415930748\n",
      "Batch:200 0.10681646621786058  0.9596154165267944\n",
      "Batch:300 0.10766321965182821  0.960576954483986\n",
      "Batch:400 0.10605652754195034  0.960913492590189\n",
      "Batch:500 0.10536779271066189  0.9608077239990235\n",
      "Batch:600 0.10492939361060659  0.9610256726543108\n",
      "Batch:700 0.1047014158591628  0.9610439880405154\n",
      "Batch:800 0.10485553820850328  0.9607933010905981\n",
      "Batch:900 0.10429293105378747  0.9608974677986569\n",
      "Batch:1000 0.10440960957668721  0.9604615704417229\n",
      "Batch:1100 0.1046372121521695  0.9604895425384695\n",
      "Batch:1200 0.10493896433773141  0.9604006730516752\n",
      "Batch:1300 0.10444350288894313  0.9606657126316658\n",
      "Batch:1400 0.10414346443489193  0.9607692629098892\n",
      "Batch:1500 0.10417216909428438  0.960641057809194\n",
      "Batch:1600 0.10376939288747962  0.9608173399791121\n",
      "Batch:100 0.08836004985496401  0.9692308002710343\n",
      "Batch:200 0.09273982775397599  0.9667308005690575\n",
      "Batch:300 0.09814547827777763  0.9642949030796687\n",
      "Epoch:1 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.10349986712110247 Train Accuracy:0.9608797473976245 Valid Loss:0.1003516413153963 Valid Accuracy:0.9636752447924456\n",
      "Batch:100 0.0935075047146529  0.965192340016365\n",
      "Batch:200 0.094547865355853  0.9640384951233864\n",
      "Batch:300 0.0929387281043455  0.9649359301726024\n",
      "Batch:400 0.09243426019907929  0.9649519558250904\n",
      "Batch:500 0.09298757053818554  0.9651538783311844\n",
      "Batch:600 0.09349580084361757  0.9653205449382464\n",
      "Batch:700 0.09358608576136508  0.9651648674692427\n",
      "Batch:800 0.0938520527567016  0.9649759937077761\n",
      "Batch:900 0.09434770730893231  0.9648290920257568\n",
      "Batch:1000 0.09477202879311517  0.9647500323653221\n",
      "Batch:1100 0.0958449087143791  0.9641958367824555\n",
      "Batch:1200 0.09566699520568363  0.9642147760589918\n",
      "Batch:1300 0.09597719425084786  0.96415683727998\n",
      "Batch:1400 0.09596312916604802  0.9642170656153134\n",
      "Batch:1500 0.09531049363718679  0.9644615711371104\n",
      "Batch:1600 0.09525422051810892  0.9644591672345996\n",
      "Batch:100 0.0881483736820519  0.9703846448659896\n",
      "Batch:200 0.09370226797647774  0.9671154165267944\n",
      "Batch:300 0.09822123788918058  0.9664743906259536\n",
      "Epoch:2 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.09535954123314766 Train Accuracy:0.9642620827071369 Valid Loss:0.10010705378141489 Valid Accuracy:0.9657542472845083\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{DATAPATH}/inter/combo_model_dict_nofreeze')\n",
    "torch.save(optimizer.state_dict(),f'{DATAPATH}/inter/combo_optimizer_dict_nofreeze')\n",
    "torch.save (model_sentiment,f'{DATAPATH}/inter/combo_model_nofreeze')\n",
    "torch.save (optimizer,f'{DATAPATH}/inter/combo_optimizer_nofreeze')\n",
    "torch.save (learner,f'{DATAPATH}/inter/combo_learner_nofreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.09336921118199826  0.9650000292062759\n",
      "Batch:200 0.08921785645652562  0.9661538755893707\n",
      "Batch:300 0.08965064291531841  0.9653205432494482\n",
      "Batch:400 0.08891484803054482  0.9659134915471077\n",
      "Batch:500 0.08503647636435926  0.9677307990789413\n",
      "Batch:600 0.0868860703210036  0.9671795176466306\n",
      "Batch:700 0.0869460022090269  0.9673351955413818\n",
      "Batch:800 0.08787463970831595  0.9670192617923021\n",
      "Batch:900 0.0877404782641679  0.9672222530841827\n",
      "Batch:1000 0.08740715342666953  0.9671538771390915\n",
      "Batch:1100 0.08672357464124533  0.9673951357061212\n",
      "Batch:1200 0.08651272422401235  0.9673397746185461\n",
      "Batch:1300 0.08623991446569562  0.9674408593544593\n",
      "Batch:1400 0.08659317132950362  0.9674176136084965\n",
      "Batch:1500 0.08648046600818635  0.9673846465746562\n",
      "Batch:1600 0.08641796901123598  0.967283685207367\n",
      "Batch:100 0.08448839819990099  0.9700000303983688\n",
      "Batch:200 0.08841913866344839  0.9679808020591736\n",
      "Batch:300 0.09339533329941332  0.9675641345977783\n",
      "Epoch:0 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.08625945976046541 Train Accuracy:0.9673400829689434 Valid Loss:0.09551864358185379 Valid Accuracy:0.966966998648715\n",
      "Batch:100 0.07608368641696871  0.9700000309944152\n",
      "Batch:200 0.08141598345246166  0.9687500312924385\n",
      "Batch:300 0.07686352257306377  0.9704487490653991\n",
      "Batch:400 0.07560928937979043  0.9708173386752605\n",
      "Batch:500 0.07509654019400477  0.9707308000326157\n",
      "Batch:600 0.07549923804122954  0.9706410561005274\n",
      "Batch:700 0.07598973425504352  0.9709615688664572\n",
      "Batch:800 0.07719045508652926  0.9704807999730111\n",
      "Batch:900 0.07728618922539883  0.970512851079305\n",
      "Batch:1000 0.07770544493105262  0.9705000305771828\n",
      "Batch:1100 0.0774019519447095  0.9706818487969312\n",
      "Batch:1200 0.0766251675299524  0.9709295179446539\n",
      "Batch:1300 0.07683034903047463  0.9709763619991449\n",
      "Batch:1400 0.07666930730687455  0.9708104702404567\n",
      "Batch:1500 0.0768848905361568  0.9707308000326157\n",
      "Batch:1600 0.07692243780620629  0.9707211844995618\n",
      "Batch:100 0.0830565068218857  0.9717308014631272\n",
      "Batch:200 0.08576381682185456  0.9683654177188873\n",
      "Batch:300 0.09087808954684684  0.9680128520727158\n",
      "Epoch:1 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.07705818482953383 Train Accuracy:0.9707724972842977 Valid Loss:0.09294950056893823 Valid Accuracy:0.9674289987251923\n",
      "Batch:100 0.06355274547124282  0.9759615641832352\n",
      "Batch:200 0.06481156292022205  0.975288487970829\n",
      "Batch:300 0.06174596431820343  0.9764743846654892\n",
      "Batch:400 0.06337170079350471  0.9760096417367459\n",
      "Batch:500 0.06709815424494445  0.9748461804389954\n",
      "Batch:600 0.06733689435757696  0.9747756677865982\n",
      "Batch:700 0.06687009964271315  0.9751099165848324\n",
      "Batch:800 0.0667937803507084  0.9751202186942101\n",
      "Batch:900 0.06688717980403452  0.9750854968362385\n",
      "Batch:1000 0.06737570122117177  0.9748654116392136\n",
      "Batch:1100 0.0674306434227831  0.9745979292826219\n",
      "Batch:1200 0.06765773788210935  0.9746154118080934\n",
      "Batch:1300 0.067515842593275  0.9746597904883898\n",
      "Batch:1400 0.06772207000209683  0.9745055217828069\n",
      "Batch:1500 0.06831513049375887  0.9743461813529333\n",
      "Batch:1600 0.06903807699782191  0.9741947390139103\n",
      "Batch:100 0.07987720765639096  0.9746154147386551\n",
      "Batch:200 0.08267277500359342  0.9714423394203187\n",
      "Batch:300 0.08790295179933309  0.9701923384269079\n",
      "Epoch:2 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.0687505937039532 Train Accuracy:0.9743782634345385 Valid Loss:0.0894718857051374 Valid Accuracy:0.9696812506194588\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{DATAPATH}/inter/combo_model_dict_nofreeze')\n",
    "torch.save(optimizer.state_dict(),f'{DATAPATH}/inter/combo_optimizer_dict_nofreeze')\n",
    "torch.save (model_sentiment,f'{DATAPATH}/inter/combo_model_nofreeze')\n",
    "torch.save (optimizer,f'{DATAPATH}/inter/combo_optimizer_nofreeze')\n",
    "torch.save (learner,f'{DATAPATH}/inter/combo_learner_nofreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.06193555163219571  0.9755769520998001\n",
      "Batch:200 0.06371829822193831  0.9755769520998001\n",
      "Batch:300 0.06301001061064501  0.9767949000994365\n",
      "Batch:400 0.06324502192204819  0.9769231052696705\n",
      "Batch:500 0.06228198135923594  0.97719233584404\n",
      "Batch:600 0.060421001594125605  0.9780448992053667\n",
      "Batch:700 0.05941204830438697  0.9779945330108915\n",
      "Batch:800 0.06033933809405426  0.9777884894609451\n",
      "Batch:900 0.06036546212853864  0.977906010945638\n",
      "Batch:1000 0.061074516123975624  0.9776346434354782\n",
      "Batch:1100 0.06074349173693918  0.9779021256078373\n",
      "Batch:1200 0.061080170981682995  0.9777243870000044\n",
      "Batch:1300 0.06102376465802081  0.977633164204084\n",
      "Batch:1400 0.060779998736605716  0.9775961818865367\n",
      "Batch:1500 0.06098924499851031  0.9774487457672755\n",
      "Batch:1600 0.06114639166633424  0.9773798353597521\n",
      "Batch:100 0.07893657001201064  0.9744231045246124\n",
      "Batch:200 0.08190254780696705  0.9720192605257034\n",
      "Batch:300 0.08765519957523793  0.9714102852344513\n",
      "Epoch:0 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.061094661320007265 Train Accuracy:0.9773695883699335 Valid Loss:0.08936027709713525 Valid Accuracy:0.9710095002128555\n",
      "Batch:100 0.049573219022713604  0.9832692521810532\n",
      "Batch:200 0.04996180261252448  0.9821154084801674\n",
      "Batch:300 0.05097435619837294  0.9813461782534917\n",
      "Batch:400 0.05131865158327855  0.9811538711190224\n",
      "Batch:500 0.052804215335287154  0.9804615633487701\n",
      "Batch:600 0.0522925312560983  0.980576947927475\n",
      "Batch:700 0.053443803351505524  0.980109915477889\n",
      "Batch:800 0.05402406028821133  0.9802163720875978\n",
      "Batch:900 0.053891282624358106  0.9801282312472661\n",
      "Batch:1000 0.053986585560953246  0.9801731028556824\n",
      "Batch:1100 0.05370396661995487  0.9804370887712999\n",
      "Batch:1200 0.05382249024696648  0.9803846411903699\n",
      "Batch:1300 0.053655706458510116  0.9803402624680446\n",
      "Batch:1400 0.05341606146040639  0.9803434323838779\n",
      "Batch:1500 0.053262695349364855  0.9804615640242894\n",
      "Batch:1600 0.053056417888365105  0.9805649295449257\n",
      "Batch:100 0.07768482827115804  0.9759615677595138\n",
      "Batch:200 0.07899250929825939  0.9737500298023224\n",
      "Batch:300 0.08660259653270866  0.972500029206276\n",
      "Epoch:1 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.05279596027482442 Train Accuracy:0.980665243911342 Valid Loss:0.08949099861325936 Valid Accuracy:0.9719335014397675\n",
      "Batch:100 0.04785280518000946  0.9834615629911423\n",
      "Batch:200 0.04775516109075397  0.983750023841858\n",
      "Batch:300 0.0447819554056817  0.9845513049761454\n",
      "Batch:400 0.04670525860885391  0.983557716012001\n",
      "Batch:500 0.04596617683279328  0.983615408539772\n",
      "Batch:600 0.046634666694832655  0.9833013063669205\n",
      "Batch:700 0.045941747111501174  0.9835714529241835\n",
      "Batch:800 0.04603917415282922  0.9835096393525601\n",
      "Batch:900 0.04574797416519787  0.9834829300642014\n",
      "Batch:1000 0.04544425877719186  0.9835000240206718\n",
      "Batch:1100 0.045138361020098355  0.9834265974434939\n",
      "Batch:1200 0.04498679571086541  0.9834775880475839\n",
      "Batch:1300 0.04586146207454686  0.983136118879685\n",
      "Batch:1400 0.04611001963261515  0.9830082660913467\n",
      "Batch:1500 0.04642399519907  0.9828846396605174\n",
      "Batch:1600 0.046509819787534074  0.9828365625813603\n",
      "Batch:100 0.0813489683996886  0.9728846430778504\n",
      "Batch:200 0.08988855391275137  0.968942337334156\n",
      "Batch:300 0.10300109143989782  0.9642949036757151\n",
      "Epoch:2 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.046687713574381354 Train Accuracy:0.982824466477793 Valid Loss:0.10477708697084102 Valid Accuracy:0.9637650788367331\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
