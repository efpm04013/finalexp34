{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os \n",
    "import fastai\n",
    "import fastai\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/home/kirana/Documents/phd\"\n",
    "DATAPATH=\"/home/kirana/Documents/phd/data/experiment/YELP_BINARY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_train,df_valid,itos, train_tokens, valid_tokens, trn_lm, val_lm]=pickle.load(open(f'{DATAPATH}/inter/dfs_tokens_fastai.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dstype</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241568</th>\n",
       "      <td>Went tonight, and had an AWFUL time due to a f...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, went, tonight, ...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 118, 1051, 5, 6, 35, 81, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302519</th>\n",
       "      <td>Go. Hurry and go. Mexican food with such an am...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, go, ., xxmaj, h...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 78, 3, 2, 2217, 6, 78, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>I used to love coming to foxy nails, and Missy...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, used, to, love, com...</td>\n",
       "      <td>[28, 29, 30, 25, 7, 323, 8, 141, 368, 8, 27370...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20836</th>\n",
       "      <td>This place has good italian food for phoenix, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, this, place, ha...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 22, 46, 113, 48, 682, 44, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Worst climbing gym I have ever been to. Custom...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, worst, climbing...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 403, 5685, 1174, 7, 34, 17...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label dstype  \\\n",
       "241568  Went tonight, and had an AWFUL time due to a f...      0  train   \n",
       "302519  Go. Hurry and go. Mexican food with such an am...      1  train   \n",
       "7005    I used to love coming to foxy nails, and Missy...      0  train   \n",
       "20836   This place has good italian food for phoenix, ...      0  train   \n",
       "808     Worst climbing gym I have ever been to. Custom...      0  train   \n",
       "\n",
       "                                                    words  \\\n",
       "241568  [ \\n , xxbos, xxfld, 1, xxmaj, went, tonight, ...   \n",
       "302519  [ \\n , xxbos, xxfld, 1, xxmaj, go, ., xxmaj, h...   \n",
       "7005    [ \\n , xxbos, xxfld, 1, i, used, to, love, com...   \n",
       "20836   [ \\n , xxbos, xxfld, 1, xxmaj, this, place, ha...   \n",
       "808     [ \\n , xxbos, xxfld, 1, xxmaj, worst, climbing...   \n",
       "\n",
       "                                                   tokens  \n",
       "241568  [28, 29, 30, 25, 2, 118, 1051, 5, 6, 35, 81, 2...  \n",
       "302519  [28, 29, 30, 25, 2, 78, 3, 2, 2217, 6, 78, 3, ...  \n",
       "7005    [28, 29, 30, 25, 7, 323, 8, 141, 368, 8, 27370...  \n",
       "20836   [28, 29, 30, 25, 2, 22, 46, 113, 48, 682, 44, ...  \n",
       "808     [28, 29, 30, 25, 2, 403, 5685, 1174, 7, 34, 17...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df_train,df_valid],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    560000\n",
       "test      38000\n",
       "Name: dstype, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dstype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df.loc[df['dstype']!='test']\n",
    "df_test=df.loc[df['dstype']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((560000, 5), (38000, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dstype</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241568</th>\n",
       "      <td>Went tonight, and had an AWFUL time due to a f...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, went, tonight, ...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 118, 1051, 5, 6, 35, 81, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302519</th>\n",
       "      <td>Go. Hurry and go. Mexican food with such an am...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, go, ., xxmaj, h...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 78, 3, 2, 2217, 6, 78, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>I used to love coming to foxy nails, and Missy...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, used, to, love, com...</td>\n",
       "      <td>[28, 29, 30, 25, 7, 323, 8, 141, 368, 8, 27370...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20836</th>\n",
       "      <td>This place has good italian food for phoenix, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, this, place, ha...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 22, 46, 113, 48, 682, 44, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Worst climbing gym I have ever been to. Custom...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, worst, climbing...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 403, 5685, 1174, 7, 34, 17...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label dstype  \\\n",
       "241568  Went tonight, and had an AWFUL time due to a f...      0  train   \n",
       "302519  Go. Hurry and go. Mexican food with such an am...      1  train   \n",
       "7005    I used to love coming to foxy nails, and Missy...      0  train   \n",
       "20836   This place has good italian food for phoenix, ...      0  train   \n",
       "808     Worst climbing gym I have ever been to. Custom...      0  train   \n",
       "\n",
       "                                                    words  \\\n",
       "241568  [ \\n , xxbos, xxfld, 1, xxmaj, went, tonight, ...   \n",
       "302519  [ \\n , xxbos, xxfld, 1, xxmaj, go, ., xxmaj, h...   \n",
       "7005    [ \\n , xxbos, xxfld, 1, i, used, to, love, com...   \n",
       "20836   [ \\n , xxbos, xxfld, 1, xxmaj, this, place, ha...   \n",
       "808     [ \\n , xxbos, xxfld, 1, xxmaj, worst, climbing...   \n",
       "\n",
       "                                                   tokens  \n",
       "241568  [28, 29, 30, 25, 2, 118, 1051, 5, 6, 35, 81, 2...  \n",
       "302519  [28, 29, 30, 25, 2, 78, 3, 2, 2217, 6, 78, 3, ...  \n",
       "7005    [28, 29, 30, 25, 7, 323, 8, 141, 368, 8, 27370...  \n",
       "20836   [28, 29, 30, 25, 2, 22, 46, 113, 48, 682, 44, ...  \n",
       "808     [28, 29, 30, 25, 2, 403, 5685, 1174, 7, 34, 17...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=52 # 52 - Jeremey, 20 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt= 70 #70 - Jeremey, 35 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dstype</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241568</th>\n",
       "      <td>Went tonight, and had an AWFUL time due to a f...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, went, tonight, ...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 118, 1051, 5, 6, 35, 81, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302519</th>\n",
       "      <td>Go. Hurry and go. Mexican food with such an am...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, go, ., xxmaj, h...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 78, 3, 2, 2217, 6, 78, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>I used to love coming to foxy nails, and Missy...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, used, to, love, com...</td>\n",
       "      <td>[28, 29, 30, 25, 7, 323, 8, 141, 368, 8, 27370...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20836</th>\n",
       "      <td>This place has good italian food for phoenix, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, this, place, ha...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 22, 46, 113, 48, 682, 44, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Worst climbing gym I have ever been to. Custom...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, worst, climbing...</td>\n",
       "      <td>[28, 29, 30, 25, 2, 403, 5685, 1174, 7, 34, 17...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label dstype  \\\n",
       "241568  Went tonight, and had an AWFUL time due to a f...      0  train   \n",
       "302519  Go. Hurry and go. Mexican food with such an am...      1  train   \n",
       "7005    I used to love coming to foxy nails, and Missy...      0  train   \n",
       "20836   This place has good italian food for phoenix, ...      0  train   \n",
       "808     Worst climbing gym I have ever been to. Custom...      0  train   \n",
       "\n",
       "                                                    words  \\\n",
       "241568  [ \\n , xxbos, xxfld, 1, xxmaj, went, tonight, ...   \n",
       "302519  [ \\n , xxbos, xxfld, 1, xxmaj, go, ., xxmaj, h...   \n",
       "7005    [ \\n , xxbos, xxfld, 1, i, used, to, love, com...   \n",
       "20836   [ \\n , xxbos, xxfld, 1, xxmaj, this, place, ha...   \n",
       "808     [ \\n , xxbos, xxfld, 1, xxmaj, worst, climbing...   \n",
       "\n",
       "                                                   tokens  \n",
       "241568  [28, 29, 30, 25, 2, 118, 1051, 5, 6, 35, 81, 2...  \n",
       "302519  [28, 29, 30, 25, 2, 78, 3, 2, 2217, 6, 78, 3, ...  \n",
       "7005    [28, 29, 30, 25, 7, 323, 8, 141, 368, 8, 27370...  \n",
       "20836   [28, 29, 30, 25, 2, 22, 46, 113, 48, 682, 44, ...  \n",
       "808     [28, 29, 30, 25, 2, 403, 5685, 1174, 7, 34, 17...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    280000\n",
       "0    280000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29986\n",
       "1    29814\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', '.', 'the']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "padlen=1400\n",
    "padding_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['n_tok']=df_train['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    560000.000000\n",
       "mean        174.079913\n",
       "std         156.012100\n",
       "min           5.000000\n",
       "25%          70.000000\n",
       "50%         128.000000\n",
       "75%         225.000000\n",
       "max        1645.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['n_tok']=df_valid['tokens'].apply(len)\n",
    "df_valid.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/kirana/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_test['n_tok']=df_test['tokens'].apply(len)\n",
    "df_test.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[28. 29. 30. 25. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    x=df_train['tokens'].values[i]\n",
    "    y=df_train['label'].values[i]    \n",
    "    out=np.ones(padlen)\n",
    "    if len(x) < padlen:\n",
    "        out[:len(x)]=x\n",
    "    else:\n",
    "        out=x[:padlen]\n",
    "    print (out)\n",
    "    print (y)\n",
    "    print (len(out))\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560000, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    280000\n",
       " 0    280000\n",
       " Name: label, dtype: int64, 0    29986\n",
       " 1    29814\n",
       " Name: label, dtype: int64, 1    19000\n",
       " 0    19000\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts(), df_valid['label'].value_counts(),df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((560000, 6), (59800, 6))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_sentiment (Dataset):\n",
    "    def __init__ (self,df,bs,padlen=64,xvar='tokens',yvar='label',len_var='n_tok',padding_idx=1):\n",
    "        self.x,self.y,self.padlen,self.padding_idx,self.len_var,self.bs=\\\n",
    "            df[xvar],df[yvar],padlen,padding_idx,df[len_var],bs\n",
    "        self.len_var=self.len_var.clip(0,padlen)\n",
    "    \n",
    "    def pad (self,x):\n",
    "        out=np.ones(self.padlen)*self.padding_idx\n",
    "        out=out.astype(int)\n",
    "        if len(x)>=self.padlen:\n",
    "            out[:]=x[:self.padlen]\n",
    "        else:\n",
    "            out[:len(x)]=x\n",
    "        return out\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        return self.pad(self.x.iloc[idx]),self.y.iloc[idx],self.len_var.iloc[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padlen=max(df_train['n_tok'])\n",
    "padlen=1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=ds_sentiment(df_train,bs,padlen)\n",
    "dsvalid=ds_sentiment(df_valid,bs,padlen)\n",
    "dstest=ds_sentiment(df_test,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain=DataLoader(dstrain,bs,True)\n",
    "dlvalid=DataLoader(dsvalid,bs,False)\n",
    "dltest=DataLoader(dstest,bs,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb,yb,xlen in dltrain:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[28, 29, 30,  ...,  1,  1,  1],\n",
       "         [28, 29, 30,  ...,  1,  1,  1],\n",
       "         [28, 29, 30,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [28, 29, 30,  ...,  1,  1,  1],\n",
       "         [28, 29, 30,  ...,  1,  1,  1],\n",
       "         [28, 29, 30,  ...,  1,  1,  1]]),\n",
       " tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "         0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 1]),\n",
       " tensor([285, 131, 129, 454, 155, 160, 365,  80, 288, 358, 418,  45,  17, 654,\n",
       "         104,  32,  27, 175,  20,  58, 147, 288,  69, 156,  46,  75, 244, 104,\n",
       "         154,  96, 315, 143, 168,  71, 350, 206,  41, 138, 211, 111, 130,  57,\n",
       "          42,  30,  41,  21, 206,  38, 119,  49, 228, 229]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb, xlen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cyclical learning rates\n",
    "\tvary learning rate by epoch between two values\n",
    "\t\n",
    "\n",
    "bptt=70\n",
    "n_emb=400\n",
    "n_hid=1150\n",
    "n_layers=3\n",
    "bs=48 # whatever is the max that can fit in memory\n",
    "\n",
    "# shuffle dataset\n",
    "# sort the data by length\n",
    "\n",
    "\n",
    "class ds_sentiment(Dataset):\n",
    "\tdef __init__(self,x,y):\n",
    "\t\tself.x,self.y=x,y\n",
    "\t\n",
    "\tdef __getitem__(self,idx):\n",
    "\t\treturn self.x[idx],self.y[idx]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 70)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp=len(itos)\n",
    "n_emb=400 #650\n",
    "n_hidden=400#400\n",
    "n_layers= 2 # 2\n",
    "dropout=0.5 # 0.5\n",
    "wd=1e-7\n",
    "bidirectional=True\n",
    "dropout_e=0.2 # 0.5 - changing to 0.4, 0.3 or any dropout value did not make much difference\n",
    "dropout_o=0.5 #0.5\n",
    "n_out=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 1400]), torch.Size([52]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape,xlen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    280000\n",
       "0    280000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', '.', 'the']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 8])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool1d(5)\n",
    "input = torch.randn(1, 64, 8)\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_classifier (nn.Module):\n",
    "    def __init__(self,n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,pretrain_mtx=None,n_out=1,padding_idx=1,n_filters=100,filter_sizes=[3,4,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device,self.pretrain_mtx,self.padding_idx=\\\n",
    "                            n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,pretrain_mtx,padding_idx\n",
    "        self.n_out,self.n_filters,self.filter_sizes=n_out,n_filters,filter_sizes\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        \n",
    "        self.create_architecture()\n",
    "        if pretrain_mtx is not None:\n",
    "            print (f'initializing glove with {pretrain_mtx.shape}')\n",
    "            self.initialize_glove()\n",
    "        self.init_hidden()\n",
    "        self.criterion=nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def set_dropouts(self, dropout, dropout_o, dropout_e):\n",
    "        self.dropout, self.dropout_o, self.dropout_e = dropout, dropout_o, dropout_e\n",
    "    \n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=False\n",
    "         \n",
    "    def unfreeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=True\n",
    "\n",
    "    def initialize_glove(self):\n",
    "        self.encoder.weight.data.copy_(torch.Tensor(self.pretrain_mtx))\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "\n",
    "    def create_architecture(self):\n",
    "        ###################################\n",
    "        # Embedding layer - common to both\n",
    "        ###################################\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb,padding_idx=self.padding_idx)\n",
    "        \n",
    "        #######################################\n",
    "        # For RNN #############################\n",
    "        #######################################\n",
    "        # Embedding Layer: Embedding layer just maps each word to an index. n_inp to n_emb mapping is all it does\n",
    "            # input to this is of shape n_batch * n_seq\n",
    "         # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "          # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        self.avg_pool1d=torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool1d=torch.nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "    \n",
    "        #######################################\n",
    "        # For CNN #############################\n",
    "        #######################################    \n",
    "        #embedding dimension is the \"depth\" of the filter and the number of tokens in the sentence is the width.\n",
    "        self.conv_0=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[0])\n",
    "        self.conv_1=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[1])\n",
    "        self.conv_2=torch.nn.Conv1d(self.n_emb,self.n_filters,kernel_size=self.filter_sizes[2])\n",
    "        \n",
    "        self.fc=nn.Linear(len(self.filter_sizes)*self.n_filters+self.n_hidden*4,self.n_out)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward (self,Xb,Yb,Xb_lengths):\n",
    "        \n",
    "        ####RNN PORTION\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "        packed_embs = pack_padded_sequence(embs,Xb_lengths,batch_first=True, enforce_sorted=False)\n",
    "        lstm_out,(hidden,cell)=self.lstm(packed_embs)\n",
    "        lstm_out,lengths=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "        hidden = self.dropout_op(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        avg_pool=self.avg_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        max_pool=self.max_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        \n",
    "        #CNN Portion\n",
    "        new_embs=embs.permute(0,2,1)        \n",
    "        conved_0=torch.relu(self.conv_0(new_embs))\n",
    "        conved_1=torch.relu(self.conv_1(new_embs))\n",
    "        conved_2=torch.relu(self.conv_2(new_embs)) \n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_0.shape[2])\n",
    "        pooled_0=max_pool1d(conved_0).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_1.shape[2])\n",
    "        pooled_1=max_pool1d(conved_1).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_2.shape[2])\n",
    "        pooled_2=max_pool1d(conved_2).squeeze(2)\n",
    "        cat_cnn = self.dropout_op(torch.cat([pooled_0,pooled_1,pooled_2],dim=1))\n",
    "        \n",
    "        ## Concatenate\n",
    "        big_out=torch.cat([cat_cnn,hidden,max_pool],dim=1)\n",
    "        preds=self.fc(big_out)\n",
    "\n",
    "        loss=self.criterion(preds,Yb.contiguous().float().view(-1,1))\n",
    "\n",
    "        \n",
    "        return preds.view(-1),loss\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds,actual, device=\"cpu\", cutoff=0.5):\n",
    "    preds=torch.sigmoid(preds)\n",
    "    zeros=torch.zeros(len(preds)).to(device)\n",
    "    ones = torch.ones(len(preds)).to(device)\n",
    "\n",
    "    preds=torch.where(preds>cutoff,ones,zeros)\n",
    "    correct=torch.round(preds).long()==actual\n",
    "    return correct.float().sum()/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds, y, device=\"cpu\", cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    y=y.float()\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lm_weights=pickle.load(open(f'{DATAPATH}/inter/varybpttpretrained_lm_weights','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if model forward works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 400, 400, 2, True, 52, 'cpu', 0.2, 0.5, 0.5, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout_o,dropout,n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (60002, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=dropout_e,dropout=dropout,\\\n",
    "                 dropout_o=dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 30,895,801 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model_sentiment):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_classifier(\n",
       "  (dropout_enc): Dropout(p=0.2)\n",
       "  (encoder): Embedding(60002, 400, padding_idx=1)\n",
       "  (lstm): LSTM(400, 400, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout_op): Dropout(p=0.5)\n",
       "  (avg_pool1d): AdaptiveAvgPool1d(output_size=1)\n",
       "  (max_pool1d): AdaptiveMaxPool1d(output_size=1)\n",
       "  (conv_0): Conv1d(400, 100, kernel_size=(3,), stride=(1,))\n",
       "  (conv_1): Conv1d(400, 100, kernel_size=(4,), stride=(1,))\n",
       "  (conv_2): Conv1d(400, 100, kernel_size=(5,), stride=(1,))\n",
       "  (fc): Linear(in_features=1900, out_features=1, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0827, -0.0579,  0.9597, -0.1018,  0.1197,  0.0780, -0.2450, -0.2263,\n",
       "          0.0157,  0.1950,  0.1299, -0.2848, -0.0062, -0.0548,  0.2742,  0.2059,\n",
       "         -0.0463,  0.0562, -0.1905, -0.1809,  0.3561,  0.1049, -0.0773,  0.0228,\n",
       "         -0.1071, -0.0340, -0.1633,  0.0326, -0.1183,  0.0797,  0.0591,  0.1533,\n",
       "          0.1626,  0.1081, -0.0023,  0.3720,  0.0615, -0.1105,  0.0874,  0.0034,\n",
       "         -0.2936, -0.4263,  0.0211, -0.1663,  0.0574, -0.0150,  0.1894,  0.1630,\n",
       "          0.4449, -0.1912, -0.6450,  0.6491], grad_fn=<ViewBackward>),\n",
       " tensor(0.7076, grad_fn=<BinaryCrossEntropyWithLogitsBackward>))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,loss=model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3451,  0.1161,  0.4484,  0.1373, -0.1280, -0.3728,  0.2010,  0.2596,\n",
       "        -0.2033,  0.0127,  0.2176,  0.0865,  0.1524, -0.2347, -0.0990,  0.0845,\n",
       "        -0.2835,  0.2939,  0.1618,  0.1024,  0.1894,  0.1100,  0.0531,  0.2357,\n",
       "        -0.2977, -0.0345,  0.0411, -0.1780,  0.2834,  0.3831,  0.5624,  0.3275,\n",
       "        -0.0502,  0.0553, -0.2646,  0.0862, -0.0816, -0.1093, -0.0842, -0.1010,\n",
       "        -0.0075,  0.2538, -0.1554,  0.0840, -0.1627, -0.4590,  0.0635, -0.0068,\n",
       "         0.1610, -0.0217,  0.6311, -0.0362], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5962)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_binomial(preds.to(device),yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48660714285714285"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yb,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.227409e-01,  2.788629e-01, -3.884962e-01,  3.981197e-01, ...,  3.707490e-01, -1.040416e-01,  1.957962e-02,\n",
       "         1.854789e-01],\n",
       "       [ 1.485352e-05, -2.342431e-05,  1.969303e-05, -2.154383e-05, ...,  2.051086e-05,  2.134880e-05,  2.177563e-05,\n",
       "        -1.239415e-05],\n",
       "       [-1.829635e-02, -1.382560e-01,  1.438132e-02, -1.285086e-02, ...,  3.653777e-03,  4.884117e-03,  5.742843e-02,\n",
       "        -7.598962e-03],\n",
       "       [-6.413675e-02,  1.201958e+00, -1.590474e-02,  5.468471e-02, ...,  2.948808e-02,  1.085662e-02, -8.994952e-01,\n",
       "         3.026809e-01],\n",
       "       ...,\n",
       "       [-1.829635e-02, -1.382560e-01,  1.438132e-02, -1.285086e-02, ...,  3.653777e-03,  4.884117e-03,  5.742843e-02,\n",
       "        -7.598962e-03],\n",
       "       [-1.829635e-02, -1.382560e-01,  1.438132e-02, -1.285086e-02, ...,  3.653777e-03,  4.884117e-03,  5.742843e-02,\n",
       "        -7.598962e-03],\n",
       "       [-4.195510e-02, -2.414285e-01,  1.600470e-02, -1.684147e-02, ..., -1.989262e-02, -5.589788e-03,  9.034025e-02,\n",
       "        -2.928584e-02],\n",
       "       [-1.829635e-02, -1.382560e-01,  1.438132e-02, -1.285086e-02, ...,  3.653777e-03,  4.884117e-03,  5.742843e-02,\n",
       "        -7.598962e-03]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_lm_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1e-07\n",
      "1 6e-07\n",
      "2 3.6e-06\n",
      "3 2.16e-05\n",
      "4 0.0001296\n",
      "5 0.0007776\n"
     ]
    }
   ],
   "source": [
    "# Weight Decay Schedule\n",
    "tempstart=1e-7\n",
    "for i in range (6):\n",
    "    print (i, tempstart)\n",
    "    tempstart=tempstart*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.005\n",
      "1 0.005\n",
      "2 0.0034999999999999996\n",
      "3 0.0017149999999999995\n",
      "4 0.0005882449999999997\n",
      "5 0.0001412376244999999\n"
     ]
    }
   ],
   "source": [
    "tempstart=5e-3\n",
    "for i in range (6):\n",
    "    print (i, tempstart)\n",
    "    tempstart=tempstart*(0.7**i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1,5,(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=[1e-2,5e-3,1e-4,5e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,4,(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs[torch.randint(0,4,(1,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=0.7,wd_mult=6):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        self.preds,self.preds_valid,self.trainY,self.actual=[],[],[],[]\n",
    "        \n",
    "    def fit (self,Xb,Yb,Xlen,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds,loss=self.model(Xb,Yb,Xlen)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "            acc=acc.item()\n",
    "            \n",
    "            if mode_train:\n",
    "                self.trainY.append(Yb.view(-1))\n",
    "                self.preds.append(preds.data)\n",
    "            else:\n",
    "                self.actual.append(Yb.view(-1))\n",
    "                self.preds_valid.append(preds.data)\n",
    "            \n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        self.model.init_hidden()\n",
    "        for Xb,Yb,Xlen in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            Xlen=Xlen.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc=self.fit(Xb,Yb,Xlen,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  {epoch_acc/(k)}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        \n",
    "        if self.cycle_mult > 0:\n",
    "            reset_cycle=self.cycle_mult\n",
    "        \n",
    "        for epoch in range(n_epochs):                \n",
    "\n",
    "            \n",
    "            loss,acc=self.run_epoch(dltrain,True)\n",
    "            lossv,accv=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss} Train Accuracy:{acc} Valid Loss:{lossv} Valid Accuracy:{accv}')\n",
    "        \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    #self.wd=self.start_wd\n",
    "                    reset_cycle=self.n_epoch+reset_cycle\n",
    "                else:\n",
    "                    self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    if self.n_epoch>1:\n",
    "                        self.wd*=self.wd_mult\n",
    "            self.n_epoch+=1\n",
    "                \n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                #param_group['weight_decay']=self.wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (60002, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout,\\\n",
    "                 dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n",
    "model_sentiment=model_sentiment.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model_sentiment.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "#optimizer=torch.optim.SGD(model_sentiment.parameters(),lr=1e-2,momentum=0.9, weight_decay=wd)\n",
    "metric_fn=accuracy_binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10770, 1150)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain),len(dlvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29986\n",
       "1    29814\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model_sentiment,optimizer,accuracy_binomial,device,bptt,500,0.25,cycle_mult=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5, 0.5, 0.2, 0.5, 0.5)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.dropout_e,model_sentiment.dropout,model_sentiment.dropout_o, learner.model.dropout_e,learner.model.dropout,learner.model.dropout_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 0.38001909692585467  0.8233077243566513\n",
      "Batch:1000 0.3065233438424766  0.8645000350475311\n",
      "Batch:1500 0.2745874199991425  0.8813333697716395\n",
      "Batch:2000 0.2544250233210623  0.8915961907505989\n",
      "Batch:2500 0.242202724955976  0.8977231141805648\n",
      "Batch:3000 0.23303538528767725  0.9022051657040914\n",
      "Batch:3500 0.2256694547432874  0.9058626750367028\n",
      "Batch:4000 0.2201988925067708  0.9084856147021055\n",
      "Batch:4500 0.21544423888002834  0.910837644788954\n",
      "Batch:5000 0.21143236012868583  0.9127192687153817\n",
      "Batch:5500 0.2079755813282999  0.9144860519495878\n",
      "Batch:6000 0.20500842518235246  0.915910294353962\n",
      "Batch:6500 0.20275546941676964  0.916985245172794\n",
      "Batch:7000 0.20065681831059712  0.9180412468739918\n",
      "Batch:7500 0.19890509835481643  0.9187949099063873\n",
      "Batch:8000 0.19752617287402974  0.9193750381469726\n",
      "Batch:8500 0.19608372873045943  0.9200814860848819\n",
      "Batch:9000 0.19497819552115267  0.920606875816981\n",
      "Batch:9500 0.19393129518000704  0.9211680543422699\n",
      "Batch:10000 0.1931441226599738  0.9215173458933831\n",
      "Batch:10500 0.19237276039751514  0.9218608440841948\n",
      "Batch:500 0.1635377962216735  0.9376538827419281\n",
      "Batch:1000 0.16104231609404088  0.9382692679762841\n",
      "Epoch:0 Learning rate 0.005 Weight Decay 1e-07 Train Loss:0.19185623769633672 Train Accuracy:0.9221145300424641 Valid Loss:0.16009186326809552 Valid Accuracy:0.9382776289919148\n",
      "Batch:500 0.174726768694818  0.9299231141805648\n",
      "Batch:1000 0.17492059331573545  0.9300769610404969\n",
      "Batch:1500 0.17368176150197784  0.930589781165123\n",
      "Batch:2000 0.17227637311350555  0.9311442687511444\n",
      "Batch:2500 0.17103699758797883  0.9315923454523086\n",
      "Batch:3000 0.17036564815727373  0.9320641403198242\n",
      "Batch:3500 0.17154983645092164  0.9313626751559121\n",
      "Batch:4000 0.17262632254092022  0.9310817687958479\n",
      "Batch:4500 0.17239465501863097  0.9311837986442778\n",
      "Batch:5000 0.1729689120016992  0.9311269611001015\n",
      "Batch:5500 0.1724717793498527  0.931143394741145\n",
      "Batch:6000 0.17206916225515306  0.931278884212176\n",
      "Batch:6500 0.17160331079363822  0.9314645350988094\n",
      "Batch:7000 0.17139755890678082  0.9316978401201111\n",
      "Batch:7500 0.17133901910434166  0.9317769609769185\n",
      "Batch:8000 0.17097359030763618  0.9319711918234825\n",
      "Batch:8500 0.17094627696100403  0.9318959656603196\n",
      "Batch:9000 0.17074639693440663  0.9319637132022116\n",
      "Batch:9500 0.17071382152759715  0.9319372849966351\n",
      "Batch:10000 0.17092172505408526  0.9318596534729003\n",
      "Batch:10500 0.1708076977538211  0.9318956424849374\n",
      "Batch:500 0.15592583601921797  0.937538498044014\n",
      "Batch:1000 0.15553117040544748  0.9385000365376472\n",
      "Epoch:1 Learning rate 0.005 Weight Decay 1e-07 Train Loss:0.17088564353162283 Train Accuracy:0.9318858558310329 Valid Loss:0.1553278647719518 Valid Accuracy:0.9386287994488426\n",
      "Batch:500 0.16541522101312875  0.9335384998321533\n",
      "Batch:1000 0.1621302753984928  0.9349231150150299\n",
      "Batch:1500 0.15965722494386136  0.9360513197978337\n",
      "Batch:2000 0.15882551264530048  0.936403884023428\n",
      "Batch:2500 0.15828800742700697  0.936453884100914\n",
      "Batch:3000 0.15757623865579565  0.9369295252164205\n",
      "Batch:3500 0.1568897437485201  0.9373242136240005\n",
      "Batch:4000 0.15626228002319112  0.9374519608616829\n",
      "Batch:4500 0.15633402017835113  0.9376410633193122\n",
      "Batch:5000 0.15663087025210262  0.9375846530675888\n",
      "Batch:5500 0.15704458067870952  0.9374371007030661\n",
      "Batch:6000 0.15712017620696375  0.9373429865241051\n",
      "Batch:6500 0.1570481477955786  0.9374379075490511\n",
      "Batch:7000 0.15699956479721836  0.9375604771886553\n",
      "Batch:7500 0.156786107869943  0.9376410632769266\n",
      "Batch:8000 0.15699871392687784  0.9376034030467272\n",
      "Batch:8500 0.1569069591392489  0.9376968702498605\n",
      "Batch:9000 0.1569541636446698  0.9376795248720381\n",
      "Batch:9500 0.15693421424925327  0.9377166369024076\n",
      "Batch:10000 0.15639993880745023  0.9378904222905636\n",
      "Batch:10500 0.15634913102218084  0.9379194515943527\n",
      "Batch:500 0.1666788795813918  0.932730806350708\n",
      "Batch:1000 0.16979332216829063  0.9329231145381928\n",
      "Epoch:2 Learning rate 0.0034999999999999996 Weight Decay 1e-07 Train Loss:0.15609672370841493 Train Accuracy:0.9379830388748325 Valid Loss:0.17298121437106442 Valid Accuracy:0.9311371619805046\n",
      "Batch:500 0.1511962053179741  0.9408461900949479\n",
      "Batch:1000 0.14557257167063653  0.941846189558506\n",
      "Batch:1500 0.14550570643444857  0.9418077281713486\n",
      "Batch:2000 0.1444508396293968  0.9423846516907215\n",
      "Batch:2500 0.1437317645996809  0.9429615746974945\n",
      "Batch:3000 0.14259370250503223  0.9434743952155114\n",
      "Batch:3500 0.1433366939915078  0.9433297066007341\n",
      "Batch:4000 0.14375041838455946  0.9431154210567474\n",
      "Batch:4500 0.14300532758732637  0.9432949084175958\n",
      "Batch:5000 0.14260510795153677  0.9434077289223671\n",
      "Batch:5500 0.1420194762992588  0.9435629737268795\n",
      "Batch:6000 0.1421604163106531  0.943695549339056\n",
      "Batch:6500 0.14198858618220458  0.9438550661160395\n",
      "Batch:7000 0.14189178950312947  0.943928607915129\n",
      "Batch:7500 0.1417721518702805  0.9439923441489537\n",
      "Batch:8000 0.14173989292304032  0.9440072480514645\n",
      "Batch:8500 0.14154761546346195  0.9440769595398623\n",
      "Batch:9000 0.14139998367408083  0.9442500364316835\n",
      "Batch:9500 0.1414564227057915  0.9442389028762517\n",
      "Batch:10000 0.1408646735684946  0.9444731133818627\n",
      "Batch:10500 0.1407632215156087  0.9444450914178576\n",
      "Batch:500 0.13508647574484348  0.9488461894989013\n",
      "Batch:1000 0.13199747610092163  0.9501731123328209\n",
      "Epoch:3 Learning rate 0.0017149999999999995 Weight Decay 6e-07 Train Loss:0.14056319041175902 Train Accuracy:0.9445147139614339 Valid Loss:0.13091593669160553 Valid Accuracy:0.9504849850094836\n",
      "Batch:500 0.1314351615346968  0.949076957821846\n",
      "Batch:1000 0.13033126910589635  0.9491538807153702\n",
      "Batch:1500 0.12997013739372293  0.9492692656119665\n",
      "Batch:2000 0.13030450217146428  0.9489904195368289\n",
      "Batch:2500 0.13052973053082823  0.9490000348091125\n",
      "Batch:3000 0.130087655392165  0.9493205474019051\n",
      "Batch:3500 0.12984258128276893  0.9495494852576937\n",
      "Batch:4000 0.12982735688448885  0.9494567656964064\n",
      "Batch:4500 0.12948706082730657  0.9497137099901836\n",
      "Batch:5000 0.12906080609131604  0.9497692654252052\n",
      "Batch:5500 0.12901111774298954  0.9497168179316954\n",
      "Batch:6000 0.12895151243343328  0.9497564450999101\n",
      "Batch:6500 0.12881941370078578  0.9497692656058532\n",
      "Batch:7000 0.12888525501891437  0.9496593755398478\n",
      "Batch:7500 0.12875555326690277  0.9497641374111175\n",
      "Batch:8000 0.1285911369987298  0.9497812848314643\n",
      "Batch:8500 0.12822525970703538  0.9499231117543052\n",
      "Batch:9000 0.12826943450876407  0.9498205476138327\n",
      "Batch:9500 0.12821339686803127  0.949908941708113\n",
      "Batch:10000 0.12785087482519447  0.9499884963214398\n",
      "Batch:10500 0.12775387040481326  0.9499743938105447\n",
      "Batch:500 0.1233072636090219  0.953923109292984\n",
      "Batch:1000 0.11915709461271763  0.9553654180765152\n",
      "Epoch:4 Learning rate 0.0005882449999999997 Weight Decay 3.6e-06 Train Loss:0.12767997868471503 Train Accuracy:0.9499768222274887 Valid Loss:0.1175817167127262 Valid Accuracy:0.9557525416042494\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type sentiment_classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{DATAPATH}/inter/combo_model_dict_freeze')\n",
    "torch.save(optimizer.state_dict(),f'{DATAPATH}/inter/combo_optimizer_dict_freeze')\n",
    "torch.save (model_sentiment,f'{DATAPATH}/inter/combo_model_freeze')\n",
    "torch.save (optimizer,f'{DATAPATH}/inter/combo_optimizer_freeze')\n",
    "torch.save (learner,f'{DATAPATH}/inter/combo_learner_freeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=list(chain.from_iterable(learner.preds))[-df_train.shape[0]:]\n",
    "preds_valid=list(chain.from_iterable(learner.preds_valid))[-df_valid.shape[0]:]\n",
    "trainY=list(chain.from_iterable(learner.trainY))[-df_train.shape[0]:]\n",
    "actual=list(chain.from_iterable(learner.actual))[-df_valid.shape[0]:]\n",
    "preds=[x.item() for x in preds]\n",
    "preds_valid=[x.item() for x in preds_valid]\n",
    "trainY=[x.item() for x in trainY]\n",
    "actual=[x.item() for x in actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9938809332844389, 0.9953131020186603)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(trainY,preds),roc_auc_score(actual,preds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9626113608135035, 0.968318846866085)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(trainY,np.round(expit(preds))), f1_score(actual,np.round(expit(preds_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9633775106866269, 0.9632887443157301)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(trainY,np.round(expit(preds))), precision_score(actual,np.round(expit(preds_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9618464285714285, 0.9734017575635607)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(trainY,np.round(expit(preds))), recall_score(actual,np.round(expit(preds_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001412376244999999"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model_sentiment,optimizer,accuracy_binomial,device,bptt,500,0.25,cycle_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 0.11832200812548399  0.9535000346899033\n",
      "Batch:1000 0.1188365598898381  0.9524423427581787\n",
      "Batch:1500 0.11943354298795263  0.9528590095440547\n",
      "Batch:2000 0.11832190256332979  0.9537404196560383\n",
      "Batch:2500 0.11737273623533546  0.9541461885213852\n",
      "Batch:3000 0.11693801787060996  0.954243624428908\n",
      "Batch:3500 0.11742168455570937  0.9541044302497591\n",
      "Batch:4000 0.11713982405187562  0.9541058038473129\n",
      "Batch:4500 0.11606956864582996  0.9544102909300063\n",
      "Batch:5000 0.11545702863987535  0.9547961883902549\n",
      "Batch:5500 0.11525633646496995  0.9549860484816811\n",
      "Batch:6000 0.11464977006350334  0.955243624150753\n",
      "Batch:6500 0.1138566996240272  0.9556272532022916\n",
      "Batch:7000 0.11324705959404154  0.9558571770446641\n",
      "Batch:7500 0.11296233197549979  0.9560205469528834\n",
      "Batch:8000 0.11277249895385466  0.9561154186874629\n",
      "Batch:8500 0.1126403840485522  0.9561357807131374\n",
      "Batch:9000 0.11216753039457318  0.9564231109221776\n",
      "Batch:9500 0.11188432920949631  0.9565688598469684\n",
      "Batch:10000 0.11136372012114153  0.9567750339329243\n",
      "Batch:10500 0.1110809254486646  0.9568974697760173\n",
      "Batch:500 0.10476875252649188  0.9604231086969376\n",
      "Batch:1000 0.10086126425303518  0.9626538782119751\n",
      "Epoch:0 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.11101606058626122 Train Accuracy:0.9569239440402613 Valid Loss:0.10005406616498595 Valid Accuracy:0.9628261190911998\n",
      "Batch:500 0.09965213019959629  0.9603461873531342\n",
      "Batch:1000 0.09934548367839306  0.9609423407912254\n",
      "Batch:1500 0.09939147087248663  0.9612436223824818\n",
      "Batch:2000 0.09979044029302896  0.961413494437933\n",
      "Batch:2500 0.09973451558127999  0.9614769559860229\n",
      "Batch:3000 0.09904923138519128  0.9619102889696757\n",
      "Batch:3500 0.09946731445592429  0.9617308018718447\n",
      "Batch:4000 0.09924929564795457  0.9618942633569241\n",
      "Batch:4500 0.09903869718147648  0.9619743915134006\n",
      "Batch:5000 0.09888101660441607  0.9620692632198333\n",
      "Batch:5500 0.09848572939685123  0.9623147178238088\n",
      "Batch:6000 0.09835497817536816  0.9624455452164015\n",
      "Batch:6500 0.09839454121099642  0.9624526951588117\n",
      "Batch:7000 0.09796037174854427  0.9625687137501581\n",
      "Batch:7500 0.09787125546398262  0.9626359299023947\n",
      "Batch:8000 0.09785917337005957  0.9627163785398006\n",
      "Batch:8500 0.09796549060940743  0.9625746931328493\n",
      "Batch:9000 0.0979261893056747  0.9625363573431969\n",
      "Batch:9500 0.09787357887870779  0.9626194656334425\n",
      "Batch:10000 0.09785668385857717  0.962688493937254\n",
      "Batch:10500 0.09826691173717735  0.9625879445530119\n",
      "Batch:500 0.0970461949929595  0.9657692617177963\n",
      "Batch:1000 0.09188173160329462  0.9677115693092346\n",
      "Epoch:1 Learning rate 0.0001412376244999999 Weight Decay 1e-07 Train Loss:0.09813716536311705 Train Accuracy:0.962637820206202 Valid Loss:0.09065597175903942 Valid Accuracy:0.9682441781396451\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{DATAPATH}/inter/combo_model_dict_nofreeze')\n",
    "torch.save(optimizer.state_dict(),f'{DATAPATH}/inter/combo_optimizer_dict_nofreeze')\n",
    "torch.save (model_sentiment,f'{DATAPATH}/inter/combo_model_nofreeze')\n",
    "torch.save (optimizer,f'{DATAPATH}/inter/combo_optimizer_nofreeze')\n",
    "torch.save (learner,f'{DATAPATH}/inter/combo_learner_nofreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
