{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os \n",
    "import fastai\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "PATH=\"/home/kirana/Documents/phd/final\"\n",
    "DATAPATH=\"/home/kirana/Documents/phd/data/aclImdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_train,df_valid,df_test,itos, train_tokens, valid_tokens, test_tokens, trn_lm, val_lm, test_lm]=pickle.load(open(f'{PATH}/inter/dfs_tokens_fastai.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.concat([df_train,df_valid],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid=df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.loc[df_train['label']<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0</td>\n",
       "      <td>I've noticed how all the other reviews of this...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>0</td>\n",
       "      <td>I went on a visit to one of my relatives a whi...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0</td>\n",
       "      <td>Darcy and her young daughter Pamela are headin...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0</td>\n",
       "      <td>Battlestar Gallactica was so great because it ...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0</td>\n",
       "      <td>Any movie with \"National Lampoon\" in the title...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3218      0  I've noticed how all the other reviews of this...   \n",
       "6854      0  I went on a visit to one of my relatives a whi...   \n",
       "2697      0  Darcy and her young daughter Pamela are headin...   \n",
       "5747      0  Battlestar Gallactica was so great because it ...   \n",
       "8731      0  Any movie with \"National Lampoon\" in the title...   \n",
       "\n",
       "                                                  words  \\\n",
       "3218  [ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...   \n",
       "6854  [ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...   \n",
       "2697  [ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...   \n",
       "5747  [ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...   \n",
       "8731  [ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...   \n",
       "\n",
       "                                                 tokens  \n",
       "3218  [41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...  \n",
       "6854  [41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...  \n",
       "2697  [41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...  \n",
       "5747  [41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...  \n",
       "8731  [41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=52 # 52 - Jeremey, 20 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt= 70 #70 - Jeremey, 35 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0</td>\n",
       "      <td>I've noticed how all the other reviews of this...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>0</td>\n",
       "      <td>I went on a visit to one of my relatives a whi...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0</td>\n",
       "      <td>Darcy and her young daughter Pamela are headin...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0</td>\n",
       "      <td>Battlestar Gallactica was so great because it ...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0</td>\n",
       "      <td>Any movie with \"National Lampoon\" in the title...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3218      0  I've noticed how all the other reviews of this...   \n",
       "6854      0  I went on a visit to one of my relatives a whi...   \n",
       "2697      0  Darcy and her young daughter Pamela are headin...   \n",
       "5747      0  Battlestar Gallactica was so great because it ...   \n",
       "8731      0  Any movie with \"National Lampoon\" in the title...   \n",
       "\n",
       "                                                  words  \\\n",
       "3218  [ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...   \n",
       "6854  [ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...   \n",
       "2697  [ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...   \n",
       "5747  [ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...   \n",
       "8731  [ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...   \n",
       "\n",
       "                                                 tokens  \n",
       "3218  [41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...  \n",
       "6854  [41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...  \n",
       "2697  [41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...  \n",
       "5747  [41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...  \n",
       "8731  [41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', 'the', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padlen=1400\n",
    "padding_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['n_tok']=df_train['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       304.945840\n",
       "std        224.981807\n",
       "min         16.000000\n",
       "25%        166.000000\n",
       "50%        228.000000\n",
       "75%        371.000000\n",
       "max       3354.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['n_tok']=df_valid['tokens'].apply(len)\n",
    "df_valid.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['n_tok']=df_test['tokens'].apply(len)\n",
    "df_test.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    x=df_train['tokens'].values[i]\n",
    "    y=df_train['label'].values[i]    \n",
    "    out=np.ones(padlen)\n",
    "    if len(x) < padlen:\n",
    "        out[:len(x)]=x\n",
    "    else:\n",
    "        out=x[:padlen]\n",
    "    print (out)\n",
    "    print (y)\n",
    "    print (len(out))\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64, 1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64, 1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts(), df_valid['label'].value_counts(),df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 5), (25000, 5))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_sentiment (Dataset):\n",
    "    def __init__ (self,df,bs,padlen=64,xvar='tokens',yvar='label',len_var='n_tok',padding_idx=1):\n",
    "        self.x,self.y,self.padlen,self.padding_idx,self.len_var,self.bs=\\\n",
    "            df[xvar],df[yvar],padlen,padding_idx,df[len_var],bs\n",
    "        self.len_var=self.len_var.clip(0,padlen)\n",
    "    \n",
    "    def pad (self,x):\n",
    "        out=np.ones(self.padlen)*self.padding_idx\n",
    "        out=out.astype(int)\n",
    "        if len(x)>=self.padlen:\n",
    "            out[:]=x[:self.padlen]\n",
    "        else:\n",
    "            out[:len(x)]=x\n",
    "        return out\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        return self.pad(self.x.iloc[idx]),self.y.iloc[idx],self.len_var.iloc[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padlen=max(df_train['n_tok'])\n",
    "padlen=1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=ds_sentiment(df_train,bs,padlen)\n",
    "dsvalid=ds_sentiment(df_valid,bs,padlen)\n",
    "dstest=ds_sentiment(df_test,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain=DataLoader(dstrain,bs,True)\n",
    "dlvalid=DataLoader(dsvalid,bs,False)\n",
    "dltest=DataLoader(dstest,bs,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb,yb,xlen in dltrain:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1]]),\n",
       " tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "         0, 0, 0, 1]),\n",
       " tensor([143, 238, 855, 251, 161,  83, 513, 215, 157, 174, 176, 153, 330, 146,\n",
       "         824, 995, 291,  79, 294, 277, 237, 315, 412, 187, 335, 250, 166, 150,\n",
       "         240, 174, 925, 320, 186, 245, 294, 189, 565, 834, 207, 184, 158,  84,\n",
       "         221, 160, 190, 114, 205, 429, 329, 224, 159, 150]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb, xlen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cyclical learning rates\n",
    "\tvary learning rate by epoch between two values\n",
    "\t\n",
    "\n",
    "bptt=70\n",
    "n_emb=400\n",
    "n_hid=1150\n",
    "n_layers=3\n",
    "bs=48 # whatever is the max that can fit in memory\n",
    "\n",
    "# shuffle dataset\n",
    "# sort the data by length\n",
    "\n",
    "\n",
    "class ds_sentiment(Dataset):\n",
    "\tdef __init__(self,x,y):\n",
    "\t\tself.x,self.y=x,y\n",
    "\t\n",
    "\tdef __getitem__(self,idx):\n",
    "\t\treturn self.x[idx],self.y[idx]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 70)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp=len(itos)\n",
    "n_emb=400 #650\n",
    "n_hidden=400#400\n",
    "n_layers= 2 # 2\n",
    "dropout=0.5 # 0.5\n",
    "wd=1e-6\n",
    "bidirectional=True\n",
    "dropout_e=0.2 # 0.5\n",
    "dropout_o=0.5 #0.5\n",
    "n_out=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 1400]), torch.Size([52]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape,xlen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', 'the', '.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool1d(5)\n",
    "input = torch.randn(1, 64, 8)\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_classifier (nn.Module):\n",
    "    def __init__(self,n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,pretrain_mtx=None,n_out=1,padding_idx=1,n_filters=100,filter_sizes=[3,4,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device,self.pretrain_mtx,self.padding_idx=\\\n",
    "                            n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,pretrain_mtx,padding_idx\n",
    "        self.n_out,self.n_filters,self.filter_sizes=n_out,n_filters,filter_sizes\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        \n",
    "        \n",
    "        self.create_architecture()\n",
    "        if pretrain_mtx is not None:\n",
    "            print (f'initializing glove with {pretrain_mtx.shape}')\n",
    "            self.initialize_glove()\n",
    "        self.init_hidden()\n",
    "        self.criterion=nn.BCEWithLogitsLoss()\n",
    "       \n",
    "    \n",
    "    def set_dropouts(self, dropout, dropout_o, dropout_e):\n",
    "        self.dropout, self.dropout_o, self.dropout_e = dropout, dropout_o, dropout_e\n",
    "    \n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=False\n",
    "         \n",
    "    def unfreeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=True\n",
    "\n",
    "    def initialize_glove(self):\n",
    "        self.encoder.weight.data.copy_(torch.Tensor(self.pretrain_mtx))\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "      \n",
    "    def create_architecture_cnn(self):\n",
    "        # Dropout layer\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        # Embedding Layer: Embedding layer just maps each word to an index. n_inp to n_emb mapping is all it does\n",
    "            # input to this is of shape n_batch * n_seq\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb,padding_idx=self.padding_idx)\n",
    "          # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "            \n",
    "            #embedding dimension is the \"depth\" of the filter and the number of tokens in the sentence is the width.\n",
    "        self.conv_0=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[0])\n",
    "        self.conv_1=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[1])\n",
    "        self.conv_2=torch.nn.Conv1d(self.n_emb,self.n_filters,kernel_size=self.filter_sizes[2])\n",
    "\n",
    "        # \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(len(self.filter_sizes)*self.n_filters,self.n_out)\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "                                    \n",
    "    def create_architecture_lstm(self):\n",
    "        # Dropout layer\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        # Embedding Layer: Embedding layer just maps each word to an index. n_inp to n_emb mapping is all it does\n",
    "            # input to this is of shape n_batch * n_seq\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb,padding_idx=self.padding_idx)\n",
    "             # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "            # h and c are of shape n_layers * n_batch * n_hidden\n",
    "        # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "        \n",
    "                # output is of shape bs * n_seq * n_hidden\n",
    "            # output [:,-1,:] is the same as hn[-1] but contains the padding idx also. Those are not there for hn[-1]\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        self.avg_pool1d=torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool1d=torch.nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.fc1=nn.Linear(self.n_hidden*4,self.n_hidden)\n",
    "        self.fc2=nn.Linear(self.n_hidden*3,self.n_out)\n",
    "\n",
    "        #self.log_softmax=nn.LogSoftmax()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def create_architecture(self):\n",
    "        ###################################\n",
    "        # Embedding layer - common to both\n",
    "        ###################################\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb,padding_idx=self.padding_idx)\n",
    "        \n",
    "        #######################################\n",
    "        # For RNN #############################\n",
    "        #######################################\n",
    "        # Embedding Layer: Embedding layer just maps each word to an index. n_inp to n_emb mapping is all it does\n",
    "            # input to this is of shape n_batch * n_seq\n",
    "         # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "          # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        self.avg_pool1d=torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool1d=torch.nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1=nn.Linear(self.n_hidden*4,self.n_hidden)\n",
    "        self.fc2=nn.Linear(self.n_hidden*3,self.n_out)\n",
    "\n",
    "        #self.log_softmax=nn.LogSoftmax()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    \n",
    "        #######################################\n",
    "        # For CNN #############################\n",
    "        #######################################    \n",
    "        #embedding dimension is the \"depth\" of the filter and the number of tokens in the sentence is the width.\n",
    "        self.conv_0=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[0])\n",
    "        self.conv_1=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[1])\n",
    "        self.conv_2=torch.nn.Conv1d(self.n_emb,self.n_filters,kernel_size=self.filter_sizes[2])\n",
    "        self.fc=nn.Linear(len(self.filter_sizes)*self.n_filters,self.n_out)\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        # \n",
    "        \n",
    "        ###################################\n",
    "        ## MERGE THE BOTH OF THEM\n",
    "        \n",
    "        self.logisticreg=nn.Linear(2,1)\n",
    "        \n",
    "    def forward (self,Xb,Yb,Xb_lengths):\n",
    "        \n",
    "        ####RNN PORTION\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "        packed_embs = pack_padded_sequence(embs,Xb_lengths,batch_first=True, enforce_sorted=False)\n",
    "        lstm_out,(hidden,cell)=self.lstm(packed_embs)\n",
    "        lstm_out,lengths=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "        hidden = self.dropout_op(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        avg_pool=self.avg_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        max_pool=self.max_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        max_avg=torch.cat([avg_pool,max_pool],dim=1)\n",
    "        preds_max_avg=self.fc1(max_avg)\n",
    "        big_out=torch.cat([hidden,preds_max_avg],dim=1)\n",
    "        preds_rnn=self.fc2(big_out)\n",
    "        \n",
    "        #CNN Portion\n",
    "        new_embs=embs.permute(0,2,1)\n",
    "        \n",
    "        conved_0=torch.relu(self.conv_0(new_embs))\n",
    "        conved_1=torch.relu(self.conv_1(new_embs))\n",
    "        conved_2=torch.relu(self.conv_2(new_embs))\n",
    "        \n",
    "        \n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_0.shape[2])\n",
    "        pooled_0=max_pool1d(conved_0).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_1.shape[2])\n",
    "        pooled_1=max_pool1d(conved_1).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_2.shape[2])\n",
    "        pooled_2=max_pool1d(conved_2).squeeze(2)\n",
    "\n",
    "        cat_cnn = self.dropout_op(torch.cat([pooled_0,pooled_1,pooled_2],dim=1))\n",
    "        preds_cnn= self.fc (cat_cnn)\n",
    "       \n",
    "        \n",
    "        loss_rnn=self.criterion(preds_cnn,Yb.contiguous().float().view(-1,1)) \n",
    "        loss_cnn=self.criterion(preds_rnn,Yb.contiguous().float().view(-1,1))\n",
    "        #return preds_cnn.view(-1), preds_rnn.view(-1),loss_cnn,loss_rnn \n",
    "        if 1==0:\n",
    "            preds=self.logisticreg(torch.cat([preds_rnn,preds_cnn],1))\n",
    "            loss=self.criterion(preds,Yb.contiguous().float().view(-1,1))\n",
    "        \n",
    "        return preds_cnn.view(-1),preds_rnn.view(-1),loss_cnn,loss_rnn\n",
    "        \n",
    "    def forward_cnn(self,Xb,Yb,Xb_lengths):\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "\n",
    "        embs=embs.permute(0,2,1)\n",
    "        \n",
    "        conved_0=torch.relu(self.conv_0(embs))\n",
    "        conved_1=torch.relu(self.conv_1(embs))\n",
    "        conved_2=torch.relu(self.conv_2(embs))\n",
    "        \n",
    "        \n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_0.shape[2])\n",
    "        pooled_0=max_pool1d(conved_0).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_1.shape[2])\n",
    "        pooled_1=max_pool1d(conved_1).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_2.shape[2])\n",
    "        pooled_2=max_pool1d(conved_2).squeeze(2)\n",
    "\n",
    "        cat_cnn = self.dropout_op(torch.cat([pooled_0,pooled_1,pooled_2],dim=1))\n",
    "        preds= self.fc (cat_cnn)\n",
    "       \n",
    "              \n",
    "        \n",
    "        loss=self.criterion(preds,Yb.contiguous().float().view(-1,1))\n",
    "        \n",
    "        return preds.view(-1), loss                               \n",
    "                                    \n",
    "  \n",
    "                                    \n",
    "                                    \n",
    "    def forward_rnn(self,Xb,Yb,Xb_lengths):\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "\n",
    "        # before lstm call\n",
    "            # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
    "        packed_embs = pack_padded_sequence(embs,Xb_lengths,batch_first=True, enforce_sorted=False)\n",
    "        lstm_out,(hidden,cell)=self.lstm(packed_embs)\n",
    "\n",
    "        # after lstm call\n",
    "        lstm_out,lengths=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "            # lstm_out is of shape bs * n_seq * (n_hidden*n_layers)\n",
    "        \n",
    "        # lstm_out has the values that are padded\n",
    "        hidden = self.dropout_op(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        avg_pool=self.avg_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        max_pool=self.max_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        \n",
    "        # concatenate\n",
    "        max_avg=torch.cat([avg_pool,max_pool],dim=1)\n",
    "        preds_max_avg=self.fc1(max_avg)\n",
    "        \n",
    "        ## Concatenate hidden, average pool and max pool\n",
    "\n",
    "        big_out=torch.cat([hidden,preds_max_avg],dim=1)\n",
    "        preds=self.fc2(big_out)\n",
    "        \n",
    "              \n",
    "        \n",
    "        loss=self.criterion(preds,Yb.contiguous().float().view(-1,1))\n",
    "        \n",
    "        return preds.view(-1), loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds,actual, device=\"cpu\", cutoff=0.5):\n",
    "    preds=torch.sigmoid(preds)\n",
    "    zeros=torch.zeros(len(preds)).to(device)\n",
    "    ones = torch.ones(len(preds)).to(device)\n",
    "\n",
    "    preds=torch.where(preds>cutoff,ones,zeros)\n",
    "    correct=torch.round(preds).long()==actual\n",
    "    return correct.float().sum()/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds, y, device=\"cpu\", cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    y=y.float()\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lm_weights=pickle.load(open(f'{PATH}/inter/pretrained_lm_weights','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==0:\n",
    "    model=torch.load (f'{PATH}/inter/model_awd_lstm')\n",
    "    pretrained_lm_weights=model.encoder.weight.data.cpu().numpy()\n",
    "    import pickle\n",
    "    pickle.dump(pretrained_lm_weights,open(f'{PATH}/inter/pretrained_lm_weights','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if model forward works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59972, 400, 400, 2, True, 52, 'cpu', 0.2, 0.5, 0.5, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout_o,dropout,n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (59972, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=dropout_e,dropout=dropout,\\\n",
    "                 dropout_o=dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 31,523,805 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model_sentiment):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_classifier(\n",
       "  (dropout_enc): Dropout(p=0.2)\n",
       "  (encoder): Embedding(59972, 400, padding_idx=1)\n",
       "  (lstm): LSTM(400, 400, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout_op): Dropout(p=0.5)\n",
       "  (avg_pool1d): AdaptiveAvgPool1d(output_size=1)\n",
       "  (max_pool1d): AdaptiveMaxPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=1600, out_features=400, bias=True)\n",
       "  (fc2): Linear(in_features=1200, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (conv_0): Conv1d(400, 100, kernel_size=(3,), stride=(1,))\n",
       "  (conv_1): Conv1d(400, 100, kernel_size=(4,), stride=(1,))\n",
       "  (conv_2): Conv1d(400, 100, kernel_size=(5,), stride=(1,))\n",
       "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
       "  (logisticreg): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4301, -0.0860, -0.6359,  0.1613, -0.6191, -0.7166, -0.5547, -1.0914,\n",
       "         -0.9626, -0.6576, -0.4800, -0.1413, -0.7141, -0.9568,  0.5514, -1.1686,\n",
       "         -0.6755, -0.1909, -0.7565, -1.2089, -1.1464,  0.2044, -0.5274, -0.2017,\n",
       "          0.0875,  0.1308, -0.4944, -0.6041, -0.8240, -0.3886, -1.6958, -0.3026,\n",
       "         -0.7969, -0.7390, -0.1324, -0.5788, -0.6594, -0.1332, -0.4386, -0.9412,\n",
       "         -0.9020, -0.3230,  0.0027, -0.6424, -0.8373, -0.3104, -0.6968, -0.7097,\n",
       "         -0.0228, -1.1145, -0.9044, -0.6945], grad_fn=<ViewBackward>),\n",
       " tensor([-0.1063, -0.0411, -0.0275, -0.0462, -0.0942, -0.0419, -0.0613, -0.0830,\n",
       "         -0.0391, -0.0957, -0.0575, -0.0552, -0.0887, -0.0780, -0.0571, -0.0527,\n",
       "         -0.0593, -0.0575, -0.0347, -0.0537, -0.0523, -0.0615, -0.0470, -0.0344,\n",
       "         -0.0821, -0.0568, -0.0158, -0.0742, -0.0358, -0.0375, -0.0583, -0.0726,\n",
       "         -0.0953, -0.0515, -0.0650, -0.0880, -0.0545, -0.0343, -0.0841, -0.0756,\n",
       "         -0.0603, -0.0625, -0.0676, -0.0986, -0.0946, -0.1383, -0.0922, -0.0806,\n",
       "         -0.0151, -0.0936, -0.0502, -0.0863], grad_fn=<ViewBackward>),\n",
       " tensor(0.6949, grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n",
       " tensor(0.7394, grad_fn=<BinaryCrossEntropyWithLogitsBackward>))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cnn,preds_rnn,loss_cnn,loss_rnn=model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2131, -0.7706, -0.8018, -0.6208, -0.9294, -0.8188, -0.4982, -0.7980,\n",
       "        -0.9118, -0.2613, -0.1989, -0.5468,  0.2974,  0.0519, -0.8382, -0.0619,\n",
       "        -1.1088, -0.5922, -1.1716, -0.5116, -0.1036, -0.4681, -0.9159, -0.5664,\n",
       "        -0.3994, -0.8222, -1.1773, -0.0233, -0.7069, -0.3660, -1.0622, -0.3888,\n",
       "        -1.1044, -1.1806, -0.2259, -0.0707, -0.3818, -0.6496, -0.9989,  0.1700,\n",
       "        -0.7013, -0.2438, -0.2054, -0.6411, -0.7891, -0.4216, -0.2778, -0.6405,\n",
       "        -1.0843,  0.3552, -0.6277, -0.4462], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cnn.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52]), torch.Size([52]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cnn.size(),preds_rnn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4808), tensor(0.5000))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_binomial(preds_cnn.to(device),yb.to(device)), accuracy_binomial(preds_rnn.to(device),yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.492603550295858, 0.4955621301775148)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yb,preds_cnn),roc_auc_score(yb,preds_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.038397e-02, -1.795423e-02, -3.457930e-02,  8.671192e-02, ..., -3.003510e-02, -1.899482e-02,  1.426260e-02,\n",
       "        -4.948893e-02],\n",
       "       [-2.453323e-02, -3.018817e-02,  6.663179e-02, -5.793565e-02, ...,  1.840935e-02,  6.371137e-02,  9.835491e-03,\n",
       "        -2.131385e-03],\n",
       "       [ 7.696263e-03, -4.266643e-02, -1.533517e-01,  2.239776e-01, ...,  9.869517e-02,  3.041433e-02,  1.824751e-01,\n",
       "         1.134978e-01],\n",
       "       [ 3.305928e-02,  2.266591e-01, -4.264669e-02,  1.490862e-01, ...,  3.407921e-02, -6.422209e-03,  3.180612e-01,\n",
       "         9.373549e-02],\n",
       "       ...,\n",
       "       [ 6.027538e-02, -5.980809e-02,  1.861691e-01, -3.105092e-02, ..., -2.764457e-02,  1.962678e-02, -2.172215e-03,\n",
       "         6.297247e-02],\n",
       "       [-1.592789e-02, -2.781571e-04,  1.301994e-01,  2.851282e-02, ...,  5.064877e-02,  1.670864e-01,  2.283701e-02,\n",
       "        -8.746398e-03],\n",
       "       [ 4.669700e-02,  3.138980e-02,  1.221957e-02, -3.927753e-02, ..., -1.281436e-01,  1.121320e-01, -3.726090e-03,\n",
       "        -3.777364e-02],\n",
       "       [ 1.677964e-02,  3.287802e-02,  2.598143e-02, -1.484041e-02, ..., -2.587889e-02,  4.438318e-02, -2.407267e-02,\n",
       "        -8.544586e-02]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_lm_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cat_preds_cnn,self.cat_preds_rnn,self.cat_preds_cnn_valid,self.cat_preds_rnn_valid=[],[],[],[]\n",
    "        self.actual,self.trainY=[],[]\n",
    "    \n",
    "    def fit (self,Xb,Yb,Xlen,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds_cnn,preds_rnn,loss_cnn,loss_rnn=self.model(Xb,Yb,Xlen)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc_cnn=self.metric_fn(preds_cnn,Yb.view(-1),self.device)\n",
    "            acc_cnn=acc_cnn.item()\n",
    "            \n",
    "            if mode_train:\n",
    "                self.trainY.append(Yb.view(-1))\n",
    "            else:\n",
    "                self.actual.append(Yb.view(-1))\n",
    "            if mode_train:\n",
    "                self.cat_preds_cnn.append(preds_cnn.data)\n",
    "            else:\n",
    "                self.cat_preds_cnn_valid.append(preds_cnn.data)\n",
    "            \n",
    "            del preds_cnn\n",
    "            \n",
    "            acc_rnn=self.metric_fn(preds_rnn,Yb.view(-1),self.device)\n",
    "            acc_rnn=acc_rnn.item()\n",
    "            if mode_train:\n",
    "                self.cat_preds_rnn.append(preds_rnn.data)\n",
    "            else:\n",
    "                self.cat_preds_rnn_valid.append(preds_rnn.data)\n",
    "            del preds_rnn\n",
    "        \n",
    "        if mode_train:\n",
    "            self.optimizer.zero_grad()\n",
    "            loss_cnn.backward()\n",
    "            loss_rnn.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss_cnn=loss_cnn.item()\n",
    "        myloss_rnn=loss_rnn.item()\n",
    "        del loss_cnn,loss_rnn\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss_cnn,myloss_rnn, acc_cnn,acc_rnn\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss_cnn,epoch_acc_cnn,epoch_loss_rnn,epoch_acc_rnn,i,k=0,0,0,0,0,0\n",
    "        self.model.init_hidden()\n",
    "        \n",
    "        if 1==0:\n",
    "            if mode_train:\n",
    "                self.cat_preds_cnn,self.cat_preds_rnn=[],[]\n",
    "            else:\n",
    "                self.cat_preds_cnn_valid,self.cat_preds_rnn_valid=[],[]\n",
    "        \n",
    "        for Xb,Yb,Xlen in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            Xlen=Xlen.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss_cnn,loss_rnn,acc_cnn,acc_rnn=self.fit(Xb,Yb,Xlen,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss_cnn+=loss_cnn\n",
    "            epoch_acc_cnn+=acc_cnn\n",
    "            epoch_loss_rnn+=loss_rnn\n",
    "            epoch_acc_rnn+=acc_rnn\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss_cnn/(k)}  {epoch_acc_cnn/(k)} {epoch_loss_rnn/(k)}  {epoch_acc_rnn/(k)}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss_cnn=epoch_loss_cnn/len(iterator)\n",
    "        epoch_acc_cnn=epoch_acc_cnn/len(iterator)\n",
    "        epoch_loss_rnn=epoch_loss_rnn/len(iterator)\n",
    "        epoch_acc_rnn=epoch_acc_rnn/len(iterator)\n",
    "            \n",
    "        return epoch_loss_cnn,epoch_acc_cnn,epoch_loss_rnn,epoch_acc_rnn\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "    \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            loss_cnn,acc_cnn,loss_rnn,acc_rnn=self.run_epoch(dltrain,True)\n",
    "            print (f'Epoch:{epoch} Loss CNN:{loss_cnn} Accuracy CNN:{acc_cnn} Loss RNN:{loss_rnn} Accuracy RNN:{acc_rnn}')\n",
    "            lossv_cnn,accv_cnn,lossv_rnn,accv_rnn=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Loss CNN:{lossv_cnn} Accuracy CNN:{accv_cnn} Loss RNN:{lossv_rnn} Accuracy RNN:{accv_rnn}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (59972, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout,\\\n",
    "                 dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n",
    "model_sentiment=model_sentiment.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model_sentiment.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "metric_fn=accuracy_binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 481)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain),len(dlvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model_sentiment,optimizer,accuracy_binomial,device,bptt,50,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5, 0.5, 0.2, 0.5, 0.5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.dropout_e,model_sentiment.dropout,model_sentiment.dropout_o, learner.model.dropout_e,learner.model.dropout,learner.model.dropout_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.7209066641330719  0.5673077124357223 0.7622488522529602  0.5053846347332\n",
      "Batch:100 0.6812536895275116  0.6382692530751228 0.6577768677473068  0.5521154043078422\n",
      "Batch:150 0.6048547821243604  0.6993589995304743 0.5719738262891769  0.6375641264518102\n",
      "Batch:200 0.5394161050021649  0.7320192573964596 0.5264809119701386  0.6915384878218174\n",
      "Batch:250 0.4979997602701187  0.7510769513845443 0.4984626128077507  0.7266923362016677\n",
      "Batch:300 0.46436295439799624  0.763397464454174 0.4806553732355436  0.7537820809086164\n",
      "Batch:350 0.43605880854385237  0.7760989305802753 0.462265433541366  0.7737362947634289\n",
      "Batch:400 0.41262580269947646  0.7859615684300661 0.44621942795813085  0.7896634937077761\n",
      "Batch:450 0.3963404511246416  0.7919231067101161 0.43545450339714686  0.8008974685271582\n",
      "Epoch:0 Loss CNN:0.38706830461468866 Accuracy CNN:0.7956821025657059 Loss RNN:0.42933704584775 Accuracy RNN:0.8073485053130842\n",
      "Batch:50 0.2121230636537075  0.8530769586563111 0.3316090700030327  0.9142308032512665\n",
      "Batch:100 0.20948889285326003  0.8457692646980286 0.3397233445942402  0.915384652018547\n",
      "Batch:150 0.20840013186136883  0.8489743932088216 0.3374899948636691  0.9164102927843729\n",
      "Batch:200 0.20799030281603337  0.8482692638039588 0.33822973392903805  0.9150000369548797\n",
      "Batch:250 0.20974924635887146  0.8454615716934204 0.341805984377861  0.9147692675590515\n",
      "Batch:300 0.21167205361028513  0.8408974691232045 0.34945310816168784  0.914743627111117\n",
      "Batch:350 0.21513791254588535  0.8376373955181666 0.3554568182996341  0.9129121254171644\n",
      "Batch:400 0.21576252045109867  0.8339423403143883 0.3612520089745522  0.9129327301681042\n",
      "Batch:450 0.21885664218001896  0.8301709722148047 0.36898875726593866  0.9112820892863803\n",
      "Epoch:0 Loss CNN:0.22127252820251886 Accuracy CNN:0.8260275383253355 Loss RNN:0.3776738053795701 Accuracy RNN:0.9103750580313795\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list (chain.from_iterable(learner.cat_preds_cnn_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cnn=list(chain.from_iterable(learner.cat_preds_cnn))[-df_train.shape[0]:]\n",
    "pred_rnn=list(chain.from_iterable(learner.cat_preds_rnn))[-df_train.shape[0]:]\n",
    "pred_cnn_valid=list(chain.from_iterable(learner.cat_preds_cnn_valid))[-df_valid.shape[0]:]\n",
    "pred_rnn_valid=list(chain.from_iterable(learner.cat_preds_rnn_valid))[-df_valid.shape[0]:]\n",
    "trainY=list(chain.from_iterable(learner.trainY))[-df_train.shape[0]:]\n",
    "actual=list(chain.from_iterable(learner.actual))[-df_valid.shape[0]:]\n",
    "pred_cnn=[x.item() for x in pred_cnn]\n",
    "pred_rnn=[x.item() for x in pred_rnn]\n",
    "pred_cnn_valid=[x.item() for x in pred_cnn_valid]\n",
    "pred_rnn_valid=[x.item() for x in pred_rnn_valid]\n",
    "trainY=[x.item() for x in trainY]\n",
    "actual=[x.item() for x in actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain=pd.DataFrame({'pred_cnn':expit(pred_cnn),'pred_rnn':expit(pred_rnn)})\n",
    "tempvalid=pd.DataFrame({'pred_cnn':expit(pred_cnn_valid),'pred_rnn':expit(pred_rnn_valid)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "myrf=RandomForestClassifier(n_estimators=100,oob_score=True,n_jobs=-1)\n",
    "myrf.fit(temptrain,trainY)\n",
    "pred_valid=myrf.predict(tempvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8878)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_binomial(torch.FloatTensor(pred_valid),torch.LongTensor(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "myLR=LogisticRegression()\n",
    "myLR.fit(temptrain,trainY)\n",
    "pred_valid=myLR.predict_proba(tempvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_binomial(torch.FloatTensor(pred_valid[:,1]),torch.LongTensor(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.23406909957528113  0.8553846490383148 0.32943603008985517  0.9111538863182068\n",
      "Batch:100 0.23520822510123252  0.855576958656311 0.3386352100968361  0.910000039935112\n",
      "Batch:150 0.23109155784050622  0.8597436265150706 0.3320385064681371  0.9123077313105266\n",
      "Batch:200 0.22860701076686382  0.8601923444867134 0.3285897759348154  0.9105769628286362\n",
      "Batch:250 0.2263640377521515  0.8619231131076813 0.3251665090918541  0.9113077323436737\n",
      "Batch:300 0.22680648686985175  0.8612179843584696 0.32584256236751874  0.9114102961619696\n",
      "Batch:350 0.2255741326510906  0.8607692658901215 0.32778202367680415  0.9115385009561267\n",
      "Batch:400 0.22400653446093202  0.8613942657411099 0.3276078986003995  0.912067347317934\n",
      "Batch:450 0.22541839650935597  0.8604701201121012 0.329388966427909  0.9120085864596896\n",
      "Epoch:0 Loss CNN:0.22785092368257268 Accuracy CNN:0.8614985157199312 Loss RNN:0.3279883096037189 Accuracy RNN:0.9114385485153437\n",
      "Batch:50 0.2110602466762066  0.897307733297348 0.26130406647920607  0.9211538851261138\n",
      "Batch:100 0.20119013544172049  0.8998077327013015 0.254621457234025  0.9238461929559708\n",
      "Batch:150 0.19827869666119416  0.9014102963606516 0.24869366491834322  0.9248718333244323\n",
      "Batch:200 0.19937478901818395  0.9018269625306129 0.24747947040945292  0.9246154236793518\n",
      "Batch:250 0.1991887806802988  0.8996154232025146 0.2497778362929821  0.9243077306747437\n",
      "Batch:300 0.20147213944544395  0.8978846534093221 0.25278860015173754  0.9229487560192744\n",
      "Batch:350 0.2033314487444503  0.8968132252352579 0.2540819181288992  0.9212088297094617\n",
      "Batch:400 0.20362032481469214  0.896682731360197 0.2544074422121048  0.9210096535086632\n",
      "Batch:450 0.20545583470828002  0.8958547397454579 0.25629904197321995  0.9199573034710354\n",
      "Epoch:0 Loss CNN:0.2050472511183819 Accuracy CNN:0.8960299443554234 Loss RNN:0.2560476647097455 Accuracy RNN:0.9199824469500917\n",
      "Batch:50 0.20855319455266  0.8680769598484039 0.3039182472229004  0.9257692658901214\n",
      "Batch:100 0.2059832588583231  0.8707692676782608 0.30290738120675087  0.9205769604444504\n",
      "Batch:150 0.2042548293620348  0.8688461907704671 0.30808931589126587  0.9221795245011648\n",
      "Batch:200 0.20297666976228357  0.8702884969115258 0.3056944955140352  0.9228846529126167\n",
      "Batch:250 0.1990061520934105  0.8743077282905578 0.30050667428970335  0.9242308065891266\n",
      "Batch:300 0.19913337777058285  0.8750000357627868 0.30189686934153237  0.9234615757067999\n",
      "Batch:350 0.19903545577611242  0.8748352009909494 0.30468456310885295  0.9228022350583758\n",
      "Batch:400 0.19768291307613253  0.8750481130182743 0.30321910701692106  0.9235577301681042\n",
      "Batch:450 0.20033327649037044  0.874529950618744 0.303772157298194  0.9223932006624009\n",
      "Epoch:1 Loss CNN:0.2016351343967067 Accuracy CNN:0.8748840920146934 Loss RNN:0.30305089569203325 Accuracy RNN:0.9222573548741252\n",
      "Batch:50 0.2539856154471636  0.9003846502304077 0.25242727786302566  0.9034615755081177\n",
      "Batch:100 0.2365204681828618  0.9011538845300674 0.24537067644298077  0.9115384984016418\n",
      "Batch:150 0.2295222377528747  0.9047436292966207 0.2383462583522002  0.9130769602457682\n",
      "Batch:200 0.23181468388065696  0.9042308089137078 0.2381496938318014  0.9126923450827599\n",
      "Batch:250 0.23427780881524085  0.9023846549987793 0.24096899050474166  0.9113077304363251\n",
      "Batch:300 0.2361109159886837  0.9001923473676046 0.2444072484970093  0.910256448785464\n",
      "Batch:350 0.23598892639790262  0.8990110286644527 0.24546340408069747  0.9101099288463592\n",
      "Batch:400 0.23582300746813417  0.8987981159985066 0.24662196086719632  0.9104808081686496\n",
      "Batch:450 0.23640731245279312  0.8971367906199561 0.24953731743825808  0.910384654071596\n",
      "Epoch:1 Loss CNN:0.23424936366304291 Accuracy CNN:0.8979730116602289 Loss RNN:0.24854822935470672 Accuracy RNN:0.9106389315113457\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cnn=list(chain.from_iterable(learner.cat_preds_cnn))[-df_train.shape[0]:]\n",
    "pred_rnn=list(chain.from_iterable(learner.cat_preds_rnn))[-df_train.shape[0]:]\n",
    "pred_cnn_valid=list(chain.from_iterable(learner.cat_preds_cnn_valid))[-df_valid.shape[0]:]\n",
    "pred_rnn_valid=list(chain.from_iterable(learner.cat_preds_rnn_valid))[-df_valid.shape[0]:]\n",
    "trainY=list(chain.from_iterable(learner.trainY))[-df_train.shape[0]:]\n",
    "actual=list(chain.from_iterable(learner.actual))[-df_valid.shape[0]:]\n",
    "pred_cnn=[x.item() for x in pred_cnn]\n",
    "pred_rnn=[x.item() for x in pred_rnn]\n",
    "pred_cnn_valid=[x.item() for x in pred_cnn_valid]\n",
    "pred_rnn_valid=[x.item() for x in pred_rnn_valid]\n",
    "trainY=[x.item() for x in trainY]\n",
    "actual=[x.item() for x in actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain=pd.DataFrame({'pred_cnn':expit(pred_cnn),'pred_rnn':expit(pred_rnn)})\n",
    "tempvalid=pd.DataFrame({'pred_cnn':expit(pred_cnn_valid),'pred_rnn':expit(pred_rnn_valid)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "myrf=RandomForestClassifier(n_estimators=100,oob_score=True,n_jobs=-1)\n",
    "myrf.fit(temptrain,trainY)\n",
    "pred_valid=myrf.predict(tempvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9068)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_binomial(torch.FloatTensor(pred_valid),torch.LongTensor(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.2969422796368599  0.883076959848404\n",
      "Batch:100 0.30535467609763145  0.873846189379692\n",
      "Batch:150 0.2947099809845289  0.8794872144858042\n",
      "Batch:200 0.2945930130034685  0.8787500348687172\n",
      "Batch:250 0.2967405049800873  0.8763077273368836\n",
      "Batch:300 0.30113854641715687  0.8746795225143432\n",
      "Batch:350 0.3023779807771955  0.8745055295739855\n",
      "Batch:400 0.30335031550377606  0.8748558042943477\n",
      "Batch:450 0.3062936148047447  0.8737179838286506\n",
      "Epoch:0 Loss:0.3062660424600272\n",
      "Batch:50 0.25533897399902344  0.9011538815498352\n",
      "Batch:100 0.24975233837962152  0.8992308080196381\n",
      "Batch:150 0.24546665102243423  0.9011538867155711\n",
      "Batch:200 0.24410639192909003  0.9015385013818741\n",
      "Batch:250 0.2465755670964718  0.9001538860797882\n",
      "Batch:300 0.25020610007146993  0.8977564495801925\n",
      "Batch:350 0.25084444512213977  0.8967033353873661\n",
      "Batch:400 0.25189696880057455  0.895961577296257\n",
      "Batch:450 0.2543337704241276  0.8949145681328243\n",
      "Epoch:0 Loss:0.3062660424600272 Accuracy:0.8738565841484467 Loss:0.2533036331160153 Accuracy:0.8951903465136173\n",
      "Batch:50 0.2607602083683014  0.8915384948253632\n",
      "Batch:100 0.27183785930275917  0.8840384966135025\n",
      "Batch:150 0.2774001429478327  0.8850000349680582\n",
      "Batch:200 0.28211689852178096  0.882884649336338\n",
      "Batch:250 0.28187499994039533  0.8817692651748658\n",
      "Batch:300 0.2856948565443357  0.8803205474217732\n",
      "Batch:350 0.28690655378358704  0.8809890457562037\n",
      "Batch:400 0.2873973524384201  0.8811058041453361\n",
      "Batch:450 0.2897278724279669  0.8806410608026717\n",
      "Epoch:1 Loss:0.2915135994553566\n",
      "Batch:50 0.2533652025461197  0.9088461923599244\n",
      "Batch:100 0.24606497794389726  0.9082692676782608\n",
      "Batch:150 0.24138824532429376  0.9106410618623098\n",
      "Batch:200 0.24048690252006055  0.9085577291250229\n",
      "Batch:250 0.24292080223560333  0.9067692682743073\n",
      "Batch:300 0.24337974501152834  0.9058333708842595\n",
      "Batch:350 0.24358543340648925  0.9038461908272335\n",
      "Batch:400 0.24405385091900825  0.9022115755081177\n",
      "Batch:450 0.2462988649143113  0.9009829425811767\n",
      "Epoch:1 Loss:0.2915135994553566 Accuracy:0.8798656996471222 Loss:0.24510090400052417 Accuracy:0.9015712827258199\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.2612586760520935  0.8907692694664001\n",
      "Batch:100 0.2686653547734022  0.891923114657402\n",
      "Batch:150 0.269331968575716  0.8923077305157979\n",
      "Batch:200 0.26797251276671885  0.8938461923599244\n",
      "Batch:250 0.26805242785811423  0.8940769622325897\n",
      "Batch:300 0.27078387459119163  0.8919872176647187\n",
      "Batch:350 0.2732546100871904  0.8908791586330959\n",
      "Batch:400 0.2743937312811613  0.8897115762531758\n",
      "Batch:450 0.273371879508098  0.8905983283784654\n",
      "Epoch:0 Loss:0.2750476974676404\n",
      "Batch:50 0.25235510617494583  0.9084615755081177\n",
      "Batch:100 0.24394078984856604  0.9063461941480636\n",
      "Batch:150 0.23914532800515492  0.9089743995666504\n",
      "Batch:200 0.2367671152204275  0.9108654245734215\n",
      "Batch:250 0.23835493183135986  0.9083846547603607\n",
      "Batch:300 0.2389568299551805  0.9066026033957799\n",
      "Batch:350 0.24093207263520786  0.9061538852964128\n",
      "Batch:400 0.24173436006531118  0.9052404238283634\n",
      "Batch:450 0.24402131956484582  0.9039316626389822\n",
      "Epoch:0 Loss:0.2750476974676404 Accuracy:0.8897409622485821 Loss:0.24454572651217732 Accuracy:0.9035903152210053\n",
      "Batch:50 0.27542655378580094  0.8907692682743072\n",
      "Batch:100 0.26507404275238516  0.8930769610404968\n",
      "Batch:150 0.27578557456533115  0.8869231140613556\n",
      "Batch:200 0.27231911588460206  0.8890384992957115\n",
      "Batch:250 0.266231288433075  0.8913077299594879\n",
      "Batch:300 0.2681507701675097  0.8910897809267044\n",
      "Batch:350 0.26820761024951933  0.8903297078609467\n",
      "Batch:400 0.26788598062470553  0.8913461911678314\n",
      "Batch:450 0.26981658866008124  0.8907265329360962\n",
      "Epoch:1 Loss:0.2694577852306644\n",
      "Batch:50 0.24446795389056206  0.907307733297348\n",
      "Batch:100 0.23537132382392884  0.9096154230833053\n",
      "Batch:150 0.23136856019496918  0.9107692694664001\n",
      "Batch:200 0.22984262518584728  0.9105769616365432\n",
      "Batch:250 0.2324460800588131  0.9083077309131622\n",
      "Batch:300 0.23460271425545215  0.9072436287005743\n",
      "Batch:350 0.23439985847898892  0.907033006634031\n",
      "Batch:400 0.23558324351906776  0.9064904244244099\n",
      "Batch:450 0.2368269481923845  0.905769270128674\n",
      "Epoch:1 Loss:0.2694577852306644 Accuracy:0.8911402899609286 Loss:0.23575219276541237 Accuracy:0.9065728844327391\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.2526996849477291  0.906153883934021\n",
      "Batch:100 0.24210990980267524  0.9075000375509262\n",
      "Batch:150 0.24906169007221857  0.9008974726994833\n",
      "Batch:200 0.2509264434874058  0.8994231143593788\n",
      "Batch:250 0.2495920861363411  0.900000037431717\n",
      "Batch:300 0.2506700047602256  0.8996154216925303\n",
      "Batch:350 0.25195729660136357  0.8992857515811921\n",
      "Batch:400 0.2543211235664785  0.8982211907207965\n",
      "Batch:450 0.2534333635866642  0.89799149023162\n",
      "Epoch:0 Loss:0.25387325458491916\n",
      "Batch:50 0.24999444887042047  0.9007692730426788\n",
      "Batch:100 0.2381196627020836  0.9040385007858276\n",
      "Batch:150 0.23106946304440498  0.9080769618352255\n",
      "Batch:200 0.2290224463492632  0.9095192700624466\n",
      "Batch:250 0.2315045661330223  0.9073846547603607\n",
      "Batch:300 0.23349443073074022  0.9061538861195246\n",
      "Batch:350 0.2334676503070763  0.9058791608469827\n",
      "Batch:400 0.23487236255779861  0.904903885871172\n",
      "Batch:450 0.23705482578939863  0.9045726892683241\n",
      "Epoch:0 Loss:0.25387325458491916 Accuracy:0.8980369795880546 Loss:0.2375039369905689 Accuracy:0.9043739403359855\n",
      "Batch:50 0.2549225839972496  0.900769270658493\n",
      "Batch:100 0.25487528890371325  0.8982692694664002\n",
      "Batch:150 0.2493559248248736  0.9015384995937348\n",
      "Batch:200 0.24702304776757955  0.9033654242753982\n",
      "Batch:250 0.2518583036959171  0.9014615769386292\n",
      "Batch:300 0.25308750472962854  0.9008333718776703\n",
      "Batch:350 0.253212406039238  0.8999450933933258\n",
      "Batch:400 0.2551231593079865  0.8993750385940075\n",
      "Batch:450 0.25471313460005657  0.8993162780337863\n",
      "Epoch:1 Loss:0.2545434121437479\n",
      "Batch:50 0.24065624967217444  0.9042308104038238\n",
      "Batch:100 0.23192795392125845  0.905769270658493\n",
      "Batch:150 0.22862434593339762  0.9062820903460185\n",
      "Batch:200 0.22539983673021197  0.9094231152534484\n",
      "Batch:250 0.2312842129021883  0.9065384995937348\n",
      "Batch:300 0.23451365650941927  0.9042949100335439\n",
      "Batch:350 0.23579976874802794  0.9041209168093545\n",
      "Batch:400 0.23714832657016813  0.904038498699665\n",
      "Batch:450 0.24066734238631196  0.9034188404348161\n",
      "Epoch:1 Loss:0.2545434121437479 Accuracy:0.9000360216023768 Loss:0.23962841995385728 Accuracy:0.9043019722504329\n",
      "Batch:50 0.2526399214565754  0.9003846561908722\n",
      "Batch:100 0.24921299137175082  0.9015385007858276\n",
      "Batch:150 0.24169398084282875  0.9037179879347483\n",
      "Batch:200 0.24377805307507516  0.9032692700624466\n",
      "Batch:250 0.24212965276837348  0.9039231162071228\n",
      "Batch:300 0.2417903296649456  0.9027564493815105\n",
      "Batch:350 0.24481004895908492  0.9015934448582785\n",
      "Batch:400 0.2470111388526857  0.8996154224872589\n",
      "Batch:450 0.24533041164278985  0.9008547390831841\n",
      "Epoch:2 Loss:0.2462734821525532\n",
      "Batch:50 0.25185428738594057  0.9026923489570617\n",
      "Batch:100 0.24154768615961075  0.9075000387430191\n",
      "Batch:150 0.23541806936264037  0.9079487578074137\n",
      "Batch:200 0.23279604904353618  0.9110577318072319\n",
      "Batch:250 0.23410877376794814  0.9099231157302856\n",
      "Batch:300 0.23583138545354207  0.9073077313105266\n",
      "Batch:350 0.2374852721605982  0.9055494896003178\n",
      "Batch:400 0.2373906622454524  0.9058654238283634\n",
      "Batch:450 0.2390692134698232  0.9055983297030131\n",
      "Epoch:2 Loss:0.2462734821525532 Accuracy:0.9001879477699185 Loss:0.24018542917751226 Accuracy:0.9046538050853785\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5, 0.5, 0.2, 0.5, 0.5)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.dropout_e,model_sentiment.dropout,model_sentiment.dropout_o, learner.model.dropout_e,learner.model.dropout,learner.model.dropout_o"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_sentiment.set_dropouts(0.6,0.6,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['lr']=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['weight_decay']=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.17109055951237678  0.9392308056354522\n",
      "Batch:100 0.16905868373811245  0.9371154230833053\n",
      "Batch:150 0.17664438232779503  0.9348718333244324\n",
      "Batch:200 0.1798207350820303  0.9339423456788063\n",
      "Batch:250 0.1809715024828911  0.9327692685127258\n",
      "Batch:300 0.1834358198940754  0.9312179865439733\n",
      "Batch:350 0.18457236400672367  0.9297802577699934\n",
      "Batch:400 0.18626736279577016  0.9287500384449959\n",
      "Batch:450 0.1895132341484229  0.9273504655890995\n",
      "Epoch:0 Loss:0.19055645330470217\n",
      "Batch:50 0.21328009873628617  0.9219231164455414\n",
      "Batch:100 0.20903003100305795  0.9209615767002106\n",
      "Batch:150 0.2022938776264588  0.9224359353383382\n",
      "Batch:200 0.2003036970458925  0.9242308074235916\n",
      "Batch:250 0.20359245420992375  0.9223077306747437\n",
      "Batch:300 0.20705148369073867  0.9202564483880997\n",
      "Batch:350 0.2082733883176531  0.9190659723963056\n",
      "Batch:400 0.20749923232942818  0.9200000385940075\n",
      "Batch:450 0.21062520899706416  0.9186752523316277\n",
      "Epoch:0 Loss:0.19055645330470217 Accuracy:0.9270910344351849 Loss:0.21082548436218884 Accuracy:0.9188190054249119\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['weight_decay']=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['lr']=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.22599529027938842  0.9088461911678314\n",
      "Batch:100 0.22253445766866206  0.9125000387430191\n",
      "Batch:150 0.21690935830275218  0.9138461907704671\n",
      "Batch:200 0.21548882938921451  0.9136538833379746\n",
      "Batch:250 0.21340395921468736  0.9152308073043823\n",
      "Batch:300 0.2117832124233246  0.9163461921612421\n",
      "Batch:350 0.21206261696560041  0.9160989395209721\n",
      "Batch:400 0.21404753772541882  0.9146154230833053\n",
      "Batch:450 0.2115788251823849  0.9156837994522519\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type sentiment_classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{PATH}/inter/sentiment_model_nounfreeze_state_dict_0.924')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/sentiment_learner_nounfreeze_state_dict_0.924')\n",
    "torch.save (model_sentiment,f'{PATH}/inter/sentiment_model_nounfreeze_0.924')\n",
    "torch.save (optimizer,f'{PATH}/inter/sentiment_optimizer_nounfreeze_0.924')\n",
    "torch.save (learner,f'{PATH}/inter/sentiment_learner_nounfreeze_0.924')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment=torch.load(f'{PATH}/inter/sentiment_model_nounfreeze_0.924')\n",
    "optimizer=torch.load(f'{PATH}/inter/sentiment_optimizer_nounfreeze_0.924')\n",
    "learner=torch.load(f'{PATH}/inter/sentiment_learner_nounfreeze_0.924')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['lr']=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.19316751204431057  0.925384657382965\n",
      "Batch:100 0.19021366197615863  0.925384657382965\n",
      "Batch:150 0.18507408944269022  0.9284615794817607\n",
      "Batch:200 0.18012874262407422  0.9291346555948258\n",
      "Batch:250 0.18090652391314507  0.9296154243946075\n",
      "Batch:300 0.18077860546608765  0.9297436296939849\n",
      "Batch:350 0.180609092350517  0.9303846549987793\n",
      "Batch:400 0.1805749541055411  0.9303365784883499\n",
      "Batch:450 0.18168599167631733  0.9298290995756785\n",
      "Epoch:0 Loss:0.18122180081950404\n",
      "Batch:50 0.23026843160390853  0.9238461923599243\n",
      "Batch:100 0.21336775977164507  0.9261538875102997\n",
      "Batch:150 0.20659958479305107  0.927692346572876\n",
      "Batch:200 0.20436845902353526  0.9275000405311584\n",
      "Batch:250 0.20656096981465816  0.9261538863182068\n",
      "Batch:300 0.20735313262790442  0.9250641421476999\n",
      "Batch:350 0.2075942880234548  0.9231319076674325\n",
      "Batch:400 0.20715798472985625  0.9229327318072319\n",
      "Batch:450 0.20928612556722428  0.9220940562089285\n",
      "Epoch:0 Loss:0.18122180081950404 Accuracy:0.9302215330813878 Loss:0.2083083272228122 Accuracy:0.9224052845564304\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.1795610073208809  0.9334615790843963\n",
      "Batch:100 0.17820095729082822  0.9340385031700135\n",
      "Batch:150 0.17120263000329336  0.934487220843633\n",
      "Batch:200 0.17333494383841752  0.9329808095097541\n",
      "Batch:250 0.17416198022663593  0.93192311668396\n",
      "Batch:300 0.17471165298173824  0.9318590136369069\n",
      "Batch:350 0.17421947273824895  0.9318132259164538\n",
      "Batch:400 0.1726349769625813  0.9328846541047097\n",
      "Batch:450 0.17152835315300358  0.933333372010125\n",
      "Epoch:0 Loss:0.17269179193213924\n",
      "Batch:50 0.23322612002491952  0.9242308080196381\n",
      "Batch:100 0.21592979423701764  0.9257692712545394\n",
      "Batch:150 0.2089104947944482  0.9280769622325897\n",
      "Batch:200 0.20654483183287084  0.927692346572876\n",
      "Batch:250 0.2095902508124709  0.9263077313899994\n",
      "Batch:300 0.20991972533985973  0.9253846542040507\n",
      "Batch:350 0.21033208885895355  0.923022016797747\n",
      "Batch:400 0.20985105094965548  0.9228846547007561\n",
      "Batch:450 0.2116426052028934  0.9220513208707174\n",
      "Epoch:0 Loss:0.17269179193213924 Accuracy:0.9328082907720316 Loss:0.21045327684193416 Accuracy:0.9222573553697979\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type sentiment_classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{PATH}/inter/sentiment_model_nounfreeze_state_dict_0.917')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/sentiment_learner_nounfreeze_state_dict_0.917')\n",
    "torch.save (model_sentiment,f'{PATH}/inter/sentiment_model_nounfreeze_0.917')\n",
    "torch.save (optimizer,f'{PATH}/inter/sentiment_optimizer_nounfreeze_0.917')\n",
    "torch.save (learner,f'{PATH}/inter/sentiment_learner_nounfreeze_0.917')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.1757665029168129  0.9338461911678314\n",
      "Batch:100 0.17884126387536525  0.9323077297210693\n",
      "Batch:150 0.17157089300453662  0.9365384995937347\n",
      "Batch:200 0.1665740057453513  0.9388461914658547\n",
      "Batch:250 0.16849402721226214  0.9384615759849548\n",
      "Batch:300 0.16642002327988545  0.9392949092388153\n",
      "Batch:350 0.16435486163944005  0.9398901465960912\n",
      "Batch:400 0.1623965109186247  0.9409615746140481\n",
      "Batch:450 0.16075962524033255  0.9414102921220991\n",
      "Epoch:0 Loss:0.16170276429217595\n",
      "Batch:50 0.22108415484428406  0.9123077321052552\n",
      "Batch:100 0.21340429924428464  0.9176923459768296\n",
      "Batch:150 0.20557850728432336  0.9205128566424052\n",
      "Batch:200 0.1989787089265883  0.9236538824439049\n",
      "Batch:250 0.2013720786422491  0.921923113822937\n",
      "Batch:300 0.2017382326349616  0.9211538823445639\n",
      "Batch:350 0.20419149936309883  0.9204945426327842\n",
      "Batch:400 0.204031760757789  0.9209134986996651\n",
      "Batch:450 0.20522147292064297  0.9203419176737467\n",
      "Epoch:0 Loss:0.16170276429217595 Accuracy:0.9410163481369336 Loss:0.20461497814423577 Accuracy:0.920818044589116\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.11615589462220668  0.966538497209549\n",
      "Batch:100 0.10260744299739599  0.9701923406124116\n",
      "Batch:150 0.10320262432098389  0.9685897755622864\n",
      "Batch:200 0.10043475738726557  0.9695192635059356\n",
      "Batch:250 0.09697593061625957  0.9700769543647766\n",
      "Batch:300 0.09517815880477429  0.97019233862559\n",
      "Batch:350 0.09467971860031997  0.9702747559547424\n",
      "Batch:400 0.09466664283769205  0.9705769535899162\n",
      "Batch:450 0.09382010911901792  0.9706837913725112\n",
      "Epoch:0 Loss:0.09396658818045797\n",
      "Batch:50 0.24926649011671542  0.9138461947441101\n",
      "Batch:100 0.2419789445772767  0.9176923471689225\n",
      "Batch:150 0.23338562476138275  0.9180769606431325\n",
      "Batch:200 0.2237020975537598  0.9211538836359978\n",
      "Batch:250 0.22683872967958452  0.9197692685127258\n",
      "Batch:300 0.22746217250823975  0.9194872166713078\n",
      "Batch:350 0.23043268159031868  0.9186264107908522\n",
      "Batch:400 0.23017218199558556  0.9188942676782608\n",
      "Batch:450 0.2322108591016796  0.9183333708180321\n",
      "Epoch:0 Loss:0.09396658818045797 Accuracy:0.9705901470600691 Loss:0.23128337080042477 Accuracy:0.9188869719445829\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.09524211082607507  0.9680769574642182\n",
      "Batch:100 0.093828199878335  0.9686538773775101\n",
      "Batch:150 0.0919878846531113  0.9687179811795552\n",
      "Batch:200 0.09395078460685909  0.9689423388242722\n",
      "Batch:250 0.09284830520302058  0.9690769546031952\n",
      "Batch:300 0.09200737948218982  0.9695513131221135\n",
      "Batch:350 0.09359771828566278  0.9695055254868099\n",
      "Batch:400 0.09153297192882746  0.9706731064617634\n",
      "Batch:450 0.09010110232565138  0.971068405840132\n",
      "Epoch:0 Loss:0.09070706779714248\n",
      "Batch:50 0.23427742831408976  0.9230769610404969\n",
      "Batch:100 0.22739623751491309  0.9246154230833054\n",
      "Batch:150 0.22029945831745862  0.9264102943738302\n",
      "Batch:200 0.21663093800656497  0.9272115764021873\n",
      "Batch:250 0.216403607301414  0.927153883934021\n",
      "Batch:300 0.2173488519154489  0.9263461919625601\n",
      "Batch:350 0.21949118124055012  0.9253846536363874\n",
      "Batch:400 0.2178897394472733  0.92600965321064\n",
      "Batch:450 0.2196268634787864  0.9252137135134803\n",
      "Epoch:0 Loss:0.09070706779714248 Accuracy:0.9704582101342089 Loss:0.21936258052140784 Accuracy:0.9254558194204081\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
