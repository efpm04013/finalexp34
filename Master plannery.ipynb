{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os \n",
    "import fastai\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "PATH=\"/home/kirana/Documents/phd/final\"\n",
    "DATAPATH=\"/home/kirana/Documents/phd/data/aclImdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_train,df_valid,df_test,itos, train_tokens, valid_tokens, test_tokens, trn_lm, val_lm, test_lm]=pickle.load(open(f'{PATH}/inter/dfs_tokens_fastai.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.concat([df_train,df_valid],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid=df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.loc[df_train['label']<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0</td>\n",
       "      <td>I've noticed how all the other reviews of this...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>0</td>\n",
       "      <td>I went on a visit to one of my relatives a whi...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0</td>\n",
       "      <td>Darcy and her young daughter Pamela are headin...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0</td>\n",
       "      <td>Battlestar Gallactica was so great because it ...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0</td>\n",
       "      <td>Any movie with \"National Lampoon\" in the title...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3218      0  I've noticed how all the other reviews of this...   \n",
       "6854      0  I went on a visit to one of my relatives a whi...   \n",
       "2697      0  Darcy and her young daughter Pamela are headin...   \n",
       "5747      0  Battlestar Gallactica was so great because it ...   \n",
       "8731      0  Any movie with \"National Lampoon\" in the title...   \n",
       "\n",
       "                                                  words  \\\n",
       "3218  [ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...   \n",
       "6854  [ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...   \n",
       "2697  [ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...   \n",
       "5747  [ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...   \n",
       "8731  [ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...   \n",
       "\n",
       "                                                 tokens  \n",
       "3218  [41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...  \n",
       "6854  [41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...  \n",
       "2697  [41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...  \n",
       "5747  [41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...  \n",
       "8731  [41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=52 # 52 - Jeremey, 20 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt= 70 #70 - Jeremey, 35 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0</td>\n",
       "      <td>I've noticed how all the other reviews of this...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>0</td>\n",
       "      <td>I went on a visit to one of my relatives a whi...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0</td>\n",
       "      <td>Darcy and her young daughter Pamela are headin...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0</td>\n",
       "      <td>Battlestar Gallactica was so great because it ...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0</td>\n",
       "      <td>Any movie with \"National Lampoon\" in the title...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3218      0  I've noticed how all the other reviews of this...   \n",
       "6854      0  I went on a visit to one of my relatives a whi...   \n",
       "2697      0  Darcy and her young daughter Pamela are headin...   \n",
       "5747      0  Battlestar Gallactica was so great because it ...   \n",
       "8731      0  Any movie with \"National Lampoon\" in the title...   \n",
       "\n",
       "                                                  words  \\\n",
       "3218  [ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...   \n",
       "6854  [ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...   \n",
       "2697  [ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...   \n",
       "5747  [ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...   \n",
       "8731  [ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...   \n",
       "\n",
       "                                                 tokens  \n",
       "3218  [41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...  \n",
       "6854  [41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...  \n",
       "2697  [41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...  \n",
       "5747  [41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...  \n",
       "8731  [41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', 'the', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padlen=1400\n",
    "padding_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['n_tok']=df_train['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       304.945840\n",
       "std        224.981807\n",
       "min         16.000000\n",
       "25%        166.000000\n",
       "50%        228.000000\n",
       "75%        371.000000\n",
       "max       3354.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['n_tok']=df_valid['tokens'].apply(len)\n",
    "df_valid.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['n_tok']=df_test['tokens'].apply(len)\n",
    "df_test.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    x=df_train['tokens'].values[i]\n",
    "    y=df_train['label'].values[i]    \n",
    "    out=np.ones(padlen)\n",
    "    if len(x) < padlen:\n",
    "        out[:len(x)]=x\n",
    "    else:\n",
    "        out=x[:padlen]\n",
    "    print (out)\n",
    "    print (y)\n",
    "    print (len(out))\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64, 1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64, 1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts(), df_valid['label'].value_counts(),df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 5), (25000, 5))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_sentiment (Dataset):\n",
    "    def __init__ (self,df,bs,padlen=64,xvar='tokens',yvar='label',len_var='n_tok',padding_idx=1):\n",
    "        self.x,self.y,self.padlen,self.padding_idx,self.len_var,self.bs=\\\n",
    "            df[xvar],df[yvar],padlen,padding_idx,df[len_var],bs\n",
    "        self.len_var=self.len_var.clip(0,padlen)\n",
    "    \n",
    "    def pad (self,x):\n",
    "        out=np.ones(self.padlen)*self.padding_idx\n",
    "        out=out.astype(int)\n",
    "        if len(x)>=self.padlen:\n",
    "            out[:]=x[:self.padlen]\n",
    "        else:\n",
    "            out[:len(x)]=x\n",
    "        return out\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        return self.pad(self.x.iloc[idx]),self.y.iloc[idx],self.len_var.iloc[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padlen=max(df_train['n_tok'])\n",
    "padlen=1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=ds_sentiment(df_train,bs,padlen)\n",
    "dsvalid=ds_sentiment(df_valid,bs,padlen)\n",
    "dstest=ds_sentiment(df_test,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain=DataLoader(dstrain,bs,True)\n",
    "dlvalid=DataLoader(dsvalid,bs,False)\n",
    "dltest=DataLoader(dstest,bs,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb,yb,xlen in dltrain:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1]]),\n",
       " tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "         1, 0, 0, 1]),\n",
       " tensor([ 251,  467,  168,  200,  969, 1400,  320,  152,  746,  377,  539,  290,\n",
       "          178,  560,  655,  211,  754,  157,  183,  419,  328,  293,  174,  149,\n",
       "          214, 1051,  147,  241,  134,  160,  326,  346,  302,  487,  209,  746,\n",
       "          317,  683,  678,  262,  345,  251,  257,  397,  160,  224,  163,  300,\n",
       "          433,  311,  176,  196]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb, xlen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cyclical learning rates\n",
    "\tvary learning rate by epoch between two values\n",
    "\t\n",
    "\n",
    "bptt=70\n",
    "n_emb=400\n",
    "n_hid=1150\n",
    "n_layers=3\n",
    "bs=48 # whatever is the max that can fit in memory\n",
    "\n",
    "# shuffle dataset\n",
    "# sort the data by length\n",
    "\n",
    "\n",
    "class ds_sentiment(Dataset):\n",
    "\tdef __init__(self,x,y):\n",
    "\t\tself.x,self.y=x,y\n",
    "\t\n",
    "\tdef __getitem__(self,idx):\n",
    "\t\treturn self.x[idx],self.y[idx]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 70)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp=len(itos)\n",
    "n_emb=400 #650\n",
    "n_hidden=400#400\n",
    "n_layers= 2 # 2\n",
    "dropout=0.5 # 0.5\n",
    "wd=1e-6\n",
    "bidirectional=True\n",
    "dropout_e=0.2 # 0.5\n",
    "dropout_o=0.5 #0.5\n",
    "n_out=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 1400]), torch.Size([52]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape,xlen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', 'the', '.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool1d(5)\n",
    "input = torch.randn(1, 64, 8)\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_classifier (nn.Module):\n",
    "    def __init__(self,n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,pretrain_mtx=None,n_out=1,padding_idx=1,n_filters=100,filter_sizes=[3,4,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device,self.pretrain_mtx,self.padding_idx=\\\n",
    "                            n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,pretrain_mtx,padding_idx\n",
    "        self.n_out,self.n_filters,self.filter_sizes=n_out,n_filters,filter_sizes\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        \n",
    "        self.create_architecture()\n",
    "        if pretrain_mtx is not None:\n",
    "            print (f'initializing glove with {pretrain_mtx.shape}')\n",
    "            self.initialize_glove()\n",
    "        self.init_hidden()\n",
    "        self.criterion=nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def set_dropouts(self, dropout, dropout_o, dropout_e):\n",
    "        self.dropout, self.dropout_o, self.dropout_e = dropout, dropout_o, dropout_e\n",
    "    \n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=False\n",
    "         \n",
    "    def unfreeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=True\n",
    "\n",
    "    def initialize_glove(self):\n",
    "        self.encoder.weight.data.copy_(torch.Tensor(self.pretrain_mtx))\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "      \n",
    "   \n",
    "\n",
    "    def create_architecture(self):\n",
    "        ###################################\n",
    "        # Embedding layer - common to both\n",
    "        ###################################\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb,padding_idx=self.padding_idx)\n",
    "        \n",
    "        #######################################\n",
    "        # For RNN #############################\n",
    "        #######################################\n",
    "        # Embedding Layer: Embedding layer just maps each word to an index. n_inp to n_emb mapping is all it does\n",
    "            # input to this is of shape n_batch * n_seq\n",
    "         # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "          # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        self.avg_pool1d=torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool1d=torch.nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        #self.fc2=nn.Linear(self.n_hidden*3,self.n_out)\n",
    "\n",
    "        #self.log_softmax=nn.LogSoftmax()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    \n",
    "        #######################################\n",
    "        # For CNN #############################\n",
    "        #######################################    \n",
    "        #embedding dimension is the \"depth\" of the filter and the number of tokens in the sentence is the width.\n",
    "        self.conv_0=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[0])\n",
    "        self.conv_1=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[1])\n",
    "        self.conv_2=torch.nn.Conv1d(self.n_emb,self.n_filters,kernel_size=self.filter_sizes[2])\n",
    "        \n",
    "        self.fc=nn.Linear(len(self.filter_sizes)*self.n_filters+self.n_hidden*4,self.n_out)\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        # \n",
    "        \n",
    "        ###################################\n",
    "        ## MERGE THE BOTH OF THEM\n",
    "        \n",
    "        self.logisticreg=nn.Linear(2,1)\n",
    "        \n",
    "    def forward (self,Xb,Yb,Xb_lengths):\n",
    "        \n",
    "        ####RNN PORTION\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "        packed_embs = pack_padded_sequence(embs,Xb_lengths,batch_first=True, enforce_sorted=False)\n",
    "        lstm_out,(hidden,cell)=self.lstm(packed_embs)\n",
    "        lstm_out,lengths=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "        hidden = self.dropout_op(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        avg_pool=self.avg_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        max_pool=self.max_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        #max_avg=torch.cat([avg_pool,max_pool],dim=1)\n",
    "        \n",
    "       \n",
    "        \n",
    "        #CNN Portion\n",
    "        new_embs=embs.permute(0,2,1)\n",
    "        \n",
    "        conved_0=torch.relu(self.conv_0(new_embs))\n",
    "        conved_1=torch.relu(self.conv_1(new_embs))\n",
    "        conved_2=torch.relu(self.conv_2(new_embs))\n",
    "        \n",
    "        \n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_0.shape[2])\n",
    "        pooled_0=max_pool1d(conved_0).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_1.shape[2])\n",
    "        pooled_1=max_pool1d(conved_1).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_2.shape[2])\n",
    "        pooled_2=max_pool1d(conved_2).squeeze(2)\n",
    "\n",
    "        cat_cnn = self.dropout_op(torch.cat([pooled_0,pooled_1,pooled_2],dim=1))\n",
    "        \n",
    "        big_out=torch.cat([cat_cnn,hidden,max_pool],dim=1)\n",
    "        preds=self.fc(big_out)\n",
    "       \n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        #loss_rnn=self.criterion(preds_cnn,Yb.contiguous().float().view(-1,1)) \n",
    "        #loss_cnn=self.criterion(preds_rnn,Yb.contiguous().float().view(-1,1))\n",
    "        \n",
    "        loss_master=self.criterion(preds,Yb.contiguous().float().view(-1,1))\n",
    "        #loss=0.7*loss_rnn+0.3*loss_cnn\n",
    "        #preds=(preds_cnn*0.3+preds_rnn*0.7)\n",
    "        \n",
    "        return preds.view(-1),loss_master,preds.view(-1),loss_master\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds,actual, device=\"cpu\", cutoff=0.5):\n",
    "    preds=torch.sigmoid(preds)\n",
    "    zeros=torch.zeros(len(preds)).to(device)\n",
    "    ones = torch.ones(len(preds)).to(device)\n",
    "\n",
    "    preds=torch.where(preds>cutoff,ones,zeros)\n",
    "    correct=torch.round(preds).long()==actual\n",
    "    return correct.float().sum()/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds, y, device=\"cpu\", cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    y=y.float()\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lm_weights=pickle.load(open(f'{PATH}/inter/pretrained_lm_weights','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==0:\n",
    "    model=torch.load (f'{PATH}/inter/model_awd_lstm')\n",
    "    pretrained_lm_weights=model.encoder.weight.data.cpu().numpy()\n",
    "    import pickle\n",
    "    pickle.dump(pretrained_lm_weights,open(f'{PATH}/inter/pretrained_lm_weights','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if model forward works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59972, 400, 400, 2, True, 52, 'cpu', 0.2, 0.5, 0.5, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout_o,dropout,n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (59972, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=dropout_e,dropout=dropout,\\\n",
    "                 dropout_o=dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 30,883,804 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model_sentiment):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0904, -0.0180, -0.0346,  ..., -0.0190,  0.0143, -0.0495],\n",
      "        [-0.0245, -0.0302,  0.0666,  ...,  0.0637,  0.0098, -0.0021],\n",
      "        [ 0.0077, -0.0427, -0.1534,  ...,  0.0304,  0.1825,  0.1135],\n",
      "        ...,\n",
      "        [-0.0159, -0.0003,  0.1302,  ...,  0.1671,  0.0228, -0.0087],\n",
      "        [ 0.0467,  0.0314,  0.0122,  ...,  0.1121, -0.0037, -0.0378],\n",
      "        [ 0.0168,  0.0329,  0.0260,  ...,  0.0444, -0.0241, -0.0854]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0324,  0.0135,  0.0274,  ...,  0.0340, -0.0074, -0.0291],\n",
      "        [-0.0206,  0.0254, -0.0225,  ...,  0.0447, -0.0007, -0.0346],\n",
      "        [-0.0427, -0.0404, -0.0221,  ..., -0.0251, -0.0258,  0.0217],\n",
      "        ...,\n",
      "        [-0.0250,  0.0262,  0.0429,  ...,  0.0117, -0.0038,  0.0150],\n",
      "        [ 0.0197, -0.0074, -0.0371,  ...,  0.0338,  0.0048,  0.0479],\n",
      "        [ 0.0478,  0.0451,  0.0244,  ...,  0.0485, -0.0260, -0.0261]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0476,  0.0332, -0.0327,  ..., -0.0419,  0.0448,  0.0337],\n",
      "        [ 0.0136, -0.0474,  0.0166,  ...,  0.0220,  0.0111,  0.0199],\n",
      "        [-0.0330,  0.0179, -0.0500,  ..., -0.0253, -0.0020,  0.0311],\n",
      "        ...,\n",
      "        [-0.0254,  0.0254,  0.0323,  ...,  0.0464, -0.0070, -0.0303],\n",
      "        [-0.0269,  0.0295, -0.0130,  ...,  0.0241,  0.0465, -0.0097],\n",
      "        [-0.0357,  0.0143,  0.0371,  ...,  0.0482, -0.0258, -0.0169]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0471, -0.0288,  0.0052,  ..., -0.0213, -0.0328,  0.0094],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0341, -0.0188, -0.0154,  ..., -0.0074, -0.0391,  0.0145],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0473,  0.0151, -0.0129,  ..., -0.0489, -0.0073,  0.0163],\n",
      "        [ 0.0021, -0.0118,  0.0252,  ...,  0.0120, -0.0103, -0.0133],\n",
      "        [ 0.0195, -0.0023,  0.0241,  ...,  0.0014, -0.0345,  0.0431],\n",
      "        ...,\n",
      "        [-0.0458, -0.0293,  0.0153,  ...,  0.0289, -0.0449, -0.0226],\n",
      "        [-0.0130, -0.0246,  0.0431,  ..., -0.0294, -0.0134,  0.0479],\n",
      "        [-0.0046,  0.0379, -0.0099,  ...,  0.0366,  0.0444,  0.0293]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0220,  0.0165,  0.0187,  ..., -0.0192, -0.0163,  0.0265],\n",
      "        [ 0.0284,  0.0161, -0.0129,  ...,  0.0051,  0.0420,  0.0023],\n",
      "        [-0.0145, -0.0137, -0.0440,  ...,  0.0378, -0.0179, -0.0285],\n",
      "        ...,\n",
      "        [-0.0470, -0.0468, -0.0306,  ..., -0.0365, -0.0454,  0.0446],\n",
      "        [-0.0407, -0.0354, -0.0253,  ..., -0.0373,  0.0195, -0.0327],\n",
      "        [-0.0177,  0.0038, -0.0295,  ..., -0.0368, -0.0399,  0.0287]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0204,  0.0459, -0.0036,  ...,  0.0303,  0.0029,  0.0341],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0228,  0.0430, -0.0171,  ...,  0.0188, -0.0443, -0.0079],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0424, -0.0162, -0.0360,  ...,  0.0293,  0.0348,  0.0171],\n",
      "        [-0.0077,  0.0112,  0.0236,  ...,  0.0125, -0.0338, -0.0288],\n",
      "        [ 0.0043,  0.0030, -0.0457,  ...,  0.0146, -0.0114, -0.0306],\n",
      "        ...,\n",
      "        [ 0.0095, -0.0301,  0.0193,  ..., -0.0338,  0.0027, -0.0165],\n",
      "        [ 0.0284,  0.0454,  0.0083,  ...,  0.0462,  0.0207, -0.0398],\n",
      "        [-0.0167, -0.0462, -0.0368,  ..., -0.0216, -0.0258,  0.0315]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0072, -0.0024,  0.0173,  ...,  0.0482,  0.0432, -0.0119],\n",
      "        [ 0.0490,  0.0362,  0.0185,  ..., -0.0397,  0.0394,  0.0459],\n",
      "        [ 0.0309,  0.0081, -0.0154,  ..., -0.0040, -0.0380,  0.0489],\n",
      "        ...,\n",
      "        [ 0.0390,  0.0123, -0.0113,  ..., -0.0382, -0.0266,  0.0331],\n",
      "        [ 0.0412,  0.0206, -0.0491,  ..., -0.0094, -0.0149,  0.0232],\n",
      "        [-0.0072,  0.0030,  0.0195,  ..., -0.0367, -0.0038,  0.0409]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0328, -0.0194, -0.0012,  ...,  0.0439,  0.0085,  0.0468],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0087, -0.0014,  0.0443,  ..., -0.0450, -0.0147, -0.0425],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0449,  0.0445,  0.0332,  ..., -0.0457,  0.0418, -0.0429],\n",
      "        [ 0.0265, -0.0199,  0.0361,  ..., -0.0354, -0.0118, -0.0210],\n",
      "        [ 0.0092,  0.0164,  0.0141,  ..., -0.0157,  0.0254, -0.0029],\n",
      "        ...,\n",
      "        [ 0.0279,  0.0386, -0.0257,  ..., -0.0148, -0.0120,  0.0405],\n",
      "        [-0.0064,  0.0039,  0.0460,  ..., -0.0277,  0.0283, -0.0360],\n",
      "        [-0.0352, -0.0411, -0.0416,  ..., -0.0099, -0.0123,  0.0499]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0004, -0.0452,  0.0247,  ...,  0.0338,  0.0092,  0.0024],\n",
      "        [-0.0073,  0.0341, -0.0168,  ...,  0.0040,  0.0356, -0.0427],\n",
      "        [-0.0418, -0.0081,  0.0114,  ..., -0.0141, -0.0052, -0.0336],\n",
      "        ...,\n",
      "        [-0.0454,  0.0056,  0.0110,  ..., -0.0149,  0.0149, -0.0222],\n",
      "        [-0.0268, -0.0236,  0.0193,  ...,  0.0383,  0.0323, -0.0178],\n",
      "        [-0.0210,  0.0153,  0.0104,  ..., -0.0412, -0.0033, -0.0466]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0270, -0.0186,  0.0111,  ...,  0.0231, -0.0459, -0.0398],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0296, -0.0066, -0.0148,  ..., -0.0383,  0.0263,  0.0024],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0084,  0.0254, -0.0276],\n",
      "         [-0.0118,  0.0225, -0.0107],\n",
      "         [ 0.0257, -0.0178,  0.0049],\n",
      "         ...,\n",
      "         [-0.0268, -0.0196,  0.0126],\n",
      "         [ 0.0244,  0.0270, -0.0122],\n",
      "         [ 0.0048,  0.0273,  0.0096]],\n",
      "\n",
      "        [[-0.0063,  0.0248,  0.0066],\n",
      "         [ 0.0241, -0.0088,  0.0277],\n",
      "         [-0.0017, -0.0228,  0.0154],\n",
      "         ...,\n",
      "         [-0.0017, -0.0231,  0.0111],\n",
      "         [ 0.0081,  0.0037, -0.0256],\n",
      "         [ 0.0097, -0.0244,  0.0273]],\n",
      "\n",
      "        [[-0.0143, -0.0130, -0.0162],\n",
      "         [ 0.0176, -0.0277,  0.0134],\n",
      "         [ 0.0168,  0.0284, -0.0031],\n",
      "         ...,\n",
      "         [-0.0280,  0.0174,  0.0010],\n",
      "         [ 0.0188,  0.0135, -0.0098],\n",
      "         [-0.0096,  0.0017, -0.0223]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0249,  0.0162, -0.0168],\n",
      "         [-0.0032,  0.0161, -0.0167],\n",
      "         [-0.0175, -0.0152,  0.0074],\n",
      "         ...,\n",
      "         [-0.0152, -0.0249, -0.0243],\n",
      "         [-0.0283, -0.0149, -0.0211],\n",
      "         [ 0.0106, -0.0061,  0.0145]],\n",
      "\n",
      "        [[ 0.0148,  0.0196,  0.0087],\n",
      "         [ 0.0267, -0.0267, -0.0146],\n",
      "         [-0.0093,  0.0048, -0.0171],\n",
      "         ...,\n",
      "         [ 0.0097,  0.0094,  0.0003],\n",
      "         [ 0.0121, -0.0154,  0.0061],\n",
      "         [ 0.0204, -0.0285, -0.0113]],\n",
      "\n",
      "        [[ 0.0216,  0.0159, -0.0003],\n",
      "         [ 0.0085,  0.0170, -0.0175],\n",
      "         [-0.0043, -0.0090,  0.0031],\n",
      "         ...,\n",
      "         [-0.0244,  0.0070, -0.0109],\n",
      "         [-0.0014, -0.0267,  0.0078],\n",
      "         [-0.0104,  0.0192,  0.0207]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-2.8701e-02,  2.0854e-02,  1.7488e-02, -8.9240e-03,  1.7614e-02,\n",
      "        -1.0060e-02, -2.5423e-02,  1.0273e-02, -4.8971e-03,  6.2351e-03,\n",
      "        -1.9150e-02,  3.7162e-03,  2.7349e-02, -2.2036e-02,  2.3959e-02,\n",
      "         2.2959e-02, -2.0618e-02, -1.1538e-02,  2.6221e-02,  2.1872e-02,\n",
      "         2.8484e-02, -7.1637e-03, -2.7564e-02,  8.9252e-03,  1.1288e-02,\n",
      "         1.0060e-02,  2.3790e-02,  1.9744e-02, -2.3120e-04,  2.4303e-02,\n",
      "         2.1663e-02, -1.6207e-02, -7.1187e-04,  1.2514e-02,  9.4778e-03,\n",
      "         7.5744e-04,  5.9996e-05, -1.2861e-02,  2.4280e-02, -9.1347e-03,\n",
      "        -2.2036e-02,  1.4293e-02, -1.9431e-02, -9.4710e-03,  1.0168e-02,\n",
      "        -1.3589e-02, -1.2859e-03,  8.6113e-03, -1.1245e-02, -1.8422e-02,\n",
      "         3.2316e-03, -7.7521e-03,  1.7325e-02, -2.4871e-02, -2.4137e-02,\n",
      "        -2.5463e-02,  2.7609e-02,  1.9552e-02,  2.0806e-02, -1.8693e-02,\n",
      "        -1.4734e-02,  1.1541e-02, -1.8165e-02,  1.2646e-02,  1.0172e-02,\n",
      "         1.3988e-02,  1.7635e-02, -3.0788e-03,  2.2082e-02,  1.4223e-02,\n",
      "        -2.4712e-02, -1.4190e-02,  2.4851e-02, -5.9966e-03,  1.1045e-02,\n",
      "         9.2607e-03, -8.8555e-03,  1.9162e-03, -1.0375e-02, -4.3519e-03,\n",
      "        -4.6732e-03,  2.8303e-02,  1.4122e-02, -1.2604e-02, -1.9390e-03,\n",
      "         2.2298e-02, -1.1504e-05,  2.7571e-02,  6.5418e-03,  2.7416e-02,\n",
      "        -2.8787e-02, -5.3485e-03, -9.2088e-03, -1.6715e-02, -1.1292e-02,\n",
      "        -1.8870e-02, -7.1565e-03,  1.1935e-02,  2.1966e-02,  6.2540e-03],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0138,  0.0129, -0.0192, -0.0158],\n",
      "         [-0.0048,  0.0141,  0.0078, -0.0078],\n",
      "         [ 0.0052,  0.0075,  0.0220, -0.0088],\n",
      "         ...,\n",
      "         [ 0.0182,  0.0090, -0.0210, -0.0054],\n",
      "         [-0.0017, -0.0074, -0.0147,  0.0227],\n",
      "         [ 0.0146,  0.0080, -0.0019,  0.0111]],\n",
      "\n",
      "        [[-0.0217,  0.0196, -0.0033, -0.0096],\n",
      "         [ 0.0123,  0.0195, -0.0224, -0.0140],\n",
      "         [-0.0181, -0.0209, -0.0148, -0.0090],\n",
      "         ...,\n",
      "         [ 0.0126, -0.0182, -0.0014, -0.0248],\n",
      "         [-0.0087, -0.0116,  0.0208, -0.0146],\n",
      "         [-0.0077, -0.0065, -0.0154,  0.0149]],\n",
      "\n",
      "        [[ 0.0121,  0.0066, -0.0088, -0.0066],\n",
      "         [-0.0064,  0.0002, -0.0151,  0.0073],\n",
      "         [-0.0024,  0.0083,  0.0129, -0.0161],\n",
      "         ...,\n",
      "         [-0.0174,  0.0150, -0.0005, -0.0065],\n",
      "         [ 0.0005,  0.0138, -0.0056, -0.0103],\n",
      "         [-0.0206, -0.0005,  0.0128, -0.0235]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0024, -0.0173, -0.0139,  0.0228],\n",
      "         [-0.0146,  0.0194,  0.0021, -0.0004],\n",
      "         [ 0.0191, -0.0139, -0.0121,  0.0049],\n",
      "         ...,\n",
      "         [-0.0136,  0.0103,  0.0110,  0.0185],\n",
      "         [ 0.0173,  0.0196, -0.0178,  0.0221],\n",
      "         [-0.0068, -0.0057, -0.0132, -0.0060]],\n",
      "\n",
      "        [[ 0.0250, -0.0095,  0.0067, -0.0026],\n",
      "         [ 0.0008, -0.0064, -0.0133, -0.0209],\n",
      "         [ 0.0018,  0.0111,  0.0128, -0.0228],\n",
      "         ...,\n",
      "         [ 0.0226, -0.0140,  0.0109,  0.0180],\n",
      "         [ 0.0010, -0.0087, -0.0168, -0.0172],\n",
      "         [-0.0129,  0.0064, -0.0030, -0.0242]],\n",
      "\n",
      "        [[ 0.0067, -0.0194,  0.0066, -0.0208],\n",
      "         [-0.0059, -0.0116,  0.0124,  0.0029],\n",
      "         [ 0.0136,  0.0168,  0.0064,  0.0116],\n",
      "         ...,\n",
      "         [ 0.0146,  0.0093,  0.0231, -0.0024],\n",
      "         [-0.0206,  0.0203, -0.0231, -0.0109],\n",
      "         [ 0.0174, -0.0048, -0.0004, -0.0098]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0002, -0.0055, -0.0080, -0.0151,  0.0061, -0.0116,  0.0075, -0.0057,\n",
      "        -0.0077, -0.0157,  0.0186,  0.0019,  0.0141, -0.0109,  0.0168, -0.0156,\n",
      "        -0.0130,  0.0162, -0.0198,  0.0067,  0.0105, -0.0047, -0.0205,  0.0228,\n",
      "         0.0148, -0.0003, -0.0161, -0.0126,  0.0247, -0.0027, -0.0204, -0.0076,\n",
      "        -0.0137,  0.0100,  0.0029,  0.0232,  0.0201,  0.0173, -0.0083,  0.0233,\n",
      "        -0.0218, -0.0121, -0.0059,  0.0035,  0.0229,  0.0106,  0.0240, -0.0097,\n",
      "         0.0037,  0.0104,  0.0214, -0.0205,  0.0039, -0.0217, -0.0107,  0.0153,\n",
      "         0.0107, -0.0200, -0.0238, -0.0144,  0.0077, -0.0101,  0.0023, -0.0123,\n",
      "         0.0083, -0.0211, -0.0006, -0.0121, -0.0022,  0.0150,  0.0087,  0.0017,\n",
      "         0.0226, -0.0176, -0.0096, -0.0022, -0.0244, -0.0161,  0.0185,  0.0114,\n",
      "         0.0081,  0.0047, -0.0223, -0.0222,  0.0034, -0.0047,  0.0127,  0.0187,\n",
      "         0.0212, -0.0168, -0.0219,  0.0011,  0.0017, -0.0142,  0.0072, -0.0097,\n",
      "        -0.0072, -0.0054, -0.0185, -0.0002], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 1.5507e-02, -2.0692e-02, -4.0995e-03,  1.2134e-02,  5.8359e-03],\n",
      "         [-1.7954e-02,  5.0226e-03, -1.7660e-02,  5.3859e-03, -1.8516e-02],\n",
      "         [ 1.1569e-02,  2.2280e-02,  8.9814e-03, -1.4025e-02,  1.9131e-02],\n",
      "         ...,\n",
      "         [-1.7414e-03,  1.7389e-02,  1.9778e-02, -2.9244e-03, -1.5698e-02],\n",
      "         [-5.7333e-03, -5.5816e-03,  1.3936e-02, -1.2879e-02,  1.7367e-02],\n",
      "         [-1.0624e-02,  1.8057e-03, -3.2357e-03, -1.1576e-02, -1.8627e-03]],\n",
      "\n",
      "        [[ 1.8682e-02, -1.0189e-02, -9.0951e-05,  1.4793e-02,  6.7114e-03],\n",
      "         [-1.2279e-03,  7.9918e-03,  2.1293e-02,  9.9717e-03, -1.3104e-02],\n",
      "         [-8.7058e-03, -8.8181e-03, -1.7539e-02,  1.1977e-02, -1.4428e-02],\n",
      "         ...,\n",
      "         [-5.2312e-03, -1.5164e-04, -2.9827e-03, -1.9856e-02,  1.8799e-02],\n",
      "         [-1.0638e-02, -8.8202e-03,  4.9550e-03,  2.0688e-02,  2.0701e-02],\n",
      "         [ 4.9040e-03,  1.3036e-02, -2.2449e-03,  7.0578e-03, -2.4701e-03]],\n",
      "\n",
      "        [[-1.8497e-03,  3.2946e-03, -9.7392e-04, -1.6749e-03, -2.0428e-02],\n",
      "         [-2.5739e-03,  1.1914e-02, -5.3940e-03, -1.5659e-04, -1.1877e-02],\n",
      "         [-6.0162e-03, -1.3989e-02,  1.1554e-02, -1.7096e-02,  1.6385e-02],\n",
      "         ...,\n",
      "         [-2.7888e-03, -1.7136e-02,  3.6246e-03, -8.3046e-03, -8.3991e-03],\n",
      "         [-1.4007e-02,  5.3499e-03,  1.8330e-02,  1.8713e-02, -4.1645e-03],\n",
      "         [-1.1092e-02,  2.0150e-03,  2.8256e-03,  1.5792e-02,  1.4827e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.8619e-03, -1.3551e-03,  2.0415e-02,  1.3452e-03, -1.4835e-02],\n",
      "         [ 1.3502e-02, -5.4324e-03, -1.1590e-02, -1.5016e-02, -1.5181e-02],\n",
      "         [-1.4669e-02, -1.1482e-02,  1.9334e-02,  5.3160e-06, -1.1865e-02],\n",
      "         ...,\n",
      "         [ 1.6690e-02, -2.9087e-03,  2.0144e-02,  7.5794e-04,  4.3880e-03],\n",
      "         [ 1.5548e-02, -1.6677e-02, -4.7139e-03, -2.8098e-03, -5.7009e-03],\n",
      "         [-4.3986e-04,  2.1008e-02, -1.0708e-02,  6.1094e-03, -2.1752e-02]],\n",
      "\n",
      "        [[ 1.0373e-02,  1.5775e-02,  9.1066e-03, -8.3352e-03, -1.5393e-02],\n",
      "         [ 1.0991e-02,  2.0261e-02,  1.0675e-02,  1.8357e-02,  1.5346e-02],\n",
      "         [ 2.1475e-02, -2.0971e-02,  1.6480e-03, -1.2205e-02, -6.9423e-03],\n",
      "         ...,\n",
      "         [ 2.0485e-02,  1.0149e-02, -1.4839e-02, -1.7478e-02,  1.5352e-02],\n",
      "         [-5.5050e-03, -1.4167e-02, -1.9384e-03, -3.7331e-03, -1.1592e-02],\n",
      "         [ 1.9243e-02, -3.6787e-03,  7.3726e-03,  1.3204e-02, -4.9322e-03]],\n",
      "\n",
      "        [[ 4.9347e-03, -1.2982e-02, -1.6860e-02,  9.2351e-03, -1.0435e-02],\n",
      "         [-1.0155e-02,  8.5820e-03, -2.1718e-02,  3.2324e-04, -7.0839e-04],\n",
      "         [ 2.2169e-02, -1.3562e-02, -4.2499e-04, -1.7499e-02, -3.4182e-03],\n",
      "         ...,\n",
      "         [-1.8466e-02, -7.9835e-04, -3.0234e-04, -1.6736e-02, -2.2157e-02],\n",
      "         [-1.2685e-02, -2.4084e-03, -5.9715e-03, -7.1321e-03,  7.1888e-03],\n",
      "         [ 1.8278e-02, -1.0918e-03,  5.8189e-03,  8.5840e-04,  7.0892e-03]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0214,  0.0143,  0.0001, -0.0016, -0.0120, -0.0056, -0.0218, -0.0118,\n",
      "        -0.0174, -0.0048, -0.0007, -0.0155,  0.0011, -0.0181,  0.0207,  0.0124,\n",
      "        -0.0165, -0.0037, -0.0076,  0.0222,  0.0168,  0.0003, -0.0131,  0.0119,\n",
      "         0.0165,  0.0058,  0.0007, -0.0054, -0.0094, -0.0040, -0.0193,  0.0012,\n",
      "        -0.0173,  0.0098,  0.0134, -0.0128, -0.0055, -0.0006,  0.0106,  0.0204,\n",
      "        -0.0168, -0.0008,  0.0025,  0.0217, -0.0117,  0.0117,  0.0177, -0.0022,\n",
      "        -0.0121, -0.0093, -0.0011,  0.0003,  0.0026, -0.0073, -0.0025, -0.0111,\n",
      "        -0.0183,  0.0208,  0.0005,  0.0107,  0.0064, -0.0115,  0.0043,  0.0146,\n",
      "        -0.0158,  0.0066,  0.0135, -0.0024, -0.0150, -0.0205,  0.0045,  0.0187,\n",
      "        -0.0092, -0.0190, -0.0058,  0.0200,  0.0200, -0.0187,  0.0036,  0.0203,\n",
      "         0.0197,  0.0151, -0.0141,  0.0157,  0.0017, -0.0110, -0.0156, -0.0167,\n",
      "        -0.0113, -0.0071,  0.0217, -0.0061,  0.0059,  0.0210, -0.0110,  0.0176,\n",
      "        -0.0136, -0.0218,  0.0084,  0.0141], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0121,  0.0021,  0.0191,  ..., -0.0109, -0.0102,  0.0007]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0202], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2248,  0.4496]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4749], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model_sentiment.parameters():\n",
    "    print (param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_classifier(\n",
       "  (dropout_enc): Dropout(p=0.2)\n",
       "  (encoder): Embedding(59972, 400, padding_idx=1)\n",
       "  (lstm): LSTM(400, 400, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout_op): Dropout(p=0.5)\n",
       "  (avg_pool1d): AdaptiveAvgPool1d(output_size=1)\n",
       "  (max_pool1d): AdaptiveMaxPool1d(output_size=1)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (conv_0): Conv1d(400, 100, kernel_size=(3,), stride=(1,))\n",
       "  (conv_1): Conv1d(400, 100, kernel_size=(4,), stride=(1,))\n",
       "  (conv_2): Conv1d(400, 100, kernel_size=(5,), stride=(1,))\n",
       "  (fc): Linear(in_features=1900, out_features=1, bias=True)\n",
       "  (logisticreg): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.3104,  0.7558,  0.2982,  0.4412,  0.5870,  0.4053,  0.0261,  0.3031,\n",
       "          0.2512,  0.3855,  0.1648,  0.3943,  0.3572,  0.2316,  0.2098,  0.2635,\n",
       "          0.3765,  0.2043,  0.2788,  0.2806,  0.0763, -0.0929,  0.5503,  0.1274,\n",
       "          0.1465,  0.2579,  0.4844,  0.2422,  0.5262, -0.0195,  0.3744,  0.2983,\n",
       "          0.3672,  0.0968,  0.3309,  0.4712,  0.2111,  0.4798,  0.2642,  0.5587,\n",
       "          0.4104,  0.1576,  0.2958,  0.2977,  0.4852,  0.2356,  0.2372,  0.0760,\n",
       "          0.5165,  0.4119,  0.4336,  0.3155], grad_fn=<ViewBackward>),\n",
       " tensor(0.7289, grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n",
       " tensor([ 0.3104,  0.7558,  0.2982,  0.4412,  0.5870,  0.4053,  0.0261,  0.3031,\n",
       "          0.2512,  0.3855,  0.1648,  0.3943,  0.3572,  0.2316,  0.2098,  0.2635,\n",
       "          0.3765,  0.2043,  0.2788,  0.2806,  0.0763, -0.0929,  0.5503,  0.1274,\n",
       "          0.1465,  0.2579,  0.4844,  0.2422,  0.5262, -0.0195,  0.3744,  0.2983,\n",
       "          0.3672,  0.0968,  0.3309,  0.4712,  0.2111,  0.4798,  0.2642,  0.5587,\n",
       "          0.4104,  0.1576,  0.2958,  0.2977,  0.4852,  0.2356,  0.2372,  0.0760,\n",
       "          0.5165,  0.4119,  0.4336,  0.3155], grad_fn=<ViewBackward>),\n",
       " tensor(0.7289, grad_fn=<BinaryCrossEntropyWithLogitsBackward>))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,loss,preds_full,loss_master=model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0236, 0.3689, 0.3374, 0.5285, 0.5353, 0.5091, 0.1900, 0.3273, 0.2356,\n",
       "         0.1013, 0.0176, 0.4405, 0.3198, 0.5186, 0.5533, 0.1796, 0.0354, 0.2479,\n",
       "         0.2350, 0.3913, 0.4415, 0.3453, 0.2577, 0.2602, 0.1268, 0.1137, 0.4254,\n",
       "         0.3119, 0.4812, 0.2968, 0.4053, 0.1495, 0.2702, 0.2912, 0.2293, 0.2199,\n",
       "         0.1506, 0.2625, 0.3906, 0.3142, 0.1359, 0.2050, 0.2847, 0.5240, 0.6288,\n",
       "         0.3845, 0.1044, 0.2447, 0.2322, 0.2454, 0.2657, 0.3788],\n",
       "        grad_fn=<ViewBackward>),\n",
       " tensor([0.0236, 0.3689, 0.3374, 0.5285, 0.5353, 0.5091, 0.1900, 0.3273, 0.2356,\n",
       "         0.1013, 0.0176, 0.4405, 0.3198, 0.5186, 0.5533, 0.1796, 0.0354, 0.2479,\n",
       "         0.2350, 0.3913, 0.4415, 0.3453, 0.2577, 0.2602, 0.1268, 0.1137, 0.4254,\n",
       "         0.3119, 0.4812, 0.2968, 0.4053, 0.1495, 0.2702, 0.2912, 0.2293, 0.2199,\n",
       "         0.1506, 0.2625, 0.3906, 0.3142, 0.1359, 0.2050, 0.2847, 0.5240, 0.6288,\n",
       "         0.3845, 0.1044, 0.2447, 0.2322, 0.2454, 0.2657, 0.3788],\n",
       "        grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.view(-1),preds_full.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4231)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_binomial(preds.to(device),yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6196969696969697"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yb,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.038397e-02, -1.795423e-02, -3.457930e-02,  8.671192e-02, ..., -3.003510e-02, -1.899482e-02,  1.426260e-02,\n",
       "        -4.948893e-02],\n",
       "       [-2.453323e-02, -3.018817e-02,  6.663179e-02, -5.793565e-02, ...,  1.840935e-02,  6.371137e-02,  9.835491e-03,\n",
       "        -2.131385e-03],\n",
       "       [ 7.696263e-03, -4.266643e-02, -1.533517e-01,  2.239776e-01, ...,  9.869517e-02,  3.041433e-02,  1.824751e-01,\n",
       "         1.134978e-01],\n",
       "       [ 3.305928e-02,  2.266591e-01, -4.264669e-02,  1.490862e-01, ...,  3.407921e-02, -6.422209e-03,  3.180612e-01,\n",
       "         9.373549e-02],\n",
       "       ...,\n",
       "       [ 6.027538e-02, -5.980809e-02,  1.861691e-01, -3.105092e-02, ..., -2.764457e-02,  1.962678e-02, -2.172215e-03,\n",
       "         6.297247e-02],\n",
       "       [-1.592789e-02, -2.781571e-04,  1.301994e-01,  2.851282e-02, ...,  5.064877e-02,  1.670864e-01,  2.283701e-02,\n",
       "        -8.746398e-03],\n",
       "       [ 4.669700e-02,  3.138980e-02,  1.221957e-02, -3.927753e-02, ..., -1.281436e-01,  1.121320e-01, -3.726090e-03,\n",
       "        -3.777364e-02],\n",
       "       [ 1.677964e-02,  3.287802e-02,  2.598143e-02, -1.484041e-02, ..., -2.587889e-02,  4.438318e-02, -2.407267e-02,\n",
       "        -8.544586e-02]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_lm_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "  \n",
    "        \n",
    "    \n",
    "    def fit (self,Xb,Yb,Xlen,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds,loss,preds_master,loss_master=self.model(Xb,Yb,Xlen)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "            acc=acc.item()\n",
    "            del preds\n",
    "            \n",
    "            acc_master=self.metric_fn(preds_master,Yb.view(-1),self.device)\n",
    "            acc_master=acc_master.item()\n",
    "            del preds_master\n",
    "            \n",
    "        if mode_train:\n",
    "            self.optimizer.zero_grad()\n",
    "            #loss.backward()\n",
    "            loss_master.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "        myloss_master=loss_master.item()\n",
    "        del loss\n",
    "        del loss_master\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc, myloss_master, acc_master\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        epoch_loss_master,epoch_acc_master=0,0\n",
    "        self.model.init_hidden()\n",
    "        for Xb,Yb,Xlen in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            Xlen=Xlen.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc,loss_master,acc_master=self.fit(Xb,Yb,Xlen,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            epoch_loss_master+=loss_master\n",
    "            epoch_acc_master+=acc_master\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  {epoch_acc/(k)} {epoch_loss_master/k} {epoch_acc_master/k}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "        epoch_loss_master=epoch_loss_master/len(iterator)\n",
    "        epoch_acc_master=epoch_loss_master/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc,epoch_loss_master,epoch_acc_master\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "    \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            loss,acc,loss_master,acc_master=self.run_epoch(dltrain,True)\n",
    "            lossv,accv,lossv_master,accv_master=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Loss:{loss} Accuracy:{acc} Loss Master:{loss_master} Acc Master: {acc_master}')\n",
    "           \n",
    "            print (f'Epoch:{epoch} Loss:{lossv} Accuracy:{accv} Loss Master:{lossv_master} Accuracy:{accv_master}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (59972, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout,\\\n",
    "                 dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n",
    "model_sentiment=model_sentiment.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model_sentiment.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "metric_fn=accuracy_binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 481)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain),len(dlvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model_sentiment,optimizer,accuracy_binomial,device,bptt,50,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5, 0.5, 0.2, 0.5, 0.5)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.dropout_e,model_sentiment.dropout,model_sentiment.dropout_o, learner.model.dropout_e,learner.model.dropout,learner.model.dropout_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.7142228960990906  0.5776923310756683 0.7142228960990906 0.5776923310756683\n",
      "Batch:100 0.6197613894939422  0.6555769485235214 0.6197613894939422 0.6555769485235214\n",
      "Batch:150 0.5450906540950139  0.7112820788224539 0.5450906540950139 0.7112820788224539\n",
      "Batch:200 0.49452481634914874  0.7475000298023224 0.49452481634914874 0.7475000298023224\n",
      "Batch:250 0.46972642016410826  0.7658461847305298 0.46972642016410826 0.7658461847305298\n",
      "Batch:300 0.44119206614792345  0.7842308006683986 0.44119206614792345 0.7842308006683986\n",
      "Batch:350 0.4230891307549817  0.7965934388978141 0.4230891307549817 0.7965934388978141\n",
      "Batch:400 0.40258065082132816  0.8097115713357925 0.40258065082132816 0.8097115713357925\n",
      "Batch:450 0.3868794124159548  0.8182478965653314 0.3868794124159548 0.8182478965653314\n",
      "Batch:50 0.2429726642370224  0.9011538887023925 0.2429726642370224 0.9011538887023925\n",
      "Batch:100 0.24101626485586167  0.9015385007858276 0.24101626485586167 0.9015385007858276\n",
      "Batch:150 0.2358936957269907  0.9052564497788748 0.2358936957269907 0.9052564497788748\n",
      "Batch:200 0.23954209031537174  0.9049038857221603 0.23954209031537174 0.9049038857221603\n",
      "Batch:250 0.24332497642934323  0.9017692701816559 0.24332497642934323 0.9017692701816559\n",
      "Batch:300 0.2462371599798401  0.9005769622325898 0.2462371599798401 0.9005769622325898\n",
      "Batch:350 0.24831866665610244  0.8996703684329986 0.24831866665610244 0.8996703684329986\n",
      "Batch:400 0.24840298174880446  0.8992788852751255 0.24840298174880446 0.8992788852751255\n",
      "Batch:450 0.25180247383813065  0.8976923460430569 0.25180247383813065 0.8976923460430569\n",
      "Epoch:0 Loss:0.3793112579384613 Accuracy:0.8236486818835046 Loss Master:0.3793112579384613 Acc Master: 0.000788588893842955\n",
      "Epoch:0 Loss:0.2519324355354056 Accuracy:0.8971653989595584 Loss Master:0.2519324355354056 Accuracy:0.0005237680572461656\n",
      "Batch:50 0.2579366137087345  0.8950000393390656 0.2579366137087345 0.8950000393390656\n",
      "Batch:100 0.2638634687662125  0.8932692700624466 0.2638634687662125 0.8932692700624466\n",
      "Batch:150 0.25086000536878905  0.8993590132395426 0.25086000536878905 0.8993590132395426\n",
      "Batch:200 0.2458872228115797  0.9005769610404968 0.2458872228115797 0.9005769610404968\n",
      "Batch:250 0.24373284223675729  0.9018461923599244 0.24373284223675729 0.9018461923599244\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-2ac86570032a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-7eb230df3d19>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(self, dltrain, dlvalid, n_epochs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_master\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_master\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mlossv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlossv_master\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccv_master\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch:{epoch} Loss:{loss} Accuracy:{acc} Loss Master:{loss_master} Acc Master: {acc_master}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-7eb230df3d19>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, iterator, mode_train, lrs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_master\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_master\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-7eb230df3d19>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Xb, Yb, Xlen, mode_train)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mloss_master\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmyloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.2602949035167694  0.9246154272556305\n",
      "Batch:100 0.26078327000141144  0.9253846567869186\n",
      "Batch:150 0.26985132664442063  0.9215385015805563\n",
      "Batch:200 0.2697112593054771  0.9200000390410423\n",
      "Batch:250 0.2718077033162117  0.9196923470497131\n",
      "Batch:300 0.27274388055006665  0.919615423878034\n",
      "Batch:350 0.27353397182055883  0.9201099286760602\n",
      "Batch:400 0.27226867550984024  0.9200481155514717\n",
      "Batch:450 0.27181959892312685  0.9212393550078074\n",
      "Epoch:0 Loss:0.2721488145402712\n",
      "Batch:50 0.23855660259723663  0.9215384984016418\n",
      "Batch:100 0.23052386477589606  0.9250000357627869\n",
      "Batch:150 0.22719828700025876  0.927564138174057\n",
      "Batch:200 0.22540926929563285  0.9287500357627869\n",
      "Batch:250 0.22739271780848502  0.9279231135845184\n",
      "Batch:300 0.22894382283091544  0.9265384991963704\n",
      "Batch:350 0.23035185047558376  0.9248901471069881\n",
      "Batch:400 0.23013888780027628  0.925000037252903\n",
      "Batch:450 0.23098011559910245  0.9244444823265076\n",
      "Epoch:0 Loss:0.2721488145402712 Accuracy:0.9211778733685706 Loss:0.23033504215942352 Accuracy:0.9247241705470174\n",
      "Batch:50 0.24890062898397447  0.9253846538066864\n",
      "Batch:100 0.25160896964371204  0.9255769610404968\n",
      "Batch:150 0.2485675858457883  0.9279487574100495\n",
      "Batch:200 0.2511365815624595  0.9288461926579475\n",
      "Batch:250 0.25154359272122384  0.9289231159687042\n",
      "Batch:300 0.2560955049842596  0.9269872184594472\n",
      "Batch:350 0.257317021297557  0.9266483902931213\n",
      "Batch:400 0.25657936403527853  0.9273558075726033\n",
      "Batch:450 0.25737373833854993  0.926752175225152\n",
      "Epoch:1 Loss:0.25764048413960206\n",
      "Batch:50 0.2370019108057022  0.9123077321052552\n",
      "Batch:100 0.22941797129809857  0.9182692712545395\n",
      "Batch:150 0.22574186275402705  0.9187179871400197\n",
      "Batch:200 0.22660034164786338  0.9192308083176612\n",
      "Batch:250 0.23030470821261406  0.9165384998321533\n",
      "Batch:300 0.23274115530153117  0.915769269267718\n",
      "Batch:350 0.23298029820833888  0.9157692692961011\n",
      "Batch:400 0.23407072311267257  0.9155288851261139\n",
      "Batch:450 0.23716040967239274  0.9147863641050127\n",
      "Epoch:1 Loss:0.25764048413960206 Accuracy:0.9271470077816018 Loss:0.2360053474931608 Accuracy:0.9154726125594236\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['lr']=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.21061992287635803  0.9423077285289765\n",
      "Batch:100 0.21618611991405487  0.9403846502304077\n",
      "Batch:150 0.21317385693391164  0.9421795201301575\n",
      "Batch:200 0.2095358297601342  0.9436538797616959\n",
      "Batch:250 0.21004493841528893  0.9423846492767334\n",
      "Batch:300 0.20874958125253518  0.9437820851802826\n",
      "Batch:350 0.2082487084184374  0.9439560789721353\n",
      "Batch:400 0.20598521264269948  0.945048111975193\n",
      "Batch:450 0.20462557028565143  0.9453846507602268\n",
      "Epoch:0 Loss:0.20349373961963427\n",
      "Batch:50 0.2257000485062599  0.9257692682743073\n",
      "Batch:100 0.21463873624801635  0.9275000381469727\n",
      "Batch:150 0.20880756457646688  0.9305128578344981\n",
      "Batch:200 0.2073708800598979  0.9311538836359978\n",
      "Batch:250 0.2092157429754734  0.929769268989563\n",
      "Batch:300 0.21088908096154532  0.9280128586292267\n",
      "Batch:350 0.21207390189170838  0.9271978402137756\n",
      "Batch:400 0.21261372368782758  0.9275481149554252\n",
      "Batch:450 0.21493610123793283  0.9268803803126017\n",
      "Epoch:0 Loss:0.20349373961963427 Accuracy:0.9456821079065795 Loss:0.21543617876490537 Accuracy:0.9269670945690972\n",
      "Batch:50 0.18994002014398575  0.9484615731239319\n",
      "Batch:100 0.19255741715431213  0.9459615743160248\n",
      "Batch:150 0.19029907112320263  0.9479487526416779\n",
      "Batch:200 0.1930109491571784  0.948173111975193\n",
      "Batch:250 0.19080265042185784  0.9491538815498352\n",
      "Batch:300 0.18984659726421038  0.9494231128692627\n",
      "Batch:350 0.18922311565705707  0.9498352006503514\n",
      "Batch:400 0.18882198870182038  0.9500000363588333\n",
      "Batch:450 0.191411790665653  0.9492735404438443\n",
      "Epoch:1 Loss:0.1900569688056338\n",
      "Batch:50 0.22341101691126825  0.9257692635059357\n",
      "Batch:100 0.21099434331059455  0.9280769574642181\n",
      "Batch:150 0.20544674555460612  0.9302564454078674\n",
      "Batch:200 0.20510664038360119  0.9300000351667405\n",
      "Batch:250 0.20722843995690346  0.9295384974479676\n",
      "Batch:300 0.20869691987832387  0.9287179851531983\n",
      "Batch:350 0.2093819136917591  0.9282417942796435\n",
      "Batch:400 0.20942980870604516  0.9285577289760113\n",
      "Batch:450 0.21126348396142325  0.9281196947892507\n",
      "Epoch:1 Loss:0.1900569688056338 Accuracy:0.9498001320942028 Loss:0.21084784133177786 Accuracy:0.9285623265155388\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['lr']=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.18099605277180672  0.9553846514225006\n",
      "Batch:100 0.17272445492446423  0.9578846514225006\n",
      "Batch:150 0.17237537413835524  0.9570513180891673\n",
      "Batch:200 0.17455839972943069  0.9554808053374291\n",
      "Batch:250 0.1772473058998585  0.9539231126308441\n",
      "Batch:300 0.1783899956693252  0.9541667022307714\n",
      "Batch:350 0.17966196766921452  0.953736299276352\n",
      "Batch:400 0.17963904932141303  0.9535577276349068\n",
      "Batch:450 0.17836755072077115  0.9536752484904395\n",
      "Epoch:0 Loss:0.1775560694090294\n",
      "Batch:50 0.22347456246614456  0.9242308032512665\n",
      "Batch:100 0.21099014237523078  0.9273077285289765\n",
      "Batch:150 0.20516699055830637  0.930897472302119\n",
      "Batch:200 0.2047584541887045  0.930480805337429\n",
      "Batch:250 0.20696539029479027  0.9300000369548798\n",
      "Batch:300 0.2084414041787386  0.9294231142600378\n",
      "Batch:350 0.2091118818947247  0.9287363009793418\n",
      "Batch:400 0.20920589435845613  0.9291827297210693\n",
      "Batch:450 0.21117532258232435  0.9285897809929318\n",
      "Epoch:0 Loss:0.1775560694090294 Accuracy:0.9541980194202827 Loss:0.21064545959234238 Accuracy:0.9288301988351866\n",
      "Batch:50 0.16405624262988566  0.9588461875915527\n",
      "Batch:100 0.173634426407516  0.9561538797616959\n",
      "Batch:150 0.17700044689079125  0.9555128542582194\n",
      "Batch:200 0.17730488220229745  0.9552884954214096\n",
      "Batch:250 0.17725023637712  0.9554615728855133\n",
      "Batch:300 0.17876277855286996  0.9547436249256134\n",
      "Batch:350 0.17629661710134575  0.9557692650386266\n",
      "Batch:400 0.17553321541287004  0.9563461874425411\n",
      "Batch:450 0.17685074176225396  0.9564530256059435\n",
      "Epoch:1 Loss:0.1757232042072097\n",
      "Batch:50 0.22327799633145332  0.9242308020591736\n",
      "Batch:100 0.2107046277076006  0.9271154206991196\n",
      "Batch:150 0.20474458237489065  0.9302564465999603\n",
      "Batch:200 0.20439835339784623  0.9300000357627869\n",
      "Batch:250 0.20669518288969993  0.9293077282905579\n",
      "Batch:300 0.20815419254203638  0.9287179853518804\n",
      "Batch:350 0.20885408324854715  0.928076959337507\n",
      "Batch:400 0.20902772672474385  0.9285577289760113\n",
      "Batch:450 0.21102451754940882  0.9281624297300974\n",
      "Epoch:1 Loss:0.1757232042072097 Accuracy:0.9564529364916986 Loss:0.21044761502414383 Accuracy:0.9284823650877589\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['weight_decay']=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type sentiment_classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{PATH}/inter/sentiment_combmodel_nounfreeze_state_dict_0.928')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/sentiment_comblearner_nounfreeze_state_dict_0.928')\n",
    "torch.save (model_sentiment,f'{PATH}/inter/sentiment_combmodel_nounfreeze_0.928')\n",
    "torch.save (optimizer,f'{PATH}/inter/sentiment_comboptimizer_nounfreeze_0.928')\n",
    "torch.save (learner,f'{PATH}/inter/sentiment_comblearner_nounfreeze_0.928')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.17493538081645965  0.9561538791656494\n",
      "Batch:100 0.17721302550286055  0.9548077237606049\n",
      "Batch:150 0.17729540345569453  0.9569231100877126\n",
      "Batch:200 0.18007498333230615  0.9548077258467674\n",
      "Batch:250 0.17792524062097073  0.95584618806839\n",
      "Batch:300 0.17829006606092054  0.9555128544569016\n",
      "Batch:350 0.17789884659860816  0.9559890450750078\n",
      "Batch:400 0.17710435344837605  0.9557211877405644\n",
      "Batch:450 0.17813795316550468  0.9558547343148126\n",
      "Epoch:0 Loss:0.178482661670434\n",
      "Batch:50 0.2226167418062687  0.9253846490383149\n",
      "Batch:100 0.21022986188530923  0.9280769598484039\n",
      "Batch:150 0.20406683415174484  0.9311538835366567\n",
      "Batch:200 0.20320395998656748  0.930865421295166\n",
      "Batch:250 0.20514419555664062  0.9298461916446685\n",
      "Batch:300 0.20654248200356962  0.9291026020050048\n",
      "Batch:350 0.20751422758613314  0.9284615761893136\n",
      "Batch:400 0.20778242031112312  0.9289904221892357\n",
      "Batch:450 0.20982487615611817  0.9285043115086026\n",
      "Epoch:0 Loss:0.178482661670434 Accuracy:0.9559691684657472 Loss:0.20982318002877762 Accuracy:0.9285783202633293\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.1796993599832058  0.9576923358440399\n",
      "Batch:100 0.17213856488466261  0.9584615689516067\n",
      "Batch:150 0.16667891293764114  0.9589743900299073\n",
      "Batch:200 0.16918746769428253  0.9588461855053901\n",
      "Batch:250 0.1691615637242794  0.9592308008670807\n",
      "Batch:300 0.169596492399772  0.9590384934345881\n",
      "Batch:350 0.16886687725782396  0.9589560759067536\n",
      "Batch:400 0.17080709227360785  0.9581250323355198\n",
      "Batch:450 0.16847730916407372  0.9587607159879472\n",
      "Epoch:0 Loss:0.16862219942272824\n",
      "Batch:50 0.22200749382376672  0.9234615743160248\n",
      "Batch:100 0.2091979483515024  0.9265385007858277\n",
      "Batch:150 0.20304773584008218  0.9300000381469726\n",
      "Batch:200 0.20253973938524722  0.9300961908698082\n",
      "Batch:250 0.2047864469587803  0.9294615759849548\n",
      "Batch:300 0.20614869686464468  0.9289743967851003\n",
      "Batch:350 0.2068827559053898  0.9282967409065791\n",
      "Batch:400 0.20708336601033805  0.9288461914658547\n",
      "Batch:450 0.20918306630518702  0.9283761061562432\n",
      "Epoch:0 Loss:0.16862219942272824 Accuracy:0.9590476893833422 Loss:0.2087184589147072 Accuracy:0.9286702757317906\n",
      "Batch:50 0.16099832475185394  0.9661538743972778\n",
      "Batch:100 0.16142963767051696  0.9625000298023224\n",
      "Batch:150 0.1619515971839428  0.9614102880160014\n",
      "Batch:200 0.16426740754395724  0.9599038797616959\n",
      "Batch:250 0.16431408062577246  0.9598461875915527\n",
      "Batch:300 0.1631758673240741  0.9606410590807597\n",
      "Batch:350 0.162586919346026  0.9602747586795262\n",
      "Batch:400 0.16229679444804787  0.9605288796126843\n",
      "Batch:450 0.16280101002918348  0.9604701194498274\n",
      "Epoch:1 Loss:0.16311668217368036\n",
      "Batch:50 0.22146387040615081  0.9246154201030731\n",
      "Batch:100 0.20863340713083744  0.9269231158494949\n",
      "Batch:150 0.2024068482220173  0.9302564481894176\n",
      "Batch:200 0.20174461767077445  0.9305769601464271\n",
      "Batch:250 0.20387699982523919  0.9300769608020782\n",
      "Batch:300 0.20519040572146574  0.9296154224872589\n",
      "Batch:350 0.20607244702322142  0.9291209166390555\n",
      "Batch:400 0.20633444894105196  0.9296154220402241\n",
      "Batch:450 0.20845994838409954  0.9289743967851003\n",
      "Epoch:1 Loss:0.16311668217368036 Accuracy:0.9602870963467381 Loss:0.20828534439670818 Accuracy:0.9289261531433296\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.14831322476267814  0.9669231069087982\n",
      "Batch:100 0.15890183448791503  0.9651923382282257\n",
      "Batch:150 0.15571161108712356  0.966153877178828\n",
      "Batch:200 0.15806500744074584  0.9662500303983689\n",
      "Batch:250 0.1604635378420353  0.9652307999134063\n",
      "Batch:300 0.16394074910630782  0.9637820820013682\n",
      "Batch:350 0.16396197034844331  0.9634615690367563\n",
      "Batch:400 0.16163033758290113  0.9640384916961193\n",
      "Batch:450 0.16222475753062301  0.9635043039586809\n",
      "Epoch:0 Loss:0.16214304859604756\n",
      "Batch:50 0.22104861378669738  0.923076958656311\n",
      "Batch:100 0.20808142654597758  0.9263461923599243\n",
      "Batch:150 0.20183727160096168  0.9297436273097992\n",
      "Batch:200 0.20117236562073232  0.9301923441886902\n",
      "Batch:250 0.20324968230724336  0.9299231135845184\n",
      "Batch:300 0.20449111166099707  0.9294872166713078\n",
      "Batch:350 0.2054740560054779  0.9289011357511793\n",
      "Batch:400 0.2057606272958219  0.929423113912344\n",
      "Batch:450 0.2078460860417949  0.9288034560945299\n",
      "Epoch:0 Loss:0.16214304859604756 Accuracy:0.963365615033806 Loss:0.207645952809997 Accuracy:0.9288701794251583\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.16885913476347925  0.9615384936332703\n",
      "Batch:100 0.15936354756355287  0.9651923406124115\n",
      "Batch:150 0.1592694428563118  0.9644872109095256\n",
      "Batch:200 0.15632881922647357  0.9650000315904618\n",
      "Batch:250 0.155020054936409  0.9660000314712525\n",
      "Batch:300 0.1532587735603253  0.9660897747675578\n",
      "Batch:350 0.15422616588217872  0.9660989323684147\n",
      "Batch:400 0.15426115840673446  0.9659615701436997\n",
      "Batch:450 0.1547477538469765  0.9656410574913025\n",
      "Epoch:0 Loss:0.15475054663797674\n",
      "Batch:50 0.22095745116472243  0.9238461887836457\n",
      "Batch:100 0.20784359097480773  0.9267308074235916\n",
      "Batch:150 0.20166147058208783  0.9303846526145935\n",
      "Batch:200 0.201059164442122  0.9307692670822143\n",
      "Batch:250 0.20317641404271125  0.9301538825035095\n",
      "Batch:300 0.20448637386163077  0.9293590112527211\n",
      "Batch:350 0.205431331630264  0.9285714653560093\n",
      "Batch:400 0.20577694775536656  0.9293269602954388\n",
      "Batch:450 0.2079033212032583  0.9288034560945299\n",
      "Epoch:0 Loss:0.15475054663797674 Accuracy:0.9655805533740228 Loss:0.2076465636801571 Accuracy:0.9288581851366404\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
