{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os \n",
    "import fastai\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "PATH=\"/home/kirana/Documents/phd/final\"\n",
    "DATAPATH=\"/home/kirana/Documents/phd/data/aclImdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_train,df_valid,df_test,itos, train_tokens, valid_tokens, test_tokens, trn_lm, val_lm, test_lm]=pickle.load(open(f'{PATH}/inter/dfs_tokens_fastai.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=52 # 52 - Jeremey, 20 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt= 70 #70 - Jeremey, 35 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_lm(tokens,bs):\n",
    "    import itertools\n",
    "    # Collapse into a single large array\n",
    "    tokens=np.asarray(list (itertools.chain(*tokens)))\n",
    "    # How many batches\n",
    "    n_batch=len(tokens)//bs\n",
    "    # Truncate to exclude the ones at the end\n",
    "    tokens=tokens[:bs*n_batch]\n",
    "    # Reshape\n",
    "    tokens=tokens.reshape(bs,-1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52, 396650), (52, 43895), (52, 143259))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens=create_data_lm(df_train['tokens'],bs)\n",
    "valid_tokens=create_data_lm(df_valid['tokens'],bs)\n",
    "test_tokens=create_data_lm(df_test['tokens'],bs)\n",
    "train_tokens.shape, valid_tokens.shape, test_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i):\n",
    "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 70) (52, 70)\n"
     ]
    }
   ],
   "source": [
    "n_batch=train_tokens.shape[1]\n",
    "for i in range(0,n_batch,bptt):\n",
    "    seq_len=min(bptt,n_batch-1-i)\n",
    "    x=train_tokens[:,i:i+seq_len]\n",
    "    y=train_tokens[:,i+1:i+1+seq_len]\n",
    "    print (x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52, 70), (52, 70))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   41,    42,    43,    40, ...,     2,  1896,   463,     4],\n",
       "        [ 1071,    23,    67,    39, ...,     2,    98,    11,    63],\n",
       "        [   54,    34,     7,   190, ...,     2,    87,    34,  5998],\n",
       "        [    7,  1213,     8,   453, ...,   406,     4,     2,    46],\n",
       "        ...,\n",
       "        [   60,   126,   931,     6, ...,   114,    39,   599,    63],\n",
       "        [    2, 15094,   132,    65, ...,    56,  1350,   209,   281],\n",
       "        [11783,   658,   318,     3, ...,     6,    64,    79,  1268],\n",
       "        [   42,    43,    40,     2, ...,   708,   111,     4,     2]]),\n",
       " array([[   42,    43,    40,    13, ...,  1896,   463,     4,     2],\n",
       "        [   23,    67,    39,    18, ...,    98,    11,    63,    28],\n",
       "        [   34,     7,   190,  1732, ...,    87,    34,  5998,    47],\n",
       "        [ 1213,     8,   453,    21, ...,     4,     2,    46,     7],\n",
       "        ...,\n",
       "        [  126,   931,     6,   126, ...,    39,   599,    63,   314],\n",
       "        [15094,   132,    65,   411, ...,  1350,   209,   281,     9],\n",
       "        [  658,   318,     3,    25, ...,    64,    79,  1268,    85],\n",
       "        [   43,    40,     2,    14, ...,   111,     4,     2, 13447]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52, 70), (52, 70))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 396650)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-trained GLOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_GLOVE='/home/kirana/Documents/phd/data/pre-trained/glove/glove.6B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mglove_50_glove_100.tgz\u001b[0m  glove.6B.300d.txt  wordvectors_glove50\r\n",
      "glove.6B.100d.txt       glove.6B.50d.txt\r\n",
      "glove.6B.200d.txt       word2idx_glove50\r\n"
     ]
    }
   ],
   "source": [
    "ls {PATH_GLOVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_vectors(path=f'{PATH_GLOVE}/glove.6B.50d.txt'):\n",
    "    f=open(f'{path}','r')\n",
    "    glovelines=f.readlines()\n",
    "    word2idx={}\n",
    "    idx=0\n",
    "    wordvectors={}\n",
    "    for line in glovelines:\n",
    "        line=line.split(' ')\n",
    "        vector=np.asarray(line[1:]).astype(np.float32)\n",
    "        word2idx[line[0]]=idx\n",
    "        idx=idx+1\n",
    "        wordvectors[line[0]]=vector\n",
    "    return word2idx,wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_glove,wordvectors_glove=load_glove_vectors()\n",
    "import pickle\n",
    "pickle.dump(word2idx_glove,open(f'{PATH_GLOVE}/word2idx_glove50','wb'))\n",
    "pickle.dump(wordvectors_glove,open(f'{PATH_GLOVE}/wordvectors_glove50','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_glove=pickle.load(open(f'{PATH_GLOVE}/word2idx_glove50','rb'))\n",
    "wordvectors_glove=pickle.load(open(f'{PATH_GLOVE}/wordvectors_glove50','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'of', 'to']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*word2idx_glove.keys()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvectors_glove['the'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_mtx=np.array([wordvectors_glove[key] for key in [*word2idx_glove.keys()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5072"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In our list but not in Glove\n",
    "len(set(itos).difference(set([*word2idx_glove.keys()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0845728006402988"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(itos).difference(set([*word2idx_glove.keys()])))/len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_mtx=np.zeros((len(itos),glove_mtx.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01, -4.4457e-02, -4.9688e-01, -1.7862e-01,\n",
       "       -6.6023e-04, -6.5660e-01,  2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,  1.1658e-02,\n",
       "        1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01, -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01,\n",
       "       -1.9181e-01, -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,  4.0071e+00, -1.8594e-01,\n",
       "       -5.2287e-01, -3.1681e-01,  5.9213e-04,  7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,  1.8785e-01,  2.7849e-03, -1.8411e-01,\n",
       "       -1.1514e-01, -7.8581e-01], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvectors_glove['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wgts = glove_mtx # converts np.ndarray from torch.FloatTensor.output shape: (238462, 400)\n",
    "row_m = enc_wgts.mean(0) # returns the average of the array elements along axis 0. output shape: (400,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,word in enumerate(itos):\n",
    "    try:\n",
    "        glove_mtx[i]=wordvectors_glove[word]\n",
    "    except:\n",
    "        glove_mtx[i]=row_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01, -4.4457e-02, -4.9688e-01, -1.7862e-01,\n",
       "       -6.6023e-04, -6.5660e-01,  2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,  1.1658e-02,\n",
       "        1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01, -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01,\n",
       "       -1.9181e-01, -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,  4.0071e+00, -1.8594e-01,\n",
       "       -5.2287e-01, -3.1681e-01,  5.9213e-04,  7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,  1.8785e-01,  2.7849e-03, -1.8411e-01,\n",
       "       -1.1514e-01, -7.8581e-01])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_mtx[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59972, 50), 59972)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_wgts.shape, len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_emb=enc_wgts.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_w=enc_wgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59972, 50)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from adaptive import *\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp=len(itos)\n",
    "n_emb=50 #650\n",
    "n_hidden=50 #650\n",
    "n_layers=3\n",
    "dropout=0.5\n",
    "wd=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class language_model (nn.Module):\n",
    "    def __init__(self,n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,pretrain_mtx=None,adaptive_log_softmax=True,tie_weights=True):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device,self.pretrain_mtx=\\\n",
    "                            n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,pretrain_mtx\n",
    "        self.adaptive_log_softmax,self.tie_weights=adaptive_log_softmax,tie_weights\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        self.gen_hidden()\n",
    "        self.create_architecture()\n",
    "        if pretrain_mtx is not None:\n",
    "            print (\"initializing\")\n",
    "            self.initialize_glove()\n",
    "            \n",
    "        if self.adaptive_log_softmax is False:\n",
    "            self.criterion=nn.CrossEntropyLoss()\n",
    "        \n",
    "    def create_architecture(self):\n",
    "        # Dropout layer\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        # Embedding Layer\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb)\n",
    "        # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=False)\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        if self.adaptive_log_softmax:\n",
    "            # Adaptive Log Softmax Loss\n",
    "            self.adaptive_softmax=AdaptiveLogSoftmaxWithLoss(self.n_hidden,\n",
    "                                    self.n_inp,\n",
    "                                    cutoffs=[round(self.n_inp/15),3*round(self.n_inp/15)],\n",
    "                                    div_value=4,\n",
    "                                    get_full_prob=True)\n",
    "        else:\n",
    "            self.decoder=nn.Linear(self.n_hidden,self.n_inp)\n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=False\n",
    "        if self.tie_weights:\n",
    "            self.decoder.weight.requires_grad=False\n",
    "        \n",
    "    \n",
    "    def unfreeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=True\n",
    "        if self.tie_weights:\n",
    "            self.decoder.weight.requires_grad=True\n",
    "        \n",
    "    def initialize_glove(self):\n",
    "        self.encoder.weight.data=torch.Tensor(self.pretrain_mtx)\n",
    "        if self.tie_weights:\n",
    "            self.decoder.weight=self.encoder.weight\n",
    "    \n",
    "    def gen_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "        \n",
    "    def forward(self,Xb,Yb):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "        out,new_hidden=self.lstm(embs,self.hidden)\n",
    "        out=self.dropout_op(out)\n",
    "         # Wrap the hidden state in a new tensor without the gradients\n",
    "        self.hidden=(Variable(new_hidden[0].data,requires_grad=False).to(self.device),\\\n",
    "                     Variable(new_hidden[1].data,requires_grad=False).to(self.device))\n",
    "        if self.adaptive_log_softmax:\n",
    "            out=out.reshape(out.size(0)*out.size(1),out.size(2))        # output is of shape n_batch * n_seq * n_hidden\n",
    "      \n",
    "            out=self.adaptive_softmax(out,Yb.view(-1))\n",
    "            loss=out.loss\n",
    "            preds=out.output_full\n",
    "        else:\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "            preds=self.decoder(out.contiguous().view(out.size(0)*out.size(1), out.size(2)))\n",
    "            loss=self.criterion(preds,Yb.contiguous().view(-1))\n",
    "\n",
    "        return preds, loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multinomial(preds,actual):\n",
    "    preds=preds.max(1)[1]\n",
    "    correct=preds==actual\n",
    "    return correct.float().sum()/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing\n"
     ]
    }
   ],
   "source": [
    "device=\"cuda:0\"\n",
    "model=language_model(n_inp,n_emb,n_hidden,n_layers,False,bs,device,0.05,0.5,0.5,new_w,False,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59972, 50)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59972, 50]), torch.Size([59972, 50]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.weight.data.shape,model.decoder.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59972, 50]), 50, 59972)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(n_hidden,n_inp).weight.data.shape, n_hidden, n_inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if model forward works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([59972, 50]), torch.Size([59972, 50]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.weight.shape,model.encoder.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 70)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==0:\n",
    "    model.forward(torch.LongTensor(x),torch.LongTensor(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "  \n",
    "        \n",
    "    \n",
    "    def fit (self,Xb,Yb,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds,loss=self.model(Xb,Yb)\n",
    "        \n",
    "       \n",
    "            \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc=self.metric_fn(preds,Yb.view(-1))\n",
    "            acc=acc.item()\n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.25)\n",
    "            if 1==0:\n",
    "                for p in self.model.parameters():\n",
    "                    p.data.add_(self.lr, p.grad.data)\n",
    "        \n",
    "        return myloss, acc\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        n_batch=iterator.shape[1]\n",
    "        epoch_loss,epoch_acc,i=0,0,0\n",
    "        self.model.gen_hidden()\n",
    "        for k,i in enumerate(range(0,n_batch,self.bptt)):\n",
    "            seq_len=min(bptt,n_batch-1-i)\n",
    "            Xb=train_tokens[:,i:i+seq_len]\n",
    "            Yb=train_tokens[:,i+1:i+1+seq_len]\n",
    "            Xb=torch.LongTensor(Xb)\n",
    "            Yb=torch.LongTensor(Yb)\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc=self.fit(Xb,Yb,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  {epoch_acc/(k)}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/k\n",
    "        epoch_acc=epoch_acc/k\n",
    "        \n",
    "        if 1==0:\n",
    "            lr /= 4.0\n",
    "            # Freeze all the layers initially\n",
    "            for param in resnet.parameters():\n",
    "                param.requires_grad=False\n",
    "            torch.save(resnet,'resnet')\n",
    "            torch.save(resnet.state_dict(),'resnet_state_dict')\n",
    "            resnet.load_state_dict(torch.load('resnet_state_dict'))\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr  \n",
    "            \n",
    "        return epoch_loss,epoch_acc\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "    \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            loss,acc=self.run_epoch(dltrain,True)\n",
    "            print (f'Epoch:{epoch} Loss:{loss}')\n",
    "            lossv,accv=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Loss:{loss} Accuracy:{acc} Loss:{lossv} Accuracy:{accv}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "metric_fn=accuracy_multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5667"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batch=np.int(np.ceil(train_tokens.shape[1]/bptt))\n",
    "n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.weight.requires_grad, model.decoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model,optimizer,accuracy_multinomial,device,bptt,500,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59972"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 8.975491941452026  0.0061406596222077494\n",
      "Batch:1000 8.692644960403442  0.009156868540361756\n",
      "Batch:1500 8.475224107424419  0.0120673997871927\n",
      "Batch:2000 8.28836444926262  0.015320192958999541\n",
      "Batch:2500 8.122718526649475  0.018832748111209368\n",
      "Batch:3000 7.973838469028473  0.022595605326709726\n",
      "Batch:3500 7.838934770175389  0.026472607004231707\n",
      "Batch:4000 7.715929921030998  0.030334548054648622\n",
      "Batch:4500 7.604136815706889  0.034098231149559274\n",
      "Batch:5000 7.502896773529053  0.03796818856553291\n",
      "Batch:5500 7.409750179204074  0.042435815985510335\n",
      "Epoch:0 Loss:7.3808314409771025\n",
      "Batch:500 6.142567819595337  0.12176758889853954\n",
      "Epoch:0 Loss:7.3808314409771025 Accuracy:0.04397693012322231 Loss:6.140104875610206 Accuracy:0.12157229394718791\n",
      "Batch:500 6.3805231208801265  0.1016934098303318\n",
      "Batch:1000 6.341601963043213  0.10463352094590664\n",
      "Batch:1500 6.312938816070557  0.10719084799289703\n",
      "Batch:2000 6.287314788818359  0.10933077526092529\n",
      "Batch:2500 6.266097012138367  0.11053275354504585\n",
      "Batch:3000 6.2486835707028705  0.11131410904725393\n",
      "Batch:3500 6.233654435021537  0.1118750458679029\n",
      "Batch:4000 6.221170031070709  0.11222960835136474\n",
      "Batch:4500 6.21033812851376  0.11257851716213756\n",
      "Batch:5000 6.201517045688629  0.1128631936520338\n",
      "Batch:5500 6.193037631555037  0.11318447243760933\n",
      "Epoch:1 Loss:6.19052616539163\n",
      "Batch:500 5.89497509765625  0.14087143491208554\n",
      "Epoch:1 Loss:6.19052616539163 Accuracy:0.1132897455186083 Loss:5.892836249806284 Accuracy:0.14075420831331606\n",
      "Batch:500 6.115626666069031  0.11701154580712318\n",
      "Batch:1000 6.1077154641151425  0.11695989753305912\n",
      "Batch:1500 6.105489089012146  0.11703700368106365\n",
      "Batch:2000 6.10177275466919  0.11731910070404411\n",
      "Batch:2500 6.098998992347718  0.11744143582582474\n",
      "Batch:3000 6.096729129473369  0.11749350541830063\n",
      "Batch:3500 6.094149089268275  0.11768634945792811\n",
      "Batch:4000 6.092076844334603  0.11780316655524076\n",
      "Batch:4500 6.09001727104187  0.1179576384458277\n",
      "Batch:5000 6.088491250705719  0.11809671044498682\n",
      "Batch:5500 6.086410913467407  0.11826604108512402\n",
      "Epoch:2 Loss:6.085923460486749\n",
      "Batch:500 5.861195951461792  0.14359231543540954\n",
      "Epoch:2 Loss:6.085923460486749 Accuracy:0.11832026252966865 Loss:5.859055467389608 Accuracy:0.14341426896231407\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 6.078976338386536  0.12054286405444145\n",
      "Batch:1000 6.07230401468277  0.12041044642031193\n",
      "Batch:1500 6.07150251865387  0.12037656359374523\n",
      "Batch:2000 6.06898297905922  0.12059533644840122\n",
      "Batch:2500 6.0674547111511234  0.12052352325022221\n",
      "Batch:3000 6.066049376328786  0.12055907270809015\n",
      "Batch:3500 6.064398186411176  0.12063784036466053\n",
      "Batch:4000 6.063378535032272  0.12069279520772397\n",
      "Batch:4500 6.0620852540334065  0.12081197253200743\n",
      "Batch:5000 6.061506959438324  0.12086214955151081\n",
      "Batch:5500 6.060173147201538  0.12096499166569927\n",
      "Epoch:0 Loss:6.059898841267461\n",
      "Batch:500 5.84247246837616  0.14542088744044304\n",
      "Epoch:0 Loss:6.059898841267461 Accuracy:0.12098373994993902 Loss:5.840349059736139 Accuracy:0.14526680280622303\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f'{PATH}/inter/glove50_model_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/glove50_learner_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.weight.requires_grad, model.decoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 5.923489140510559  0.1383637427687645\n",
      "Batch:1000 5.839897509098053  0.14385824939608574\n",
      "Batch:1500 5.787385323842367  0.14753407403826713\n",
      "Batch:2000 5.745237706899643  0.15060275558382272\n",
      "Batch:2500 5.712291193008423  0.15279110733270646\n",
      "Batch:3000 5.685442800998688  0.15454387297232947\n",
      "Batch:3500 5.662019091742379  0.1561941215608801\n",
      "Batch:4000 5.642152305483818  0.15749368988722562\n",
      "Batch:4500 5.624449687639872  0.15870306105746163\n",
      "Batch:5000 5.609346181678772  0.1597312722891569\n",
      "Batch:5500 5.5948268599943685  0.16073991865190593\n",
      "Epoch:0 Loss:5.590528269096857\n",
      "Batch:500 5.153270504951477  0.1958033037483692\n",
      "Epoch:0 Loss:5.590528269096857 Accuracy:0.16102258566250197 Loss:5.152303151156533 Accuracy:0.19555949147618368\n",
      "Batch:500 5.448493457794189  0.17179890966415406\n",
      "Batch:1000 5.437963190078736  0.17195907419919967\n",
      "Batch:1500 5.434427093187968  0.17187345155080158\n",
      "Batch:2000 5.427937515258789  0.17227857970446347\n",
      "Batch:2500 5.422540602493286  0.1724734148979187\n",
      "Batch:3000 5.417928430398305  0.17270989838739237\n",
      "Batch:3500 5.412982037952968  0.1730292076425893\n",
      "Batch:4000 5.408767763853073  0.17329684890806674\n",
      "Batch:4500 5.4044481250974865  0.17360531961255604\n",
      "Batch:5000 5.40105043554306  0.17385951374471187\n",
      "Batch:5500 5.39683364686099  0.1741955127255483\n",
      "Epoch:1 Loss:5.395742636622366\n",
      "Batch:500 5.061910626411438  0.20233627119660377\n",
      "Epoch:1 Loss:5.395742636622366 Accuracy:0.1742514364297761 Loss:5.060874254509593 Accuracy:0.20200414370977138\n",
      "Batch:500 5.365922280311585  0.1775022057890892\n",
      "Batch:1000 5.358042948722839  0.17752418391406535\n",
      "Batch:1500 5.356838129997254  0.1773272975186507\n",
      "Batch:2000 5.35281426024437  0.17753476082533598\n",
      "Batch:2500 5.349645133018494  0.17757110697627068\n",
      "Batch:3000 5.347032600561778  0.17767116190493107\n",
      "Batch:3500 5.344119091851371  0.1778854868710041\n",
      "Batch:4000 5.341598795175552  0.17800749434158206\n",
      "Batch:4500 5.3391638914744055  0.17815696777237786\n",
      "Batch:5000 5.33744604139328  0.1782797882735729\n",
      "Batch:5500 5.334837713414973  0.17849965839494358\n",
      "Epoch:2 Loss:5.334209023033651\n",
      "Batch:500 5.017531436920166  0.2054450630247593\n",
      "Epoch:2 Loss:5.334209023033651 Accuracy:0.17852812969154408 Loss:5.016515188810358 Accuracy:0.20513237570746665\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f'{PATH}/inter/glove50_model_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/glove50_learner_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 5.3223634014129635  0.18038077726960183\n",
      "Batch:1000 5.316381345748901  0.18031621696054936\n",
      "Batch:1500 5.316147819201151  0.18011868943770726\n",
      "Batch:2000 5.313197108983993  0.18028063988685608\n",
      "Batch:2500 5.310846315383911  0.18024330460429192\n",
      "Batch:3000 5.308963719526926  0.18025476981699468\n",
      "Batch:3500 5.306856641088213  0.18038344591004507\n",
      "Batch:4000 5.305174709796906  0.18044739807397128\n",
      "Batch:4500 5.303480764283075  0.18055757814645768\n",
      "Batch:5000 5.302480280590057  0.18063506286144257\n",
      "Batch:5500 5.300642538244074  0.18078322469104421\n",
      "Epoch:0 Loss:5.300245186148959\n",
      "Batch:500 4.988265664100647  0.20725715133547784\n",
      "Epoch:0 Loss:5.300245186148959 Accuracy:0.18078733923849266 Loss:4.987243751970015 Accuracy:0.20695774364129207\n",
      "Batch:500 5.297073210716247  0.18213572204113007\n",
      "Batch:1000 5.2914591135978695  0.18196401883661747\n",
      "Batch:1500 5.291667382876078  0.1816893852253755\n",
      "Batch:2000 5.288867577075958  0.18183173863589763\n",
      "Batch:2500 5.286954933929444  0.1817383594930172\n",
      "Batch:3000 5.285433278242747  0.1817670408040285\n",
      "Batch:3500 5.283713215146746  0.18186311615364892\n",
      "Batch:4000 5.282222226500511  0.1819254886060953\n",
      "Batch:4500 5.280902798758612  0.18200965376032724\n",
      "Batch:5000 5.28030662317276  0.18205682100653647\n",
      "Batch:5500 5.2787634319825605  0.18220135645703836\n",
      "Epoch:1 Loss:5.278454615040546\n",
      "Batch:500 4.970265551567078  0.2082456131875515\n",
      "Epoch:1 Loss:5.278454615040546 Accuracy:0.1822009920426952 Loss:4.969293993625914 Accuracy:0.20795192527904086\n",
      "Batch:500 5.279627155303955  0.18352308467030526\n",
      "Batch:1000 5.273860673904419  0.18339286479353906\n",
      "Batch:1500 5.27412290986379  0.18311685750881831\n",
      "Batch:2000 5.272140985488892  0.18318146378546954\n",
      "Batch:2500 5.27055674571991  0.18306396382451057\n",
      "Batch:3000 5.269314378420512  0.18304130815466246\n",
      "Batch:3500 5.267901367051261  0.18304671109148435\n",
      "Batch:4000 5.26673603606224  0.18309169732779265\n",
      "Batch:4500 5.265661910692851  0.18314689421984884\n",
      "Batch:5000 5.265262816429138  0.18317654622495175\n",
      "Batch:5500 5.263956135142934  0.1832922155667435\n",
      "Epoch:2 Loss:5.263746150845233\n",
      "Batch:500 4.9561597347259525  0.20909066849946975\n",
      "Epoch:2 Loss:5.263746150845233 Accuracy:0.18327666133736875 Loss:4.9552326453359505 Accuracy:0.2088457685100595\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(train_tokens,valid_tokens,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),f'{PATH}/inter/glove50_model_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/glove50_learner_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.40244910553017, 142.5937958969891)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.9), np.exp(4.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:500 7.944759424209595  0.03532285663112998\n",
      "Batch:1000 7.877773783683777  0.03720142808556557\n",
      "Batch:1500 7.802010853131613  0.03968857092410326\n",
      "Batch:2000 7.722838351964951  0.04160571377538145\n",
      "Batch:2500 7.658665308570862  0.043098285208642485\n"
     ]
    }
   ],
   "source": [
    "if 1==0:\n",
    "    learner.lr_find(1e-4,1e-1,valid_tokens,n_batch)\n",
    "    learner.plot_lrs(50)\n",
    "    len(learner.lrs)\n",
    "    len(learner.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning to predict RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
