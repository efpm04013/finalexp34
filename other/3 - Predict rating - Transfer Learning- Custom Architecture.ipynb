{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os \n",
    "import fastai\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "PATH=\"/home/kirana/Documents/phd/final\"\n",
    "DATAPATH=\"/home/kirana/Documents/phd/data/aclImdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_train,df_valid,df_test,itos, train_tokens, valid_tokens, test_tokens, trn_lm, val_lm, test_lm]=pickle.load(open(f'{PATH}/inter/dfs_tokens_fastai.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.concat([df_train,df_valid],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid=df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.loc[df_train['label']<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0</td>\n",
       "      <td>I've noticed how all the other reviews of this...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>0</td>\n",
       "      <td>I went on a visit to one of my relatives a whi...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0</td>\n",
       "      <td>Darcy and her young daughter Pamela are headin...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0</td>\n",
       "      <td>Battlestar Gallactica was so great because it ...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0</td>\n",
       "      <td>Any movie with \"National Lampoon\" in the title...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3218      0  I've noticed how all the other reviews of this...   \n",
       "6854      0  I went on a visit to one of my relatives a whi...   \n",
       "2697      0  Darcy and her young daughter Pamela are headin...   \n",
       "5747      0  Battlestar Gallactica was so great because it ...   \n",
       "8731      0  Any movie with \"National Lampoon\" in the title...   \n",
       "\n",
       "                                                  words  \\\n",
       "3218  [ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...   \n",
       "6854  [ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...   \n",
       "2697  [ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...   \n",
       "5747  [ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...   \n",
       "8731  [ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...   \n",
       "\n",
       "                                                 tokens  \n",
       "3218  [41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...  \n",
       "6854  [41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...  \n",
       "2697  [41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...  \n",
       "5747  [41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...  \n",
       "8731  [41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=52 # 52 - Jeremey, 20 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt= 70 #70 - Jeremey, 35 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0</td>\n",
       "      <td>I've noticed how all the other reviews of this...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>0</td>\n",
       "      <td>I went on a visit to one of my relatives a whi...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0</td>\n",
       "      <td>Darcy and her young daughter Pamela are headin...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0</td>\n",
       "      <td>Battlestar Gallactica was so great because it ...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0</td>\n",
       "      <td>Any movie with \"National Lampoon\" in the title...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3218      0  I've noticed how all the other reviews of this...   \n",
       "6854      0  I went on a visit to one of my relatives a whi...   \n",
       "2697      0  Darcy and her young daughter Pamela are headin...   \n",
       "5747      0  Battlestar Gallactica was so great because it ...   \n",
       "8731      0  Any movie with \"National Lampoon\" in the title...   \n",
       "\n",
       "                                                  words  \\\n",
       "3218  [ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...   \n",
       "6854  [ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...   \n",
       "2697  [ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...   \n",
       "5747  [ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...   \n",
       "8731  [ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...   \n",
       "\n",
       "                                                 tokens  \n",
       "3218  [41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...  \n",
       "6854  [41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...  \n",
       "2697  [41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...  \n",
       "5747  [41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...  \n",
       "8731  [41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', 'the', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padlen=1400\n",
    "padding_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['n_tok']=df_train['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       304.945840\n",
       "std        224.981807\n",
       "min         16.000000\n",
       "25%        166.000000\n",
       "50%        228.000000\n",
       "75%        371.000000\n",
       "max       3354.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['n_tok']=df_valid['tokens'].apply(len)\n",
    "df_valid.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['n_tok']=df_test['tokens'].apply(len)\n",
    "df_test.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    x=df_train['tokens'].values[i]\n",
    "    y=df_train['label'].values[i]    \n",
    "    out=np.ones(padlen)\n",
    "    if len(x) < padlen:\n",
    "        out[:len(x)]=x\n",
    "    else:\n",
    "        out=x[:padlen]\n",
    "    print (out)\n",
    "    print (y)\n",
    "    print (len(out))\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64, 1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64, 1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts(), df_valid['label'].value_counts(),df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 5), (25000, 5))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_sentiment (Dataset):\n",
    "    def __init__ (self,df,bs,padlen=64,xvar='tokens',yvar='label',len_var='n_tok',padding_idx=1):\n",
    "        self.x,self.y,self.padlen,self.padding_idx,self.len_var,self.bs=\\\n",
    "            df[xvar],df[yvar],padlen,padding_idx,df[len_var],bs\n",
    "        self.len_var=self.len_var.clip(0,padlen)\n",
    "    \n",
    "    def pad (self,x):\n",
    "        out=np.ones(self.padlen)*self.padding_idx\n",
    "        out=out.astype(int)\n",
    "        if len(x)>=self.padlen:\n",
    "            out[:]=x[:self.padlen]\n",
    "        else:\n",
    "            out[:len(x)]=x\n",
    "        return out\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        return self.pad(self.x.iloc[idx]),self.y.iloc[idx],self.len_var.iloc[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padlen=max(df_train['n_tok'])\n",
    "padlen=1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=ds_sentiment(df_train,bs,padlen)\n",
    "dsvalid=ds_sentiment(df_valid,bs,padlen)\n",
    "dstest=ds_sentiment(df_test,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain=DataLoader(dstrain,bs,True)\n",
    "dlvalid=DataLoader(dsvalid,bs,False)\n",
    "dltest=DataLoader(dstest,bs,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb,yb,xlen in dltrain:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1]]),\n",
       " tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "         0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "         1, 0, 0, 1]),\n",
       " tensor([  77,  486,  435,  425,  169,   95,  170,  517,  253,   56, 1188,  220,\n",
       "          198,   99,  723, 1288,  371,  387,  415,  208,  187,  364,  646,   95,\n",
       "          134,  224,  184,  313,  260,  121,   98,  352,  290,   77,  296,  188,\n",
       "          166,  181,  205,  176,  144,  220,  385,  257,  236,  253,  652,  193,\n",
       "          288,  347,  356,  411]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb, xlen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cyclical learning rates\n",
    "\tvary learning rate by epoch between two values\n",
    "\t\n",
    "\n",
    "bptt=70\n",
    "n_emb=400\n",
    "n_hid=1150\n",
    "n_layers=3\n",
    "bs=48 # whatever is the max that can fit in memory\n",
    "\n",
    "# shuffle dataset\n",
    "# sort the data by length\n",
    "\n",
    "\n",
    "class ds_sentiment(Dataset):\n",
    "\tdef __init__(self,x,y):\n",
    "\t\tself.x,self.y=x,y\n",
    "\t\n",
    "\tdef __getitem__(self,idx):\n",
    "\t\treturn self.x[idx],self.y[idx]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 70)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp=len(itos)\n",
    "n_emb=400 #650\n",
    "n_hidden=400#400\n",
    "n_layers= 2 # 2\n",
    "dropout=0.5 # 0.5\n",
    "wd=1e-6\n",
    "bidirectional=True\n",
    "dropout_e=0.1 # 0.5\n",
    "dropout_o=0.5 #0.5\n",
    "n_out=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 1400]), torch.Size([52]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape,xlen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', 'the', '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_classifier (nn.Module):\n",
    "    def __init__(self,n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,pretrain_mtx=None,n_out=1,padding_idx=1):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device,self.pretrain_mtx,self.padding_idx=\\\n",
    "                            n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,pretrain_mtx,padding_idx\n",
    "        self.n_out=n_out\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        \n",
    "        self.create_architecture()\n",
    "        if pretrain_mtx is not None:\n",
    "            print (f'initializing glove with {pretrain_mtx.shape}')\n",
    "            self.initialize_glove()\n",
    "        self.init_hidden()\n",
    "        self.criterion=nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def set_dropouts(self, dropout, dropout_o, dropout_e):\n",
    "        self.dropout, self.dropout_o, self.dropout_e = dropout, dropout_o, dropout_e\n",
    "    \n",
    "    def create_architecture(self):\n",
    "        # Dropout layer\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        # Embedding Layer: Embedding layer just maps each word to an index. n_inp to n_emb mapping is all it does\n",
    "            # input to this is of shape n_batch * n_seq\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb,padding_idx=self.padding_idx)\n",
    "             # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "            # h and c are of shape n_layers * n_batch * n_hidden\n",
    "        # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "        \n",
    "                # output is of shape n_batch * n_seq * n_hidden\n",
    "            # output [:,-1,:] is the same as hn[-1]\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        self.fc=nn.Linear(self.n_hidden*2,self.n_out)\n",
    "\n",
    "        #self.log_softmax=nn.LogSoftmax()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=False\n",
    "         \n",
    "    def unfreeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=True\n",
    "\n",
    "    def initialize_glove(self):\n",
    "        self.encoder.weight.data.copy_(torch.Tensor(self.pretrain_mtx))\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "        \n",
    "    def forward(self,Xb,Yb,Xb_lengths):\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        \n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        #embs=self.dropout_enc(embs)\n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        # before lstm call\n",
    "            # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
    "        packed_embs = pack_padded_sequence(embs,Xb_lengths,batch_first=True, enforce_sorted=False)\n",
    "        lstm_out,(hidden,cell)=self.lstm(packed_embs)\n",
    "\n",
    "        # after lstm call\n",
    "        lstm_out,_=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "        #lstm_out=self.dropout_op(lstm_out)      \n",
    "        \n",
    "        # Wrap the hidden state in a new tensor without the gradients\n",
    "        #self.hidden=(Variable(newhidden[0].data,requires_grad=False).to(self.device),Variable(newhidden[1].data,requires_grad=False).to(self.device))\n",
    "        \n",
    "            # lstm_out has the values that are padded\n",
    "        #out=self.fc (lstm_out[:,-1,:])\n",
    "        hidden = self.dropout_op(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        \n",
    "        preds=self.fc(hidden)\n",
    "        \n",
    "              \n",
    "        \n",
    "        loss=self.criterion(preds,Yb.contiguous().float().view(-1,1))\n",
    "        \n",
    "        return preds.view(-1), loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds,actual, device=\"cpu\", cutoff=0.5):\n",
    "    preds=torch.sigmoid(preds)\n",
    "    zeros=torch.zeros(len(preds)).to(device)\n",
    "    ones = torch.ones(len(preds)).to(device)\n",
    "\n",
    "    preds=torch.where(preds>cutoff,ones,zeros)\n",
    "    correct=torch.round(preds).long()==actual\n",
    "    return correct.float().sum()/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds, y, device=\"cpu\", cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    y=y.float()\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lm_weights=pickle.load(open(f'{PATH}/inter/pretrained_lm_weights','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==0:\n",
    "    model=torch.load (f'{PATH}/inter/model_awd_lstm')\n",
    "    pretrained_lm_weights=model.encoder.weight.data.cpu().numpy()\n",
    "    import pickle\n",
    "    pickle.dump(pretrained_lm_weights,open(f'{PATH}/inter/pretrained_lm_weights','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if model forward works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59972, 400, 400, 2, True, 52, 'cpu', 0.1, 0.5, 0.5, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout_o,dropout,n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (59972, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=dropout_e,dropout=dropout,\\\n",
    "                 dropout_o=dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 30,402,401 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model_sentiment):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_classifier(\n",
       "  (dropout_enc): Dropout(p=0.1)\n",
       "  (encoder): Embedding(59972, 400, padding_idx=1)\n",
       "  (lstm): LSTM(400, 400, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout_op): Dropout(p=0.5)\n",
       "  (fc): Linear(in_features=800, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0057, -0.0218, -0.0379, -0.0263, -0.0034, -0.0097, -0.0489, -0.0381,\n",
       "         -0.0459, -0.0648, -0.0513, -0.0650, -0.0613, -0.0114, -0.0384,  0.0117,\n",
       "         -0.0634, -0.0441, -0.0327, -0.0516, -0.0436, -0.0385, -0.0293, -0.0189,\n",
       "          0.0221, -0.0306, -0.0268, -0.0068, -0.0590, -0.0556, -0.0035, -0.0688,\n",
       "         -0.0113, -0.0524, -0.0454, -0.0030, -0.0562, -0.0450, -0.0335, -0.0689,\n",
       "          0.0234, -0.0523,  0.0024, -0.0027, -0.0411, -0.0300, -0.0654, -0.0126,\n",
       "         -0.0469, -0.0004, -0.0677, -0.0421], grad_fn=<ViewBackward>),\n",
       " tensor(0.6943, grad_fn=<BinaryCrossEntropyWithLogitsBackward>))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,loss=model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1524e-02,  2.7905e-02, -5.0202e-02, -5.0593e-02, -1.5948e-02,\n",
       "        -4.4161e-02, -2.9383e-02, -9.8798e-03, -3.6411e-02,  1.8726e-03,\n",
       "        -6.3698e-02, -4.1794e-02, -3.3014e-02, -4.9287e-02,  1.1356e-02,\n",
       "         3.2799e-02, -3.4925e-02, -6.2835e-02, -1.3888e-02, -3.1053e-02,\n",
       "        -3.7084e-02, -2.3132e-02, -2.6684e-02, -4.1958e-02, -6.4447e-02,\n",
       "        -2.1188e-02,  5.5239e-05, -3.7687e-02, -4.8288e-02, -5.3419e-02,\n",
       "        -2.9108e-02, -6.7970e-02, -2.1826e-02, -2.6133e-02, -3.6825e-02,\n",
       "        -7.4513e-03, -3.6871e-02, -5.2097e-02, -9.4595e-03, -3.4023e-02,\n",
       "        -2.6630e-02, -3.3766e-02, -3.6976e-02, -3.4707e-02, -6.4169e-02,\n",
       "        -4.2531e-02, -7.4793e-02, -7.9659e-02, -3.3324e-02, -2.6354e-02,\n",
       "        -2.6314e-02, -3.7594e-02], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5769)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_binomial(preds.to(device),yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45333333333333337"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yb,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.038397e-02, -1.795423e-02, -3.457930e-02,  8.671192e-02, ..., -3.003510e-02, -1.899482e-02,  1.426260e-02,\n",
       "        -4.948893e-02],\n",
       "       [-2.453323e-02, -3.018817e-02,  6.663179e-02, -5.793565e-02, ...,  1.840935e-02,  6.371137e-02,  9.835491e-03,\n",
       "        -2.131385e-03],\n",
       "       [ 7.696263e-03, -4.266643e-02, -1.533517e-01,  2.239776e-01, ...,  9.869517e-02,  3.041433e-02,  1.824751e-01,\n",
       "         1.134978e-01],\n",
       "       [ 3.305928e-02,  2.266591e-01, -4.264669e-02,  1.490862e-01, ...,  3.407921e-02, -6.422209e-03,  3.180612e-01,\n",
       "         9.373549e-02],\n",
       "       ...,\n",
       "       [ 6.027538e-02, -5.980809e-02,  1.861691e-01, -3.105092e-02, ..., -2.764457e-02,  1.962678e-02, -2.172215e-03,\n",
       "         6.297247e-02],\n",
       "       [-1.592789e-02, -2.781571e-04,  1.301994e-01,  2.851282e-02, ...,  5.064877e-02,  1.670864e-01,  2.283701e-02,\n",
       "        -8.746398e-03],\n",
       "       [ 4.669700e-02,  3.138980e-02,  1.221957e-02, -3.927753e-02, ..., -1.281436e-01,  1.121320e-01, -3.726090e-03,\n",
       "        -3.777364e-02],\n",
       "       [ 1.677964e-02,  3.287802e-02,  2.598143e-02, -1.484041e-02, ..., -2.587889e-02,  4.438318e-02, -2.407267e-02,\n",
       "        -8.544586e-02]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_lm_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "  \n",
    "        \n",
    "    \n",
    "    def fit (self,Xb,Yb,Xlen,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds,loss=self.model(Xb,Yb,Xlen)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "            acc=acc.item()\n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        self.model.init_hidden()\n",
    "        for Xb,Yb,Xlen in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            Xlen=Xlen.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc=self.fit(Xb,Yb,Xlen,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  {epoch_acc/(k)}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "    \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            loss,acc=self.run_epoch(dltrain,True)\n",
    "            print (f'Epoch:{epoch} Loss:{loss}')\n",
    "            lossv,accv=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Loss:{loss} Accuracy:{acc} Loss:{lossv} Accuracy:{accv}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (59972, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout,\\\n",
    "                 dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n",
    "model_sentiment=model_sentiment.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model_sentiment.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "metric_fn=accuracy_binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.dropout_e,model_sentiment.dropout,model_sentiment.dropout_o\n",
    "learner.model.dropout_e,learner.model.dropout,learner.model.dropout_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 481)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain),len(dlvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model_sentiment,optimizer,accuracy_binomial,device,bptt,50,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.7066369485855103  0.5430769413709641\n",
      "Batch:100 0.684576485157013  0.5759615570306778\n",
      "Batch:150 0.6425048341353734  0.6267948929468791\n",
      "Batch:200 0.6065327759087086  0.6668269464373588\n",
      "Batch:250 0.5629986177682876  0.7026154100894928\n",
      "Batch:300 0.5198106682797273  0.7329487460851669\n",
      "Batch:350 0.49186822848660605  0.7530220081124986\n",
      "Batch:400 0.4667872473783791  0.7699519543349743\n",
      "Batch:450 0.44730751251180967  0.7832478948434194\n",
      "Epoch:0 Loss:0.4355782112900532\n",
      "Batch:50 0.23108960017561914  0.9107692682743073\n",
      "Batch:100 0.22891017936170102  0.9103846526145936\n",
      "Batch:150 0.22456104099750518  0.9105128578344981\n",
      "Batch:200 0.22391567029058934  0.9104808065295219\n",
      "Batch:250 0.22508717516064644  0.9097692675590515\n",
      "Batch:300 0.22787363258500895  0.9082051652669907\n",
      "Batch:350 0.23063194313219615  0.9078022347177778\n",
      "Batch:400 0.2317401228286326  0.907403883934021\n",
      "Batch:450 0.2332555033100976  0.9073504650592804\n",
      "Epoch:0 Loss:0.4355782112900532 Accuracy:0.7905365745391766 Loss:0.2350553782683896 Accuracy:0.9069367085821664\n",
      "Batch:50 0.2646583187580109  0.8950000309944153\n",
      "Batch:100 0.26424520641565324  0.8969231122732162\n",
      "Batch:150 0.25522372340162597  0.9002564481894175\n",
      "Batch:200 0.24894668739289044  0.9028846538066864\n",
      "Batch:250 0.24857273218035697  0.9042308084964752\n",
      "Batch:300 0.24447269834578036  0.9062179865439733\n",
      "Batch:350 0.2456202973638262  0.90549454331398\n",
      "Batch:400 0.24672786626964807  0.9048077295720577\n",
      "Batch:450 0.24664675320188204  0.9044444817966885\n",
      "Epoch:1 Loss:0.24618590029882045\n",
      "Batch:50 0.210488620698452  0.9126923489570617\n",
      "Batch:100 0.20662694841623305  0.914807734489441\n",
      "Batch:150 0.20198044255375863  0.9184615790843964\n",
      "Batch:200 0.20062920805066825  0.9201923486590385\n",
      "Batch:250 0.20134564703702926  0.920153886795044\n",
      "Batch:300 0.20401029879848162  0.9180128608147303\n",
      "Batch:350 0.20797256729432514  0.9158242160933359\n",
      "Batch:400 0.2082466163113713  0.915528885871172\n",
      "Batch:450 0.21044747215178278  0.9145726891358693\n",
      "Epoch:1 Loss:0.24618590029882045 Accuracy:0.9044538997810745 Loss:0.2117946673951377 Accuracy:0.9146250198883723\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.15643781267106532  0.9392308044433594\n",
      "Batch:100 0.15170912496745587  0.940576959848404\n",
      "Batch:150 0.14887252272417148  0.9437179843584697\n",
      "Batch:200 0.15302244954742492  0.942692342698574\n",
      "Batch:250 0.15552149205654858  0.9412308051586151\n",
      "Batch:300 0.1550097617569069  0.9417308056354523\n",
      "Batch:350 0.15466980420585189  0.9423077288695744\n",
      "Batch:400 0.1547545985551551  0.9422596521675587\n",
      "Batch:450 0.1535891719038288  0.9433333696259393\n",
      "Epoch:0 Loss:0.15388753840200248\n",
      "Batch:50 0.19780825667083263  0.9261538851261139\n",
      "Batch:100 0.19303739733994008  0.9257692694664001\n",
      "Batch:150 0.18850326873362064  0.9271795252958933\n",
      "Batch:200 0.1865695379115641  0.9279808077216148\n",
      "Batch:250 0.18671285258233547  0.9276154234409332\n",
      "Batch:300 0.18851893016447624  0.9266667052110036\n",
      "Batch:350 0.19104087996695723  0.925494544335774\n",
      "Batch:400 0.1905733852647245  0.9252885000407696\n",
      "Batch:450 0.19199975997209548  0.9242308076222737\n",
      "Epoch:0 Loss:0.15388753840200248 Accuracy:0.9432992525011487 Loss:0.19188262097800843 Accuracy:0.924348351241645\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{PATH}/inter/sentiment_model_nounfreeze_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/sentiment_learner_nounfreeze_state_dict')\n",
    "torch.save (model_sentiment,f'{PATH}/inter/sentiment_model_nounfreeze')\n",
    "torch.save (optimizer,f'{PATH}/inter/sentiment_optimizer_nounfreeze')\n",
    "torch.save (learner,f'{PATH}/inter/sentiment_learner_nounfreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.13206933081150055  0.9523077249526978\n",
      "Batch:100 0.13517245573922992  0.9523077273368835\n",
      "Batch:150 0.13895772594958544  0.9517949072519938\n",
      "Batch:200 0.13599954378791154  0.9526923432946205\n",
      "Batch:250 0.13511675421893596  0.9520000364780427\n",
      "Batch:300 0.13753904967258374  0.9511538829406102\n",
      "Batch:350 0.13729520365595818  0.951208826984678\n",
      "Batch:400 0.13575063530821352  0.95125003606081\n",
      "Batch:450 0.13639881011098623  0.9507265318764581\n",
      "Epoch:0 Loss:0.13726736557536337\n",
      "Batch:50 0.20821160793304444  0.9246154248714447\n",
      "Batch:100 0.20299150850623845  0.9255769610404968\n",
      "Batch:150 0.19593957920869193  0.9280769618352255\n",
      "Batch:200 0.19357149995863437  0.9278846541047097\n",
      "Batch:250 0.19429796694219112  0.9273846545219422\n",
      "Batch:300 0.19594232687105737  0.9262820903460185\n",
      "Batch:350 0.19837450975818294  0.925164874451501\n",
      "Batch:400 0.1978247296344489  0.9250481155514717\n",
      "Batch:450 0.19936219852003786  0.9242735426955753\n",
      "Epoch:0 Loss:0.13726736557536337 Accuracy:0.9506797100303079 Loss:0.1990309358340167 Accuracy:0.9239765294128545\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment=torch.load(f'{PATH}/inter/sentiment_model_nounfreeze')\n",
    "optimizer=torch.load(f'{PATH}/inter/sentiment_optimizer_nounfreeze')\n",
    "learner=torch.load(f'{PATH}/inter/sentiment_learner_nounfreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['lr']=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.14123125590384006  0.9515384960174561\n",
      "Batch:100 0.13720126066356897  0.9519231110811234\n",
      "Batch:150 0.14175206201771895  0.9503846498330434\n",
      "Batch:200 0.13787070576101543  0.950673111975193\n",
      "Batch:250 0.13643595884740353  0.9506923418045043\n",
      "Batch:300 0.13587378985558948  0.9508974699179331\n",
      "Batch:350 0.1364343300940735  0.9503846493789128\n",
      "Batch:400 0.1369226293871179  0.9502884954214096\n",
      "Batch:450 0.137931289759775  0.9493162737952339\n",
      "Epoch:0 Loss:0.13690404950596563\n",
      "Batch:50 0.20945526883006096  0.9242308080196381\n",
      "Batch:100 0.20437140921130775  0.92538465321064\n",
      "Batch:150 0.19885895226150752  0.9276923461755117\n",
      "Batch:200 0.19594240334816276  0.9286538848280906\n",
      "Batch:250 0.196985928542912  0.9280769622325897\n",
      "Batch:300 0.19861771863574784  0.9266667060057322\n",
      "Batch:350 0.20131355455411332  0.9254395999227252\n",
      "Batch:400 0.20086622369941323  0.925576962530613\n",
      "Batch:450 0.20266997471037837  0.9247863643699222\n",
      "Epoch:0 Loss:0.13690404950596563 Accuracy:0.9499320670373722 Loss:0.20239591946643382 Accuracy:0.9245362622574312\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type sentiment_classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{PATH}/inter/sentiment_model_nounfreeze_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/sentiment_learner_nounfreeze_state_dict')\n",
    "torch.save (model_sentiment,f'{PATH}/inter/sentiment_model_nounfreeze')\n",
    "torch.save (optimizer,f'{PATH}/inter/sentiment_optimizer_nounfreeze')\n",
    "torch.save (learner,f'{PATH}/inter/sentiment_learner_nounfreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.10892339136451483  0.9611538779735566\n",
      "Batch:100 0.11346936272457242  0.9590384936332703\n",
      "Batch:150 0.11927967343479395  0.9567949052651723\n",
      "Batch:200 0.12147471337579191  0.9556731104850769\n",
      "Batch:250 0.11969630967825651  0.9563846490383148\n",
      "Batch:300 0.11972544053569437  0.9562820849816004\n",
      "Batch:350 0.1217567585568343  0.955329703773771\n",
      "Batch:400 0.1228498473810032  0.9552404180169105\n",
      "Batch:450 0.12125151558054818  0.9561111439598932\n",
      "Epoch:0 Loss:0.12041834579575458\n",
      "Batch:50 0.21568004801869392  0.9215384960174561\n",
      "Batch:100 0.20902543500065804  0.9248077273368835\n",
      "Batch:150 0.20488682145873705  0.9260256787141165\n",
      "Batch:200 0.20381532108411193  0.9253846538066864\n",
      "Batch:250 0.20431856028735637  0.9250000388622284\n",
      "Batch:300 0.20576626198987166  0.9237820907433828\n",
      "Batch:350 0.20771939370248999  0.9228022374425615\n",
      "Batch:400 0.20725659501738847  0.9228846544027328\n",
      "Batch:450 0.20813429785271487  0.9223932010597653\n",
      "Epoch:0 Loss:0.12041834579575458 Accuracy:0.9564089564424543 Loss:0.20729067916991556 Accuracy:0.9223493110860955\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in learner.optimizer.param_groups:\n",
    "    param_group['lr']=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.0991195897012949  0.968846184015274\n",
      "Batch:100 0.09707770511507988  0.9696154141426087\n",
      "Batch:150 0.09497584269692501  0.9682051571210225\n",
      "Batch:200 0.09389502447796985  0.9688461831212044\n",
      "Batch:250 0.09578236123733222  0.9685384905338288\n",
      "Batch:300 0.09489997792833794  0.9682051567236583\n",
      "Batch:350 0.09468853758781084  0.9682967323916299\n",
      "Batch:400 0.0958864542923402  0.9677884908020497\n",
      "Batch:450 0.0963372344058007  0.968076952430937\n",
      "Epoch:0 Loss:0.097667737183376\n",
      "Batch:50 0.22544684886932373  0.9230769610404969\n",
      "Batch:100 0.21884346472099422  0.9242308074235916\n",
      "Batch:150 0.21248358910282453  0.9269231140613556\n",
      "Batch:200 0.20938478557392956  0.9275961908698082\n",
      "Batch:250 0.2092197651565075  0.9276154222488403\n",
      "Batch:300 0.21024449918419122  0.9268590128421783\n",
      "Batch:350 0.2124457100672381  0.9256593792779105\n",
      "Batch:400 0.21124606043100358  0.9261538840830326\n",
      "Batch:450 0.2128145018219948  0.9253846534093221\n",
      "Epoch:0 Loss:0.097667737183376 Accuracy:0.9676435608378071 Loss:0.21244211647496897 Accuracy:0.9256557231137758\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:50 0.09524211082607507  0.9680769574642182\n",
      "Batch:100 0.093828199878335  0.9686538773775101\n",
      "Batch:150 0.0919878846531113  0.9687179811795552\n",
      "Batch:200 0.09395078460685909  0.9689423388242722\n",
      "Batch:250 0.09284830520302058  0.9690769546031952\n",
      "Batch:300 0.09200737948218982  0.9695513131221135\n",
      "Batch:350 0.09359771828566278  0.9695055254868099\n",
      "Batch:400 0.09153297192882746  0.9706731064617634\n",
      "Batch:450 0.09010110232565138  0.971068405840132\n",
      "Epoch:0 Loss:0.09070706779714248\n",
      "Batch:50 0.23427742831408976  0.9230769610404969\n",
      "Batch:100 0.22739623751491309  0.9246154230833054\n",
      "Batch:150 0.22029945831745862  0.9264102943738302\n",
      "Batch:200 0.21663093800656497  0.9272115764021873\n",
      "Batch:250 0.216403607301414  0.927153883934021\n",
      "Batch:300 0.2173488519154489  0.9263461919625601\n",
      "Batch:350 0.21949118124055012  0.9253846536363874\n",
      "Batch:400 0.2178897394472733  0.92600965321064\n",
      "Batch:450 0.2196268634787864  0.9252137135134803\n",
      "Epoch:0 Loss:0.09070706779714248 Accuracy:0.9704582101342089 Loss:0.21936258052140784 Accuracy:0.9254558194204081\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
