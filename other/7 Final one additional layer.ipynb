{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os \n",
    "import fastai\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "PATH=\"/home/kirana/Documents/phd/final\"\n",
    "DATAPATH=\"/home/kirana/Documents/phd/data/aclImdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_train,df_valid,df_test,itos, train_tokens, valid_tokens, test_tokens, trn_lm, val_lm, test_lm]=pickle.load(open(f'{PATH}/inter/dfs_tokens_fastai.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.concat([df_train,df_valid],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid=df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.loc[df_train['label']<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0</td>\n",
       "      <td>I've noticed how all the other reviews of this...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>0</td>\n",
       "      <td>I went on a visit to one of my relatives a whi...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0</td>\n",
       "      <td>Darcy and her young daughter Pamela are headin...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0</td>\n",
       "      <td>Battlestar Gallactica was so great because it ...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0</td>\n",
       "      <td>Any movie with \"National Lampoon\" in the title...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3218      0  I've noticed how all the other reviews of this...   \n",
       "6854      0  I went on a visit to one of my relatives a whi...   \n",
       "2697      0  Darcy and her young daughter Pamela are headin...   \n",
       "5747      0  Battlestar Gallactica was so great because it ...   \n",
       "8731      0  Any movie with \"National Lampoon\" in the title...   \n",
       "\n",
       "                                                  words  \\\n",
       "3218  [ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...   \n",
       "6854  [ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...   \n",
       "2697  [ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...   \n",
       "5747  [ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...   \n",
       "8731  [ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...   \n",
       "\n",
       "                                                 tokens  \n",
       "3218  [41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...  \n",
       "6854  [41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...  \n",
       "2697  [41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...  \n",
       "5747  [41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...  \n",
       "8731  [41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=52 # 52 - Jeremey, 20 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt= 70 #70 - Jeremey, 35 - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0</td>\n",
       "      <td>I've noticed how all the other reviews of this...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>0</td>\n",
       "      <td>I went on a visit to one of my relatives a whi...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...</td>\n",
       "      <td>[41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0</td>\n",
       "      <td>Darcy and her young daughter Pamela are headin...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0</td>\n",
       "      <td>Battlestar Gallactica was so great because it ...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0</td>\n",
       "      <td>Any movie with \"National Lampoon\" in the title...</td>\n",
       "      <td>[ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...</td>\n",
       "      <td>[41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3218      0  I've noticed how all the other reviews of this...   \n",
       "6854      0  I went on a visit to one of my relatives a whi...   \n",
       "2697      0  Darcy and her young daughter Pamela are headin...   \n",
       "5747      0  Battlestar Gallactica was so great because it ...   \n",
       "8731      0  Any movie with \"National Lampoon\" in the title...   \n",
       "\n",
       "                                                  words  \\\n",
       "3218  [ \\n , xxbos, xxfld, 1, i, 've, noticed, how, ...   \n",
       "6854  [ \\n , xxbos, xxfld, 1, i, went, on, a, visit,...   \n",
       "2697  [ \\n , xxbos, xxfld, 1, xxmaj, darcy, and, her...   \n",
       "5747  [ \\n , xxbos, xxfld, 1, xxmaj, battlestar, xxm...   \n",
       "8731  [ \\n , xxbos, xxfld, 1, xxmaj, any, movie, wit...   \n",
       "\n",
       "                                                 tokens  \n",
       "3218  [41, 42, 43, 40, 13, 161, 2030, 110, 44, 3, 10...  \n",
       "6854  [41, 42, 43, 40, 13, 436, 30, 7, 2074, 9, 39, ...  \n",
       "2697  [41, 42, 43, 40, 2, 9225, 6, 55, 207, 551, 2, ...  \n",
       "5747  [41, 42, 43, 40, 2, 7900, 2, 33242, 20, 52, 10...  \n",
       "8731  [41, 42, 43, 40, 2, 120, 25, 23, 16, 2, 2155, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', 'the', '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padlen=1400\n",
    "padding_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['n_tok']=df_train['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       304.945840\n",
       "std        224.981807\n",
       "min         16.000000\n",
       "25%        166.000000\n",
       "50%        228.000000\n",
       "75%        371.000000\n",
       "max       3354.000000\n",
       "Name: n_tok, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['n_tok'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['n_tok']=df_valid['tokens'].apply(len)\n",
    "df_valid.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['n_tok']=df_test['tokens'].apply(len)\n",
    "df_test.sort_values(by='n_tok', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "1\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n",
      "[41. 42. 43. 40. ...  1.  1.  1.  1.]\n",
      "0\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    x=df_train['tokens'].values[i]\n",
    "    y=df_train['label'].values[i]    \n",
    "    out=np.ones(padlen)\n",
    "    if len(x) < padlen:\n",
    "        out[:len(x)]=x\n",
    "    else:\n",
    "        out=x[:padlen]\n",
    "    print (out)\n",
    "    print (y)\n",
    "    print (len(out))\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64, 1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64, 1    12500\n",
       " 0    12500\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts(), df_valid['label'].value_counts(),df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 5), (25000, 5))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds_sentiment (Dataset):\n",
    "    def __init__ (self,df,bs,padlen=64,xvar='tokens',yvar='label',len_var='n_tok',padding_idx=1):\n",
    "        self.x,self.y,self.padlen,self.padding_idx,self.len_var,self.bs=\\\n",
    "            df[xvar],df[yvar],padlen,padding_idx,df[len_var],bs\n",
    "        self.len_var=self.len_var.clip(0,padlen)\n",
    "    \n",
    "    def pad (self,x):\n",
    "        out=np.ones(self.padlen)*self.padding_idx\n",
    "        out=out.astype(int)\n",
    "        if len(x)>=self.padlen:\n",
    "            out[:]=x[:self.padlen]\n",
    "        else:\n",
    "            out[:len(x)]=x\n",
    "        return out\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        return self.pad(self.x.iloc[idx]),self.y.iloc[idx],self.len_var.iloc[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padlen=max(df_train['n_tok'])\n",
    "padlen=1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=ds_sentiment(df_train,bs,padlen)\n",
    "dsvalid=ds_sentiment(df_valid,bs,padlen)\n",
    "dstest=ds_sentiment(df_test,bs,padlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain=DataLoader(dstrain,bs,True)\n",
    "dlvalid=DataLoader(dsvalid,bs,False)\n",
    "dltest=DataLoader(dstest,bs,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb,yb,xlen in dltrain:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1],\n",
       "         [41, 42, 43,  ...,  1,  1,  1]]),\n",
       " tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "         0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " tensor([ 147,  232,  176,  409,  230,  192,  250,  418,  178,  335,  242, 1095,\n",
       "          114,  194,  159,  278,  285,  435,  428,  442,  201,  177,   81,  371,\n",
       "          139,  199,  466,  176,  173,  182,  200,  355,   99,  235,  599,  225,\n",
       "         1277,   94,   75,  175,  252,  174,  309,  473,  153,  140,  168,  453,\n",
       "          166,  198,  106,  423]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb, xlen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cyclical learning rates\n",
    "\tvary learning rate by epoch between two values\n",
    "\t\n",
    "\n",
    "bptt=70\n",
    "n_emb=400\n",
    "n_hid=1150\n",
    "n_layers=3\n",
    "bs=48 # whatever is the max that can fit in memory\n",
    "\n",
    "# shuffle dataset\n",
    "# sort the data by length\n",
    "\n",
    "\n",
    "class ds_sentiment(Dataset):\n",
    "\tdef __init__(self,x,y):\n",
    "\t\tself.x,self.y=x,y\n",
    "\t\n",
    "\tdef __getitem__(self,idx):\n",
    "\t\treturn self.x[idx],self.y[idx]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 70)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp=len(itos)\n",
    "n_emb=400 #650\n",
    "n_hidden=650#400\n",
    "n_layers= 3 # 2\n",
    "dropout=0.5 # 0.5\n",
    "wd=1e-7\n",
    "bidirectional=True\n",
    "dropout_e=0.2 # 0.5\n",
    "dropout_o=0.5 #0.5\n",
    "n_out=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 1400]), torch.Size([52]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape,xlen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'xxmaj', 'the', '.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool1d(5)\n",
    "input = torch.randn(1, 64, 8)\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_classifier (nn.Module):\n",
    "    def __init__(self,n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=0.05,dropout=0.5,\\\n",
    "                 dropout_o=0.5,pretrain_mtx=None,n_out=1,padding_idx=1,n_filters=100,filter_sizes=[3,4,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.n_emb,self.n_hidden,self.n_layers,self.bidirectional,self.bs,self.device,self.pretrain_mtx,self.padding_idx=\\\n",
    "                            n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,pretrain_mtx,padding_idx\n",
    "        self.n_out,self.n_filters,self.filter_sizes=n_out,n_filters,filter_sizes\n",
    "        self.dropout_e,self.dropout,self.dropout_o=dropout_e,dropout,dropout_o\n",
    "        \n",
    "        self.create_architecture()\n",
    "        if pretrain_mtx is not None:\n",
    "            print (f'initializing glove with {pretrain_mtx.shape}')\n",
    "            self.initialize_glove()\n",
    "        self.init_hidden()\n",
    "        self.criterion=nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def set_dropouts(self, dropout, dropout_o, dropout_e):\n",
    "        self.dropout, self.dropout_o, self.dropout_e = dropout, dropout_o, dropout_e\n",
    "    \n",
    "    \n",
    "    def freeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=False\n",
    "         \n",
    "    def unfreeze_embedding(self):\n",
    "        self.encoder.weight.requires_grad=True\n",
    "\n",
    "    def initialize_glove(self):\n",
    "        self.encoder.weight.data.copy_(torch.Tensor(self.pretrain_mtx))\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden\n",
    "        self.hidden=(Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)),\n",
    "                     Variable(torch.zeros(self.n_layers,self.bs,self.n_hidden,requires_grad=False).to(self.device)))\n",
    "    \n",
    "\n",
    "    def create_architecture(self):\n",
    "        ###################################\n",
    "        # Embedding layer - common to both\n",
    "        ###################################\n",
    "        self.dropout_enc=nn.Dropout(self.dropout_e)\n",
    "        self.encoder=nn.Embedding(self.n_inp,self.n_emb,padding_idx=self.padding_idx)\n",
    "        \n",
    "        #######################################\n",
    "        # For RNN #############################\n",
    "        #######################################\n",
    "        # Embedding Layer: Embedding layer just maps each word to an index. n_inp to n_emb mapping is all it does\n",
    "            # input to this is of shape n_batch * n_seq\n",
    "         # LSTM Layer\n",
    "        self.lstm=nn.LSTM(self.n_emb,self.n_hidden,self.n_layers,batch_first=True,dropout=self.dropout,\\\n",
    "                          bidirectional=self.bidirectional)\n",
    "          # embs are going to be of shape n_batch * n_seq * n_emb\n",
    "        self.dropout_op=nn.Dropout(self.dropout_o)\n",
    "        \n",
    "        self.avg_pool1d=torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool1d=torch.nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "    \n",
    "        #######################################\n",
    "        # For CNN #############################\n",
    "        #######################################    \n",
    "        #embedding dimension is the \"depth\" of the filter and the number of tokens in the sentence is the width.\n",
    "        self.conv_0=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[0])\n",
    "        self.conv_1=torch.nn.Conv1d (self.n_emb,self.n_filters,kernel_size=self.filter_sizes[1])\n",
    "        self.conv_2=torch.nn.Conv1d(self.n_emb,self.n_filters,kernel_size=self.filter_sizes[2])\n",
    "        \n",
    "        self.fc=nn.Linear(len(self.filter_sizes)*self.n_filters+self.n_hidden*4,self.n_out)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward (self,Xb,Yb,Xb_lengths):\n",
    "        \n",
    "        ####RNN PORTION\n",
    "        embs=self.dropout_enc(self.encoder(Xb))\n",
    "        if Xb.size(0) < self.bs:\n",
    "            self.hidden=(self.hidden[0][:,:Xb.size(0),:].contiguous(),\n",
    "            self.hidden[1][:,:Xb.size(0),:].contiguous())\n",
    "        packed_embs = pack_padded_sequence(embs,Xb_lengths,batch_first=True, enforce_sorted=False)\n",
    "        lstm_out,(hidden,cell)=self.lstm(packed_embs)\n",
    "        lstm_out,lengths=pad_packed_sequence(lstm_out,batch_first=True)\n",
    "        hidden = self.dropout_op(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        avg_pool=self.avg_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        max_pool=self.max_pool1d(lstm_out.permute(0,2,1)).view(Xb.size(0),-1)\n",
    "        \n",
    "        #CNN Portion\n",
    "        new_embs=embs.permute(0,2,1)        \n",
    "        conved_0=torch.relu(self.conv_0(new_embs))\n",
    "        conved_1=torch.relu(self.conv_1(new_embs))\n",
    "        conved_2=torch.relu(self.conv_2(new_embs)) \n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_0.shape[2])\n",
    "        pooled_0=max_pool1d(conved_0).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_1.shape[2])\n",
    "        pooled_1=max_pool1d(conved_1).squeeze(2)\n",
    "        max_pool1d=torch.nn.MaxPool1d(conved_2.shape[2])\n",
    "        pooled_2=max_pool1d(conved_2).squeeze(2)\n",
    "        cat_cnn = self.dropout_op(torch.cat([pooled_0,pooled_1,pooled_2],dim=1))\n",
    "        \n",
    "        ## Concatenate\n",
    "        big_out=torch.cat([cat_cnn,hidden,max_pool],dim=1)\n",
    "        preds=self.fc(big_out)\n",
    "\n",
    "        loss=self.criterion(preds,Yb.contiguous().float().view(-1,1))\n",
    "\n",
    "        \n",
    "        return preds.view(-1),loss\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds,actual, device=\"cpu\", cutoff=0.5):\n",
    "    preds=torch.sigmoid(preds)\n",
    "    zeros=torch.zeros(len(preds)).to(device)\n",
    "    ones = torch.ones(len(preds)).to(device)\n",
    "\n",
    "    preds=torch.where(preds>cutoff,ones,zeros)\n",
    "    correct=torch.round(preds).long()==actual\n",
    "    return correct.float().sum()/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binomial(preds, y, device=\"cpu\", cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    y=y.float()\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==0:\n",
    "    model=torch.load (f'{PATH}/inter/varybptt_model_awd_lstm')\n",
    "    pretrained_lm_weights=model.encoder.weight.data.cpu().numpy()\n",
    "    import pickle\n",
    "    pickle.dump(pretrained_lm_weights,open(f'{PATH}/inter/varybpttpretrained_lm_weights','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lm_weights=pickle.load(open(f'{PATH}/inter/varybpttpretrained_lm_weights','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if model forward works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59972, 400, 650, 3, True, 52, 'cpu', 0.2, 0.5, 0.5, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout_o,dropout,n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (59972, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e=dropout_e,dropout=dropout,\\\n",
    "                 dropout_o=dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 50,243,201 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model_sentiment):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_classifier(\n",
       "  (dropout_enc): Dropout(p=0.2)\n",
       "  (encoder): Embedding(59972, 400, padding_idx=1)\n",
       "  (lstm): LSTM(400, 650, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout_op): Dropout(p=0.5)\n",
       "  (avg_pool1d): AdaptiveAvgPool1d(output_size=1)\n",
       "  (max_pool1d): AdaptiveMaxPool1d(output_size=1)\n",
       "  (conv_0): Conv1d(400, 100, kernel_size=(3,), stride=(1,))\n",
       "  (conv_1): Conv1d(400, 100, kernel_size=(4,), stride=(1,))\n",
       "  (conv_2): Conv1d(400, 100, kernel_size=(5,), stride=(1,))\n",
       "  (fc): Linear(in_features=2900, out_features=1, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1720,  0.2152,  0.1471,  0.0471,  0.2479, -0.1711, -0.1465, -0.0710,\n",
       "          0.1347, -0.1875, -0.0061,  0.1740,  0.1584, -0.0970, -0.0822, -0.0072,\n",
       "          0.1839,  0.0710,  0.0609, -0.1447,  0.1054,  0.1393,  0.0952,  0.1834,\n",
       "          0.0654,  0.1726, -0.0235,  0.0480,  0.1059,  0.0055, -0.0384,  0.0519,\n",
       "          0.0906,  0.0687,  0.1459, -0.0274, -0.0706,  0.0401,  0.1523,  0.1061,\n",
       "          0.0200, -0.0222,  0.1844, -0.0557, -0.0227,  0.0875, -0.0396,  0.2745,\n",
       "          0.2360,  0.2532,  0.2390,  0.0311], grad_fn=<ViewBackward>),\n",
       " tensor(0.7132, grad_fn=<BinaryCrossEntropyWithLogitsBackward>))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,loss=model_sentiment.forward(xb,yb,xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0656,  0.0136, -0.1372,  0.2664,  0.0462,  0.0115, -0.1068,  0.1533,\n",
       "        -0.0305,  0.1814,  0.1157,  0.1596,  0.0667, -0.1568,  0.1733,  0.1093,\n",
       "        -0.1035, -0.1171, -0.0759, -0.0396, -0.1533,  0.0909,  0.0184,  0.0966,\n",
       "        -0.1293,  0.3231,  0.1233, -0.2267,  0.0190,  0.0853, -0.0648,  0.1876,\n",
       "         0.2022, -0.0178,  0.2353,  0.1190,  0.1483,  0.1013,  0.1072,  0.2681,\n",
       "         0.1409,  0.1748, -0.0869,  0.1414,  0.0591,  0.0903,  0.1532,  0.0349,\n",
       "         0.0477,  0.1788, -0.0938,  0.2276], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4231)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_binomial(preds.to(device),yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4609250398724083"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yb,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.145316,  0.061101, -0.033757,  0.046711, ..., -0.058453,  0.008306,  0.083778, -0.039654],\n",
       "       [-0.022339, -0.025568,  0.051964, -0.041687, ..., -0.009573,  0.103125,  0.010123,  0.003203],\n",
       "       [ 0.106638, -0.067644, -0.106292,  0.187177, ...,  0.035562,  0.054249,  0.158896,  0.07562 ],\n",
       "       [ 0.126048,  0.231132, -0.045351,  0.129894, ..., -0.02568 ,  0.022782,  0.360755,  0.066252],\n",
       "       ...,\n",
       "       [ 0.023593,  0.005543,  0.223388, -0.111507, ..., -0.072671,  0.084183,  0.033837, -0.05104 ],\n",
       "       [-0.118694,  0.003163,  0.080704, -0.06    , ...,  0.023115,  0.100214, -0.068435, -0.065693],\n",
       "       [ 0.030997,  0.019074,  0.051958, -0.069346, ..., -0.086905,  0.150055,  0.035902, -0.072329],\n",
       "       [ 0.002274, -0.002966,  0.049782, -0.051592, ..., -0.086745, -0.014879, -0.034296, -0.030868]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_lm_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1e-06\n",
      "1 9e-06\n",
      "2 8.1e-05\n",
      "3 0.000729\n",
      "4 0.006561000000000001\n",
      "5 0.059049000000000004\n"
     ]
    }
   ],
   "source": [
    "# Weight Decay Schedule\n",
    "tempstart=1e-6\n",
    "for i in range (6):\n",
    "    print (i, tempstart)\n",
    "    tempstart=tempstart*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.005\n",
      "1 0.0025\n",
      "2 0.00125\n",
      "3 0.000625\n",
      "4 0.0003125\n",
      "5 0.00015625\n"
     ]
    }
   ],
   "source": [
    "tempstart=5e-3\n",
    "for i in range (6):\n",
    "    print (i, tempstart)\n",
    "    tempstart=tempstart*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1,5,(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=[1e-2,5e-3,1e-4,5e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,4,(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs[torch.randint(0,4,(1,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=0.7,wd_mult=6):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        \n",
    "    def fit (self,Xb,Yb,Xlen,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            \n",
    "        preds,loss=self.model(Xb,Yb,Xlen)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "            acc=acc.item()\n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        self.model.init_hidden()\n",
    "        for Xb,Yb,Xlen in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            Xlen=Xlen.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc=self.fit(Xb,Yb,Xlen,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  {epoch_acc/(k)}')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        \n",
    "        if self.cycle_mult > 0:\n",
    "            reset_cycle=self.cycle_mult\n",
    "        \n",
    "        for epoch in range(n_epochs):                \n",
    "\n",
    "            self.n_epoch+=1\n",
    "            loss,acc=self.run_epoch(dltrain,True)\n",
    "            lossv,accv=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss} Train Accuracy:{acc} Valid Loss:{lossv} Valid Accuracy:{accv}')\n",
    "        \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    #self.wd=self.start_wd\n",
    "                    reset_cycle=self.n_epoch+reset_cycle\n",
    "                else:\n",
    "                    self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    if self.n_epoch>1:\n",
    "                        self.wd*=self.wd_mult\n",
    "                \n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                param_group['weight_decay']=self.wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing glove with (59972, 400)\n"
     ]
    }
   ],
   "source": [
    "model_sentiment=sentiment_classifier (n_inp,n_emb,n_hidden,n_layers,bidirectional,bs,device,dropout_e,dropout,\\\n",
    "                 dropout_o,pretrain_mtx=pretrained_lm_weights,n_out=1,padding_idx=1)\n",
    "model_sentiment=model_sentiment.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model_sentiment.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "#optimizer=torch.optim.SGD(model_sentiment.parameters(),lr=1e-2,momentum=0.9, weight_decay=wd)\n",
    "metric_fn=accuracy_binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 481)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain),len(dlvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(model_sentiment,optimizer,accuracy_binomial,device,bptt,100,0.25,cycle_mult=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5, 0.5, 0.2, 0.5, 0.5)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.dropout_e,model_sentiment.dropout,model_sentiment.dropout_o, learner.model.dropout_e,learner.model.dropout,learner.model.dropout_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.6561590895056725  0.6403846392035484\n",
      "Batch:200 0.5366727832704783  0.7254807962477208\n",
      "Batch:300 0.4839458031952381  0.7623077196876208\n",
      "Batch:400 0.4557170709222555  0.7820192597061396\n",
      "Batch:100 0.2724725313484669  0.8825000357627869\n",
      "Batch:200 0.26886157132685184  0.8884615758061409\n",
      "Batch:300 0.2781013127664725  0.8832051652669907\n",
      "Batch:400 0.28134386125952004  0.8809134976565838\n",
      "Epoch:0 Learning rate 0.005 Weight Decay 1e-07 Train Loss:0.43928361561714735 Train Accuracy:0.7931153341167434 Valid Loss:0.2816500296030124 Valid Accuracy:0.8814249521977192\n",
      "Batch:100 0.31812149576842785  0.8653846484422684\n",
      "Batch:200 0.3137647982314229  0.8698077249526978\n",
      "Batch:300 0.311615818887949  0.8701282382011414\n",
      "Batch:400 0.3130276659503579  0.8705288803577423\n",
      "Batch:100 0.24592029325664044  0.9063461929559707\n",
      "Batch:200 0.24146697673946618  0.9049038848280907\n",
      "Batch:300 0.24663610418637594  0.8998718329270681\n",
      "Batch:400 0.24899925781413912  0.8988461922109127\n",
      "Epoch:1 Learning rate 0.0034999999999999996 Weight Decay 1e-07 Train Loss:0.3138850336882776 Train Accuracy:0.870022423549898 Valid Loss:0.2536592009223672 Valid Accuracy:0.8974452643285422\n",
      "Batch:100 0.27341140106320383  0.893653883934021\n",
      "Batch:200 0.26730622485280037  0.8934615769982338\n",
      "Batch:300 0.266503561809659  0.8916667054096857\n",
      "Batch:400 0.2641939618624747  0.8924038851261139\n",
      "Batch:100 0.23154495149850846  0.9101923453807831\n",
      "Batch:200 0.22707522876560687  0.9121154230833054\n",
      "Batch:300 0.23244846401115257  0.9068590128421783\n",
      "Batch:400 0.23442873608320952  0.9053365774452686\n",
      "Epoch:2 Learning rate 0.0017149999999999995 Weight Decay 6e-07 Train Loss:0.2617020432115097 Train Accuracy:0.8936830708242008 Valid Loss:0.23608247991535122 Valid Accuracy:0.90462581841217\n",
      "Batch:100 0.23867666356265546  0.9061538869142532\n",
      "Batch:200 0.22844685688614846  0.9110577324032784\n",
      "Batch:300 0.2275799639771382  0.910192347963651\n",
      "Batch:400 0.22699896804988384  0.9100481168925763\n",
      "Batch:100 0.22466572254896164  0.9119231140613556\n",
      "Batch:200 0.22054356426000596  0.9136538842320442\n",
      "Batch:300 0.22642452336847782  0.9087179871400197\n",
      "Batch:400 0.22793347619473933  0.9075000390410424\n",
      "Epoch:3 Learning rate 0.0005882449999999997 Weight Decay 3.6e-06 Train Loss:0.22580535228126014 Train Accuracy:0.9105949539404649 Valid Loss:0.22964028275248413 Valid Accuracy:0.9066248593112287\n",
      "Batch:100 0.2107885481417179  0.9159615778923035\n",
      "Batch:200 0.2133527360111475  0.9154808092117309\n",
      "Batch:300 0.21750386429329713  0.914551323056221\n",
      "Batch:400 0.2163775018416345  0.9144711945950985\n",
      "Batch:100 0.22399921998381614  0.9136538833379746\n",
      "Batch:200 0.22061442654579877  0.9141346541047096\n",
      "Batch:300 0.22694745096067587  0.9091026031970978\n",
      "Batch:400 0.22831541476771236  0.9077404238283634\n",
      "Epoch:4 Learning rate 0.0001412376244999999 Weight Decay 2.16e-05 Train Loss:0.21547358078793033 Train Accuracy:0.914764953130496 Valid Loss:0.22975139124725563 Valid Accuracy:0.9071446098309792\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-1f7b1cd53d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-2af8cd7ad5a6>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(self, dltrain, dlvalid, n_epochs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mlossv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss} Train Accuracy:{acc} Valid Loss:{lossv} Valid Accuracy:{accv}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-2af8cd7ad5a6>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, iterator, mode_train, lrs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-2af8cd7ad5a6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Xb, Yb, Xlen, mode_train)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-2bf85162f7b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Xb, Yb, Xb_lengths)\u001b[0m\n\u001b[1;32m     76\u001b[0m             self.hidden[1][:,:Xb.size(0),:].contiguous())\n\u001b[1;32m     77\u001b[0m         \u001b[0mpacked_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXb_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_packed\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n\u001b[0;32m--> 525\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.30271638438105586  0.8767308050394058\n",
      "Batch:200 0.3132958155870438  0.872692343890667\n",
      "Batch:300 0.3159764149536689  0.8702564458052318\n",
      "Batch:400 0.3201662853360176  0.8679327280819416\n",
      "Batch:100 0.2887049153447151  0.8776923453807831\n",
      "Batch:200 0.2814566734805703  0.8803846517205238\n",
      "Batch:300 0.28890246905386446  0.8757051644722621\n",
      "Batch:400 0.29719005519524216  0.8715865743160248\n",
      "Epoch:0 Learning rate 0.005 Weight Decay 8.1e-06 Train Loss:0.3237553465948779 Train Accuracy:0.8664761269910419 Valid Loss:0.31267792787286697 Valid Accuracy:0.8644970768206829\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-2ac86570032a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-efd41f391d7c>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(self, dltrain, dlvalid, n_epochs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mlossv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss} Train Accuracy:{acc} Valid Loss:{lossv} Valid Accuracy:{accv}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-efd41f391d7c>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, iterator, mode_train, lrs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-efd41f391d7c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Xb, Yb, Xlen, mode_train)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-2bf85162f7b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Xb, Yb, Xb_lengths)\u001b[0m\n\u001b[1;32m     76\u001b[0m             self.hidden[1][:,:Xb.size(0),:].contiguous())\n\u001b[1;32m     77\u001b[0m         \u001b[0mpacked_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXb_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_packed\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n\u001b[0;32m--> 525\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type sentiment_classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{PATH}/inter/master_plannery_nounfreeze_state_dict_0.926')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/master_plannery_nounfreeze_state_dict_0.926')\n",
    "torch.save (model_sentiment,f'{PATH}/inter/master_plannery_nounfreeze_0.926')\n",
    "torch.save (optimizer,f'{PATH}/inter/master_plannery_nounfreeze_0.926')\n",
    "torch.save (learner,f'{PATH}/inter/master_plannery_nounfreeze_0.926')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.1861233239620924  0.9290384995937347\n",
      "Batch:200 0.2040072415024042  0.9222115752100944\n",
      "Batch:300 0.20834294127921263  0.9191026026010514\n",
      "Batch:400 0.20797092800959946  0.9189904239773751\n",
      "Batch:100 0.19662061750888823  0.9232692706584931\n",
      "Batch:200 0.19518430452793836  0.9242308068275452\n",
      "Batch:300 0.19698684968054295  0.9219231156508128\n",
      "Batch:400 0.19752246107906102  0.9215385001897812\n",
      "Epoch:0 Learning rate 0.005 Weight Decay 8.1e-06 Train Loss:0.21063770214386146 Train Accuracy:0.917831480255246 Valid Loss:0.19994267463498205 Valid Accuracy:0.9206981033148736\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type sentiment_classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_sentiment.state_dict(),f'{PATH}/inter/master_plannery_nounfreeze_state_dict_0.924')\n",
    "torch.save(optimizer.state_dict(),f'{PATH}/inter/master_plannery_nounfreeze_state_dict_0.924')\n",
    "torch.save (model_sentiment,f'{PATH}/inter/master_plannery_nounfreeze_0.924')\n",
    "torch.save (optimizer,f'{PATH}/inter/master_plannery_nounfreeze_0.924')\n",
    "torch.save (learner,f'{PATH}/inter/master_plannery_nounfreeze_0.924')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment.unfreeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment.encoder.weight.requires_grad, learner.model.encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:100 0.1648136916011572  0.9338461947441101\n",
      "Batch:200 0.18203133828938006  0.9277885025739669\n",
      "Batch:300 0.1935055408626795  0.9226923481623331\n",
      "Batch:400 0.19548907152377068  0.9235577322542667\n",
      "Batch:100 0.21496307700872422  0.9142308104038238\n",
      "Batch:200 0.20938672099262476  0.9173077315092086\n",
      "Batch:300 0.21482633091509343  0.9149359367291132\n",
      "Batch:400 0.21724978463724257  0.9122596545517445\n",
      "Epoch:0 Learning rate 0.0025 Weight Decay 7.290000000000001e-05 Train Loss:0.19839880052419562 Train Accuracy:0.9213617860403477 Valid Loss:0.22030734810629654 Valid Accuracy:0.9104070431725151\n",
      "Batch:100 0.13987691268324853  0.948653883934021\n",
      "Batch:200 0.1612088291347027  0.938750039935112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-2ac86570032a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-efd41f391d7c>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(self, dltrain, dlvalid, n_epochs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mlossv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss} Train Accuracy:{acc} Valid Loss:{lossv} Valid Accuracy:{accv}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-efd41f391d7c>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, iterator, mode_train, lrs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-efd41f391d7c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Xb, Yb, Xlen, mode_train)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmyloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
